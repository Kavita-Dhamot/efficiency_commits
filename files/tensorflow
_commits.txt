commit 8bb77977a92af20d53bcbbeeab916f170a78e519
Author: Dan Moldovan <mdan@google.com>
Date:   Tue Nov 9 08:08:39 2021 -0800

    Clean up placer rules.
    
    This change uses type information to determine whether a node without HostMemory outputs returns (variant) data types known to only exist on the host, such as datasets. Mainly, such nodes include common ops like Identity, control flow, etc, as most other dataset-specific nodes have HostMemory annotations in their kernel registrations.
    
    This method is more robust because we no longer need to match op names by substring checks, and it avoids inefficient DFS searches in this pass.
    
    PiperOrigin-RevId: 408612872
    Change-Id: I5db8a165fc4e429ff0bb39198216c86949103612

commit 1a01f1a2a15dff46f802fa3e37aac1041062a676
Author: Dan Moldovan <mdan@google.com>
Date:   Mon Nov 8 12:23:13 2021 -0800

    Clean up placer rules.
    
    This change uses type information to determine whether a node without HostMemory outputs returns (variant) data types known to only exist on the host, such as datasets. Mainly, such nodes include common ops like Identity, control flow, etc, as most other dataset-specific nodes have HostMemory annotations in their kernel registrations.
    
    This method is more robust because we no longer need to match op names by substring checks, and it avoids inefficient DFS searches in this pass.
    
    PiperOrigin-RevId: 408411228
    Change-Id: I092d0b1187659207d7dc89b5d4560e656b5b00b9

commit 67275fb0568b3669f9fed2d411fd38d970103c08
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Wed Nov 3 10:50:49 2021 -0700

    Add resolve methods for function attributes.
    
    Enable versions that allow for more efficient queries, keep old names for
    forwarding and move towards deprecating them in follow ups.
    
    PiperOrigin-RevId: 407375469
    Change-Id: Id101bc896a35733c69550143c3d67631fc603026

commit 545fd4f34e9106e00104d10b05391cee0e8c9b20
Author: Edward Loper <edloper@google.com>
Date:   Fri Oct 8 07:01:17 2021 -0700

    Add RaggedTensor support to tf.image.resize -- allows resizing a batch of images that have different sizes to all have the same size.  For now, this uses `tf.map_fn`, but if this proves to be too slow/inefficient, then we could look into other solutions.
    
    PiperOrigin-RevId: 401762053
    Change-Id: Ia3e825219f9c2449bb0e8bfab8c1ac48833ac815

commit cf6a88aa42a9490892be6c5e040b7b8cdf3e3ba8
Author: Michael Gester <mgester@google.com>
Date:   Wed Oct 6 10:51:44 2021 -0700

    Rewrite side effect analysis for TF dialect
    
    Some advantages of the new code:
    - support op-based side effects efficiently which saves control dependencies and
      results in better performance; previously they were treated like unknown side
      effects (see new tests which failed before)
    - support value-based side effects for non-resource operands/results
      efficiently; those are not supported by resource alias analysis and are now
      treated like op-based side effects; previously they were treated like unknown
      side effects (see new tests which failed before)
    - simplified/removed many special cases, unified behavior for value-based and
      op-based side effects
    - improved code efficiency and readability
    - added function for querying all resource IDs that an op potentially accesses
    
    PiperOrigin-RevId: 401286244
    Change-Id: I33e782dfd83a1ab7f7876e2e96b90b2b738cd819

commit 6dfeeb33cc4dda0cc965bbf8ce59b9853e0bb20b
Author: Mehdi Amini <aminim@google.com>
Date:   Mon Oct 4 21:14:57 2021 -0700

    Migrate `ConvolutionDimensions`attribute definition from StructAttr to be a first class attribute (NFC)
    
    This makes it more efficient to store, to access, and able to provide custom parsing/verification. The accessor are providing native view (ArrayRef<int64_t>)
    which are much nicer to work with as well.
    
    PiperOrigin-RevId: 400885874
    Change-Id: I8bfa488c25424b620d00a29bf3d4bc7b3bc48dc1

commit ac90b8f890a8cc24aeea2c49b3fbd880ab8003f8
Author: Paul Chiang <paulchiang@google.com>
Date:   Mon Oct 4 12:16:43 2021 -0700

    Hold and reuse the CheckpointReader in _CheckpointRestoreCoordinator
    
    Tiny improvement to actual execution speed, just seems rather inefficient to open the same file twice or more in quick succession.
    
    PiperOrigin-RevId: 400783565
    Change-Id: I86cf5d6b405dad5a315e57a8fa3cd407cb473112

commit f8a17851a9bbafe46fb6af81ec8b2f4e8fa8041a
Author: Geoffrey Martin-Noble <gcmn@google.com>
Date:   Thu Sep 30 17:07:48 2021 -0700

    Lowering of general mhlo.gather to linalg
    
    This is a complete lowering of the gather op and all its weirdnesses.
    Accounting for all these makes the lowering pretty fiddly and also
    means we miss more efficient representations for the common special
    cases. Some of those are already covered by the lowering via
    mhlo.torch_index_select, but this is something that should be
    revisited. In the meantime this gets us a (hopefully) correct lowering
    for the full API.
    
    In addition to the lit tests here, I also spot-checked the output of
    running this through IREE against `jax.lax.gather`.
    
    Fixes https://github.com/tensorflow/mlir-hlo/issues/16
    
    PiperOrigin-RevId: 400063077
    Change-Id: Icec8c50d891206a1a45c588a07a11f6038fb4bd0

commit aac48bdcb8665b3e21098d80a28454d84805c441
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Sep 28 12:49:25 2021 -0700

    Hold and reuse the CheckpointReader in _CheckpointRestoreCoordinator
    
    Tiny improvement to actual execution speed, just seems rather inefficient to open the same file twice or more in quick succession.
    
    PiperOrigin-RevId: 399507429
    Change-Id: I5667546be3ef3402de62ee9f0552b2762a139032

commit d12113312db4099f1d11cec85fbf25aaae6ae695
Author: Paul Chiang <paulchiang@google.com>
Date:   Tue Sep 28 11:42:24 2021 -0700

    Hold and reuse the CheckpointReader in _CheckpointRestoreCoordinator
    
    Tiny improvement to actual execution speed, just seems rather inefficient to open the same file twice or more in quick succession.
    
    PiperOrigin-RevId: 399491540
    Change-Id: I211137bd91d0a338080197f445484265977a9307

commit c1c6d04f358898ddc4d0d69b74822b8fecadbda9
Author: Mehdi Amini <aminim@google.com>
Date:   Thu Sep 23 12:55:11 2021 -0700

    Migrate `DotDimensionNumbers` attribute definition from StructAttr to be a first class attribute (NFC)
    
    This makes it more efficient to store, to access, and able to provide custom parsing/verification. The accessor are providing native view (ArrayRef<int64_t>)
    which are much nicer to work with as well.
    
    PiperOrigin-RevId: 398556364
    Change-Id: I648577d84ab61b8874be53e2e685523eae832267

commit 9789e64f1b9b46c9428a4cb4395df268a97692ea
Author: Mehdi Amini <aminim@google.com>
Date:   Wed Sep 22 19:18:57 2021 -0700

    Migrate `GatherDimensionNumbers` attribute definition from StructAttr to be a first class attribute (NFC)
    
    This makes it more efficient to store, to access, and able to provide custom parsing/verification. The accessor are providing native view (ArrayRef<int64_t>)
    which are much nicer to work with as well.
    
    PiperOrigin-RevId: 398386692
    Change-Id: I84d7d7529d6a88f9faad960296ad0a373a85cf2e

commit 8d855afa6855cca85676e783d8ce84f3addb59d1
Author: Rahul Joshi <jurahul@google.com>
Date:   Wed Sep 22 17:44:39 2021 -0700

    [XLA:GPU][SPMD] Move SPMD partitioning passes to before optimizations
    - Certain transformation and expansions of instructions can prevent optimal sharding
       propagation, so move SPMD partitioning to before optimizations.
    - Run several IR simplification passes (like inlining calls) before SPMD partitioning that
      are required for sharding propagation to happen correctly and efficiently.
    
    PiperOrigin-RevId: 398372070
    Change-Id: I6f6a0db61a15e19f8f2e64334f4655db0b700c70

commit 468636f1e914538ee9b4c91e2c79566be9a71407
Author: Mehdi Amini <aminim@google.com>
Date:   Wed Sep 22 14:44:48 2021 -0700

    Migrate `ScatterDimensionNumbers` attribute definition from StructAttr to be a first class attribute (NFC)
    
    This makes it more efficient to store, to access, and able to provide custom parsing/verification. The accessor are providing native view (ArrayRef<int64_t>)
    which are much nicer to work with as well.
    
    PiperOrigin-RevId: 398333824
    Change-Id: I5767d5e2c0303bc37aaf86d8818fc3a57629f736

commit 171ffe1ea9e0b0a33bcdd74c89a41eafa31c3827
Author: Eugene Zhulenev <ezhulenev@google.com>
Date:   Sat Aug 21 06:07:17 2021 -0700

    [tfrt:tf] Update shape optimization pass to handle const shapes
    
    - fix a bug in shape constraints optimization
    - add an option to optimize only constraints, because it allows more efficient mhlo broadcasts movement
    
    PiperOrigin-RevId: 392166188
    Change-Id: I01a653e316c3a05fed094fb47f5c33b31b160299

commit b5935d249ccd2f5c4c8c8d35251a5e29a5aa36be
Author: Matt Watson <mattdangerw@google.com>
Date:   Tue Aug 17 17:34:27 2021 -0700

    Add sparse and ragged options to TextVectorization output
    
    Sparse will only apply when output_mode is "one_hot", "multi_hot",
    "count", or "tf_idf" and the last dimension of the output contains
    bins for every element in the vocab. Sparse will be a more efficient
    output option when vocab size is large.
    
    Ragged will only apply when output_mode is "int", and will output
    a ragged tensor after string splitting where the final dimension
    contains ragged vocab indices of variable length.
    
    PiperOrigin-RevId: 391415472
    Change-Id: I6f600fb476667b8af8328b051392bdcf9f9b3266

commit afcd94a63b46ae0f3d5e249c2a696ffe3234916d
Author: Chenguang Wang <chenguangwang@google.com>
Date:   Tue Aug 10 20:37:14 2021 -0700

    Add a C++ friendly sparse->dense constructor for FormatConverter.
    
    The existing constructor uses the C API TfLiteSparsity struct, which needs to
    be freed with TfLiteSparsityFree() and allocated with malloc(). The
    TfLiteSparsity struct itself is then converted to C++ vectors.
    
    For C++ users, the TfLiteSparsity-based interface is neither easy to use or
    efficient.
    
    PiperOrigin-RevId: 390042122
    Change-Id: Iae6c00cabd6f1fbb84cdbe849823489097edeb40

commit 370888bf50de1b8f5fdfaafb64612be2babea4e1
Author: Ran Chen <crccw@google.com>
Date:   Thu Aug 5 04:52:59 2021 -0700

    Improve cancellation of MultiDeviceIterator::GetNextFromShard
    
    Cancelling GetNextFromShard shouldn't cancel the whole MultiDeviceIterator. Although in practice tf.distribute always fetch from all shards, it's possible that one shard iterator is deleted while the others are still fetching. This didn't surface any problems before because RemoteCall didn't propagate the cancellation.
    
    This change:
    1. Propagate cancellation in RemoteCall.
    2. Cancelling a GetNextFromShard only cancels itself. It no longer cancels MultiDeviceIterator. The cancellation is not efficient but it should be rare.
    
    PiperOrigin-RevId: 388906528
    Change-Id: Iadc4e34d401aecd071a7b0f86ce9f0580abe9ef5

commit a1582860e940bb8ec328ba412cf04b5ae7db210a
Author: Michael Gester <mgester@google.com>
Date:   Mon Jul 26 11:29:23 2021 -0700

    Make resource analysis more efficient by using new resource allocation trait
    
    For some resource-allocating ops we know that they will always create a unique
    resource. This CL introduces a trait to reflect that and implements
    `ResourceHandleAllocatorInterface` for the trait so resource alias analysis does
    not conservatively treat allocated resources as "unknown" in such cases anymore.
    
    PiperOrigin-RevId: 386920597
    Change-Id: Iac1fbf1f0ac0bde66041fd6ed876f857d5ccd8ad

commit c3d96abd1b48e5e0e7c3f309c7db5363e06bff9d
Author: Michael Gester <mgester@google.com>
Date:   Fri Jul 16 15:03:42 2021 -0700

    Make resource alias analysis less conservative
    
    Now we handle ops with `MemoryEffectOpInterface` less conservative which makes
    side-effect analysis more efficient. In particular, for a resource-allocating op
    with empty or anonymous `shared_name` attribute we can assume that the resource
    being created is unique which wasn't utilized before. One implication of this is
    less control dependencies in the exported GraphDef.
    Also added tests and improved some comments.
    
    PiperOrigin-RevId: 385231241
    Change-Id: I9614d050cb1a521dc34befa3e4189c0a2794493a

commit 41cc9e51b82b2655d75beaf619af6798e6a63be3
Author: Scott Zhu <scottzhu@google.com>
Date:   Mon May 17 17:30:04 2021 -0700

    Update keras metrics to use memory efficient alternative when collect values for evenly distributed thresholds.
    
    This implementation is based on the example in tf.slim. It exhibits a run time and space complexity of O(T + N), where T is the number of thresholds and N is the size of predictions. Metrics that rely on standard implementation instead exhibit a complexity of O(T * N). It could save a lot of memory when N is large.
    
    Added a unit test to verify the memory consumption. Under eager context, the ratio of memory between old and new approach is between 80 and 500. Set the limit to 50 to avoid the flakiness.
    
    PiperOrigin-RevId: 374315460
    Change-Id: If775df7031287d647a56589a7cfe9bafa7dd8cf3

commit 839928c4fcaca95eb540101f5f93a060e0995996
Author: Scott Zhu <scottzhu@google.com>
Date:   Fri May 14 16:41:03 2021 -0700

    Update keras metrics to use memory efficient alternative when collect values for evenly distributed thresholds.
    
    This implementation is based on the example in tf.slim. It exhibits a run time and space complexity of O(T + N), where T is the number of thresholds and N is the size of predictions. Metrics that rely on standard implementation instead exhibit a complexity of O(T * N). It could save a lot of memory when N is large.
    
    Added a unit test to verify the memory consumption. Under eager context, the ratio of memory between old and new approach is between 80 and 500. Set the limit to 50 to avoid the flakiness.
    
    PiperOrigin-RevId: 373889953
    Change-Id: Id0106518672d11773af051900df8cfa08a240a42

commit ffc28ef81c4235c4d5ebe77de92825db2367f579
Author: Srinivas Vasudevan <srvasude@google.com>
Date:   Thu May 13 16:41:51 2021 -0700

    Allow non-square matrices for LinearOperatorBlockDiag.
    
    We can still do matmuls efficiently in this case since we can avoid materializing zeros.
    
    PiperOrigin-RevId: 373683980
    Change-Id: If4dfe202f8c3abad3d6096175c953b3b78549871

commit bcf28627b3d8161fb53274ac0eeb11c5d59bdafe
Author: Scott Zhu <scottzhu@google.com>
Date:   Wed May 12 15:54:10 2021 -0700

    Update keras metrics to use memory efficient alternative when collect values for evenly distributed thresholds.
    
    This implementation is based on the example in tf.slim. It exhibits a run time and space complexity of O(T + N), where T is the number of thresholds and N is the size of predictions. Metrics that rely on standard implementation instead exhibit a complexity of O(T * N). It could save a lot of memory when N is large.
    
    Added a unit test to verify the memory consumption. Under eager context, the ratio of memory between old and new approach is between 80 and 500. Set the limit to 50 to avoid the flakiness.
    
    PiperOrigin-RevId: 373469207
    Change-Id: I95ed482dc4abde5de829d3018e445c9ecb62d2d6

commit 752ea9ac32ce762f272c2574a63f5379b8457c95
Author: Rajkumar Samuel <rsamuel@google.com>
Date:   Mon May 10 11:38:45 2021 -0700

    Add support in collective_rma_distributed for worker interfaces that directly populate the pointer provided in the RecvBuf request with the remote tensor, rather than populating transport_options with a serialized proto containing the remote tensor. This allows for more efficient implementation that avoids extra serialization / de-serialization costs from transport format into protos and finally to tensor buffer.
    
    PiperOrigin-RevId: 372976144
    Change-Id: I2f46d9c6b7dd30ea7003de7587703dc8666e7c27

commit 64a517a2b2421a2ae8f8655b474333591e48b726
Author: Eugene Zhulenev <ezhulenev@google.com>
Date:   Thu May 6 04:55:29 2021 -0700

    [tf:tfrt] Add ClusteringPolicy based clustering API to cluster_ops_by_policy
    
    Take the library based approach for clustering. End-user clustering pass must provide a specific clustering policies to the generic API.
    
    1. Values constraints propagation and refinement is not properly supported yet.
    2. A lot of inefficient linear lookups that will be removed once proper constraints propagation is implemented, and it will become clear what auxiliary data structures are required.
    
    tf_to_corert still relies on the generic cluster_ops_by_policy_pass.
    
    PiperOrigin-RevId: 372318535
    Change-Id: Ifdd521f0f66d84541c797a49b0c5f72f76788970

commit 311c53372c29ab23f6ca0a3bc63f40154278caf4
Author: Haoliang Zhang <haoliang@google.com>
Date:   Thu Apr 29 14:03:24 2021 -0700

    Improve the efficiency of registering FunctionDef in the flex delegate:
    Previously we add a FunctionDef for each subgraph in the tflite model, this isn't efficient since there are subgraphs that are not intended to be invoked as functions. After the change, we will collect subgraphs used by a list of ops (MapDataset, ReduceDataset) and only register functions for those subgraphs.
    
    PiperOrigin-RevId: 371199293
    Change-Id: I3a8ca3841d018b9a57e339fd8becf0d03863b974

commit e98fc97bee12655f93627604515a7140eea1cfe0
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Apr 22 11:59:02 2021 -0700

    [Grappler] Remove inefficient optimizer phase ReorderReshapeAroundUnary, and slightly extend RemoveRedundantReshapeAndBroadcast to do the same thing with fewer graph mutations.
    
    PiperOrigin-RevId: 369920081
    Change-Id: I94848f4b760081c098488b13c0b19f7e66bfcf7d

commit 0b9548386559a705308c9476dc3e562ffd0fae80
Author: Eugene Zhulenev <ezhulenev@google.com>
Date:   Wed Apr 21 14:45:46 2021 -0700

    [tf:mlir] Add clustering policy for TF operation
    
    1. Instead of passing a list of operations that could be clustered together via flags, configure clustered operations with a set of policies.
    2. Allow clustering with constraints, to guarantee that clustered operations can be compiled at runtime: no unknown ranks, guaranteed lowering to linalg indexing maps, etc...
    
    "ClusteringPolicy" is not a property of the operation itself, because different targets might have different restriction on what they can efficiently compile.
    
    PiperOrigin-RevId: 369739307
    Change-Id: Ib2e063d5fb0eb84f60c36d4d52d6e6bbc4b612cd

commit 8040cd1cca688fdfd10f954ebc7870d3c5c1883f
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Apr 15 12:06:29 2021 -0700

    [Grappler] Remove inefficient optimizer phase ReorderReshapeAroundUnary, and slightly extend RemoveRedundantReshapeAndBroadcast to do the same thing with fewer graph mutations.
    
    PiperOrigin-RevId: 368689570
    Change-Id: Iaed5c446291ceaf89a06cc42f8c1c020fe95140c

commit e4fcd304db0e6728862a62d2142596347017f32c
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Apr 14 14:22:56 2021 -0700

    [Grappler] Remove inefficient optimizer phase ReorderReshapeAroundUnary, and slightly extend RemoveRedundantReshapeAndBroadcast to do the same thing with fewer graph mutations.
    
    PiperOrigin-RevId: 368507717
    Change-Id: I6ceacd91abb058306c646ed75179810fa2f20414

commit 07da0b1e218bddc612dce603dbeb029bd9e44f18
Author: Ian Langmore <langmore@google.com>
Date:   Wed Apr 14 10:31:36 2021 -0700

    LinearOperatorLowRankUpdate now implements an efficient `diag_part`
    calculation.
    
    PiperOrigin-RevId: 368458205
    Change-Id: If752edbaf8097d90154102197e336fa9e45b4472

commit 63015de617b9286469aa6f8fd1224c9fdae69bb6
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Apr 13 19:20:40 2021 -0700

    [Grappler] Remove inefficient optimizer phase ReorderReshapeAroundUnary, and slightly extend RemoveRedundantReshapeAndBroadcast to do the same thing with fewer graph mutations.
    
    PiperOrigin-RevId: 368342596
    Change-Id: I4a5ce18508fb1aad76c1c0dac3ce5504224c6ddc

commit 03796cf1ddaa559bdca4e4f2e8fdc859bdf21a52
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Apr 13 17:22:10 2021 -0700

    [Grappler] Remove inefficient optimizer phase ReorderReshapeAroundUnary, and slightly extend RemoveRedundantReshapeAndBroadcast to do the same thing with fewer graph mutations.
    
    PiperOrigin-RevId: 368328186
    Change-Id: I73f5f45ebe4bc1387a4356aac9d3648840064855

commit 7fcf01bda7bb618fd174b17889657390d729cae4
Author: Mehdi Amini <aminim@google.com>
Date:   Fri Apr 9 21:56:39 2021 -0700

    Use tensor_content when converting constant attributes from MLIR to TensorFlow proto (NFC)
    
    This is just a more efficient storage, no functional change intended.
    
    PiperOrigin-RevId: 367753660
    Change-Id: Iec5016995eae1a88bd8df4074bfd85c85d2fe4e7

commit 7c138d4ae09bd56796a9b38f35c686756ec432c4
Author: Scott Zhu <scottzhu@google.com>
Date:   Thu Mar 18 15:23:37 2021 -0700

    Add docstring for tf.keras.applications.efficientnet.preprocess_input with more context.
    
    PiperOrigin-RevId: 363759122
    Change-Id: Ia3c12142a5e0855578a33c654cd6191869ae5e32

commit 6547de3b8e5d4c5c5f82386ad7eca616dffcc2f1
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Mar 11 09:44:05 2021 -0800

    [TF:TRT] Enable large tensor transpose for TensorRT 7.1.3.4 or higher.
    
    TensorRT 7.1.3.4 is no longer inefficient at large tensor transpose. It is better to enable the large tensor transpose by default to improve coverage and reduce fragmentation.
    
    PiperOrigin-RevId: 362313390
    Change-Id: I0add74e9996aefdeace431afad5ede9960705d68

commit 1e27427e0a74a7be489af8040a9a3378f8f8d94f
Author: Matt Watson <mattdangerw@google.com>
Date:   Wed Mar 10 19:00:15 2021 -0800

    Set TextVectorization.pad_to_max_tokens default to False
    
    This gives a consistent default across the preprocessing layers, and is the more efficient option.
    
    PiperOrigin-RevId: 362193657
    Change-Id: Id8cf48bdc501162dcd9cc9803cd7b3dce84906d4

commit 3779a51a376ac5116a9a64e3090ffd621493651f
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Thu Mar 4 14:48:53 2021 -0800

    Re-enable inference for large result number ops
    
    This was made more efficient upstream by https://github.com/llvm/llvm-project/commit/3dfa86149e14ebb7fa40c55749ae435641940ff6#diff-e0acb49d6ec4a97460a1af5fe8f80abc39f04d172d6c9a08c33da1209115cd4b so re-enabling.
    
    PiperOrigin-RevId: 361008357
    Change-Id: Ie095676290a5f8b086db086a48bee9a66f7c2b32

commit 1cac769816201020fe437e84a69867781861bef0
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Wed Jan 20 17:47:47 2021 -0800

    Add a prepare for export to XLA pass
    
    Add pass that prepares for more efficient export to XLA. Initially focus on splat constants: there is a mismatch in splat constant representations, where it is cheap in the dialect (and also in TF) but expensive on export to XLA/HloInstruction.
    
    PiperOrigin-RevId: 352913787
    Change-Id: I07e34a60a7e9f330c897178f8b65d75865e62d3f

commit 373f458fb66fdb709d7af828fe6200e3137942e6
Author: Chris Kennelly <ckennelly@google.com>
Date:   Mon Dec 21 08:44:36 2020 -0800

    Optimize calls to std::string::find() and friends for a single char.
    
    The character literal overload is more efficient.
    
    PiperOrigin-RevId: 348473483
    Change-Id: Ia76efa5ee243f7a92b35f1fb81d4af864fca8372

commit 4692525ffaa79982f094979f564b0b4942732ff5
Author: Chris Kennelly <ckennelly@google.com>
Date:   Thu Dec 17 17:59:05 2020 -0800

    Optimize calls to std::string::find() and friends for a single char.
    
    The character literal overload is more efficient.
    
    PiperOrigin-RevId: 348126864
    Change-Id: I12485209607a957ecb17a4ba1087473bb0c4dd06

commit c04bf06bfc9660bbe8863b35cf24646e3cad3a05
Author: Chris Kennelly <ckennelly@google.com>
Date:   Thu Dec 17 17:37:39 2020 -0800

    Optimize calls to std::string::find() and friends for a single char.
    
    The character literal overload is more efficient.
    
    PiperOrigin-RevId: 348124169
    Change-Id: I55909265a8267017210eb0deff5091da20d8ed70

commit fd0d7123b12c4b7e80468f3ce64a26687a6dc70b
Author: Chris Kennelly <ckennelly@google.com>
Date:   Thu Dec 17 10:57:49 2020 -0800

    Optimize calls to std::string::find() and friends for a single char.
    
    The character literal overload is more efficient.
    
    PiperOrigin-RevId: 348053258
    Change-Id: Ida72d7b6d860e1acf9a914e32d31a208cb23728b

commit 76a17bad5846a5bebec1b45ca29895cb50f43449
Author: Taehee Jeong <taeheej@google.com>
Date:   Wed Dec 9 11:14:46 2020 -0800

    Apply correct quantization schemes for LSTM inputs
    
    * Split LSTM quantization pass, and run it before main prepare_quantize pass.
    * Import correct quantization scheme from `operator_property.cc`
    * Added processing for input tensors, according to quantization scheme
      * Input 0, 18 (input and state): int8, handled by default quantization pass
      * Input 1~8, 16 (weights): int8, symmetric
      * Input 9~11 (coefficients for peephole): int16, symmetric
      * Input 12~15, 17 (biases): int32, depends on other scales and normalization
      * Input 19 (state): int16, quantized with power_of_two range. (already handled)
      * Input 20~23 (normalization parameters): int16, symmetric
    * Modify op definition of LSTM to recognize quantized type similarity
    
    PiperOrigin-RevId: 346593339
    Change-Id: I85dd22a9158fcb61496444ddf5bdf192447d45a0

commit e9f1da3c9b20e45ee226a835b27a252dbbd00d53
Author: Chenkai Kuang <chenkai@google.com>
Date:   Fri Nov 6 16:37:48 2020 -0800

    Improve the warning message when a large variable is not initialized in memory-efficient way.
    
    PiperOrigin-RevId: 341140947
    Change-Id: I3ffb9c61b71c9bdd78967dc77302727dd1e1462e

commit 3ac0818dea42c6699cda3cea26657f606f11a3cc
Author: Edward Loper <edloper@google.com>
Date:   Mon Oct 26 17:42:57 2020 -0700

    Add PythonTensorConverter class, which can be used in c++ to efficiently convert PyObjects to tensors.
    
    PiperOrigin-RevId: 339155091
    Change-Id: Icad20253f523e3ac3685d8d34c52e940f3889b57

commit 3be76dbd4932bddcb9101c6793b5f51359cb8b2e
Author: Chenkai Kuang <chenkai@google.com>
Date:   Wed Oct 21 17:25:39 2020 -0700

    Allow parameter server strategy sharded variable creator to efficiently use TF initializers.
    
    PiperOrigin-RevId: 338373212
    Change-Id: Id73d06faf5a950ebaad91b0dde0fba6c885aa089

commit 239fe406d30e8c8eb5387761d4e1eb48c5b532be
Author: Chenkai Kuang <chenkai@google.com>
Date:   Wed Oct 21 17:16:27 2020 -0700

    Modify some v2 initializers to be able to return a value that corresponds to a partition of the entire value. This is useful for efficiently initializing sharded variables where only a shard of the initial value is necessary at a time.
    
    PiperOrigin-RevId: 338371904
    Change-Id: Ib4320d73cbaec30f5a61793debe7755026175781

commit 9f2b92b4e94dba44177bca57351d7a9d4f441f94
Author: Michelle Casbon <michellecasbon@google.com>
Date:   Sat Oct 17 18:35:58 2020 -0700

    Add functions that return device type and ID for eager.
    
    This addition enables more efficient device handling in S4TF without needing to parse the full device string. As support for devices beyond TF eager are added, this info is needed more often and has a bigger impact on performance.
    
    Partial fix for https://github.com/tensorflow/swift/issues/524.
    
    PiperOrigin-RevId: 337696655
    Change-Id: Ifb576d37c765cced2329b77e0cebb591d8d3a46c

commit 36c1d26aef3dc5f880b23a73b4276d951c36eb43
Author: Jiri Simsa <jsimsa@google.com>
Date:   Thu Oct 15 13:29:24 2020 -0700

    [tf.data] Change implementation of `from_generator` so that generator functions that only produce dense tensors use PyFunc-based mechanism (which is more efficient) and the EagerPyFunc-based mechanism is only used when support for composite tensors is needed.
    
    PiperOrigin-RevId: 337371087
    Change-Id: Ib3c058a6ceeef330802cb41e92d61e71a3e98e8c

commit 6fdce880fa8a5f8b752323ce9d2b49d87382d80e
Author: Jose Baiocchi <jbaiocchi@google.com>
Date:   Tue Oct 6 14:20:19 2020 -0700

    Add format_utils to profiler
    
    For now just provide OneDigit implemented using StrFormat.
    A more efficient implementation could be used in the future.
    
    PiperOrigin-RevId: 335720026
    Change-Id: Iefa6ce5f5860b45533f081bbd83267347847a962

commit 7ea86e9de8a5b6426e7291e0e5477ddaee83ba88
Author: Adrian Kuegel <akuegel@google.com>
Date:   Thu Oct 1 05:12:01 2020 -0700

    Refactor the code to avoid duplication (NFC).
    
    IsFusedIrEmitterInefficient can reuse the code from
    FusionNodeIndexingEvaluation.
    
    PiperOrigin-RevId: 334791886
    Change-Id: I8bd812913355133bfcc0ea1f85792f47c550fb1c

commit dc5718967ed5f0b087cc9c6f69079d90f9ec1806
Author: Peter Hawkins <phawkins@google.com>
Date:   Wed Sep 9 06:35:02 2020 -0700

    [XLA] Use the compact WY representation in the implementation of blocked QR decompositions.
    
    Compact WY representations are described in:
    Schreiber, Robert, and Charles Van Loan. "A storage-efficient WY representation for products of Householder transformations." SIAM Journal on Scientific and Statistical Computing 10.1 (1989): 53-57.
    
    The compact WY representation is more storage efficient, requiring calculation of an nxn triangular matrix, where n is the block size (e.g., 128), instead of an mxn matrix where m is the number of matrix rows.
    
    PiperOrigin-RevId: 330711085
    Change-Id: Ideac239ff118ee6ac2fd1397b731a40e11d6ecd7

commit 4b0e555bdce3f1d78c97ff97d3c3bf037730c7ab
Author: Anna R <annarev@google.com>
Date:   Tue Sep 8 15:34:42 2020 -0700

    Addressing some of the StreamExecutor C API feedback:
    * Add block_host_until_done. Some devices might have more efficient implementation than enqueueing an event and waiting for it.
    * Plugin registration function now takes `void* dso_handle` instead of dso path. We might want to initialize multiple plugins based on `dso_handle` (for e.g. device, kernel, filesystem, etc..).
    * `visible_device_count` could be 0 at registration time. So, I removed corresponding validation.
    
    PiperOrigin-RevId: 330601080
    Change-Id: I378b0229d6c7a4311cbcd57ae6b872323edc8e82

commit 8c81dd1e6d657d92e98f8c33d7a83ab3d7122a1c
Author: Chenkai Kuang <chenkai@google.com>
Date:   Mon Aug 24 17:50:21 2020 -0700

    Add several new features to ShardedVariable in ParameterServer strategy:
    
    1. Dense layer partition. It is learned that in some cases dense layer partition could improve the model training speed.
    
    2. ShardedVariable now supports "assign", "assign_add" and "assign_sub" methods.
    
    3. ParameterServerStrategy now accepts a "variable_partitioner" parameter that controls all variable partitioning under strategy.scope(). It is compatible with tf.compat.v1 partitioner. Default partitioner is same as estimator canned models: each partition would has at least 64MB data.
    
    4. ParameterServerStrategy now is able to do memory-efficient initialization of sharded variables, but it requires a custom initializer that is partition aware.
    
    5. ParameterServerStrategy now is able to partition variables even if their `initial_value` is a Tensor (not a callable).
    
    Meanwhile, removed `strategy.experimental_variable_partitioning_scope` method. Per-layer partitioning using different partitioners is not going to be supported right now.
    
    PiperOrigin-RevId: 328241842
    Change-Id: I382743dd8d1a2f6b7ab207576aed2e77d71c5735

commit 5e9d0fe25cbd7d02a2350760e4bde00c58a803ec
Author: Rahul Joshi <jurahul@google.com>
Date:   Thu Aug 13 18:09:04 2020 -0700

    [MLIR] Extend ResourceDeviceInference to handle WhileRegion
    
    - For supporting device attribute propagation efficiently in the presence of WhileRegion,
      use tensorflow::walk() generic walker to implement a pre-order walk.
    - Extend test cases to test a inlined version of WhileRegion (where calls are inlined in
      the cond and body regions).
    
    PiperOrigin-RevId: 326565094
    Change-Id: Iac19d7f22bfd79b344fa8118115acc04fff7310e

commit ae10b73d6b70e2174613d83c3cbada09df4d4c48
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Jul 31 08:07:11 2020 -0700

    Optimize RearrangeWeights for fully connected to be cache efficient while reading weights.
    
    PiperOrigin-RevId: 324209359
    Change-Id: Ifa6dfff91b216e2e007bd4cefb8f3d814971d598

commit 8d2f9f65480a36e95e1f75956bcb40be6c08f5e8
Author: Ran Chen <crccw@google.com>
Date:   Thu Jul 30 11:29:11 2020 -0700

    Add timeout to CollectiveHints
    
    This allows users to set a timeout on the collective. This now should only be
    used for debugging purposes because it doesn't have an efficient implementation.
    
    PiperOrigin-RevId: 324044909
    Change-Id: I5d2e5c19fa5501749ebc4f13e2fd515e1de86539

commit 77787199e48764a439558e9d0b7368d96e730c2e
Author: Dmitry Volodin <mr.molkree@gmail.com>
Date:   Wed Jul 15 18:58:06 2020 +0300

    Fix indent in efficientnet.py

commit 62f54dd24004ade4a890a16c326953af3b1db87e
Author: Haoyu Zhang <haoyuzhang@google.com>
Date:   Thu Jul 9 21:37:46 2020 -0700

    Skip graph optimization passes for component functions.
    
    Before this change, the registered graph optimization passes are executed on both the main function side and the component function side when running distributed functions. This is not efficient, and can cause graph compilation problems. This change annotate component functions execution so that the graph passes will be skipped when instantiating them, avoiding the repeated graph passes that are already executed on the main function side.
    
    PiperOrigin-RevId: 320540983
    Change-Id: I4816240bcd5b54c738114c36f17ecc1b0b6c920d

commit 13e7dee685a9d7cd753ef1f6a3ac8ff54f679927
Author: Katherine Wu <kathywu@google.com>
Date:   Thu Jun 25 11:29:31 2020 -0700

    Don't trace OpLayer in SavedModel.
    
    OP Layers wrap a single Tensorflow op in a Layer class. Previously, SavedModel would wrap every internal layer call in a tf.function, so that the user can inspect individual layers in the loaded model. For TensorflowOpLayer, this is unnecessary because (1) wrapping a single op in a tf.function is very inefficient (2) the user is unlikely to individually inspect the autogenerated op layers in the loaded model.
    
    This change also resolves the saving issue that occurs when a user builds a functional model while using the eager-computed results of `tf.shape(x)` as the input shape to another op layer.
    
    An example to help illustrate:
    ```
    x = tf.keras.Input((2,))  # Shape is (None, 2)
    state = tf.zeros(4, tf.shape(x)[0])  # Expected shape is (4, None)
    LSTM(inputs, initial_state=state)
    ```
    
    Prior to this CL, the TensorFlowOpLayers generated for tf.shape and tf.zeros would be separately wrapped in tf.functions when saving. This results in `state` having a shape of `(None, None)` instead of `(4, None)`, causing potential problems when saving the rest of the model.
    
    PiperOrigin-RevId: 318311978
    Change-Id: I15099d8ba29c1d4facd3f88630f8e2651f22ae83

commit 81e6c5917e590f9c9a389d3e8825eae59fee171a
Author: Yixing Fu <yxfu93@hotmail.com>
Date:   Fri Jun 19 13:44:40 2020 -0400

    add script for updating efficientnet weights from ckpt

commit af926984871a130eec2816815cfc98a362d4f5b6
Author: Tres Popp <tpopp@google.com>
Date:   Wed Jun 17 00:44:26 2020 -0700

    [TF:XLA] Update TF:XLA tests for matrix_triangular_solve to test V1 and V2.
    
    TF:V1 raises an error on non-square coefficient matrices
    TF:V2 allows non-square coefficient matrices.
    PiperOrigin-RevId: 316839892
    Change-Id: I34c2567ba3579c8f0fd4bc6da57abe14bc6471b2

commit 580151fa26419ae583ec42cc6cbb92777e214109
Author: Berkin Ilbeyi <berkin@google.com>
Date:   Thu Jun 11 14:50:25 2020 -0700

    [XLA] Use latest to earliest order in prefetch picker.
    
    This will make more efficient use of alternate memory by trying to avoid
    prefetches that are unnecessarily early (and hence waste alternate memory).
    
    PiperOrigin-RevId: 315982838
    Change-Id: I6080a48661a5f032c0478b6d230b5b482840f2d4

commit 2b05096c356263ccd997cd01fa34d4e3aac25c21
Author: Robert Suderman <suderman@google.com>
Date:   Wed Jun 10 16:13:45 2020 -0700

    HLO Concat to Slice optimization
    
    In some Shape cases we encounter a Slice of a Concatenate optimization. This
    can be often completely removed or made more efficient for HLO optimization.
    
    PiperOrigin-RevId: 315789492
    Change-Id: I7a7384be1bc31fda41d0209eafc343f2a9190e81

commit d14b3ad658da633f15cb12e178e89fa2c7c470a2
Author: Rahul Joshi <jurahul@google.com>
Date:   Wed Jun 10 10:59:03 2020 -0700

    [NFC] Change IsExported() to be more efficient
    
    PiperOrigin-RevId: 315724467
    Change-Id: If2090deabaf0e2d387eceded3bf0a8ee1a122d5a

commit 2d4f1920d2d00775196d81073f92ad6079ee7f1a
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri May 29 05:10:42 2020 -0700

      [XLA] Transform unranked HLO
    
      All applications of a unary element-wise operation on a given tensor are
      independent from each other.
      We use this to realize these operations on a flattened, hence ranked, tensor
      when its shape is unknown at compile time.
      With only one dynamic reshape operation before and one after the targeted
      operation we can generate efficient code for the core of the operation.
      This CL realizes the transformation for `xla_hlo.sqrt` and others will follow
      analogously.
    
    PiperOrigin-RevId: 313761871
    Change-Id: I3566c2c36f1322a5833ebe49309255ba191c1bd1

commit f0ef163443b301ca913e967be566d8401c1bbf7a
Author: Mehdi Amini <aminim@google.com>
Date:   Wed May 27 02:56:50 2020 -0700

    Add an MLIR tracing implementation to the C unified API
    
    This is plumbing just enough to pass all the unit-tests.
    The conversion to the function library is quite inefficient, but it isn't
    clear if we want to optimize this or just focus on TFRT moving forward.
    
    PiperOrigin-RevId: 313356850
    Change-Id: I83815317d4958786d0103168b5d88498f89511ed

commit ad6798a2f62ae2cb7f433af7b721bf14b9850dde
Author: Berkin Ilbeyi <berkin@google.com>
Date:   Mon May 18 17:01:57 2020 -0700

    [XLA] Fix alternate memory allocation of conditional operands.
    
    Consider the following flattened HLO schedule of a conditional:
    
    1: a = fusion()
       true_computation:
    2:    parameter = parameter(0)
    3:    ...
    4:    ...
       false_computation:
    5:    parameter = parameter(0)
    6:    ...
    7:    ...
    8: conditional = conditional(pred, a, a)
    9: b = fusion(a)
    
    When we had a tensor that was a conditional operand (e.g. "a" in the example),
    we reserved the alternate memory for the entire 1-8 range. This meant that when
    we tried to allocate inside the called computations of the conditional, the
    offset we picked wasn't available since it would fall within the 1-8 range. This
    CL now reserves the conditional until the parameter of the earliest called
    computations (1-2 range).
    
    To allow efficient use of alternate memory by avoiding a very large conditional
    from claiming the offset for the entire called computation, the conditional
    operand might die within the called computation, allowing other HLOs inside the
    called computations to reclaim that alternate memory offset. This creates a
    subtlety for subsequent uses of conditional operands (e.g. "a" is used by a
    fusion at 9). These subsequent uses will force evictions (and then do another
    prefetch). After optimization, the graph might look like the following:
    
      a (Alternate Mem) = fusion()
      cs0 = copy-start(a)  # Must evict a because the allocation may die within
                           # called computation.
      cd0 (Default Mem) = copy-done(cs0)
      true_computation:
        parameter (Alternate Mem) = parameter(0)
        ...
        # parameter's alternate memory allocation may die here and another tensor
        # might use the same offset.
      false_computation:
        parameter (Alternate Mem) = parameter(0)
        ...
        # parameter's alternate memory allocation may die here and another tensor
        # might use the same offset.
      conditional = conditional(pred, a, a)
      cs1 = copy-start(cd0)  # May prefetch the value back to alternate memory.
      cd1 (Alternate Mem) = copy-done(cs1)
      b = fusion(cd1)
    
    PiperOrigin-RevId: 312182824
    Change-Id: I3ff5d019025ef96ced1aed4f6d170df677273348

commit 3e6697b916c9e775dc61375b913d21ba9d22126f
Author: Allen Lavoie <allenl@google.com>
Date:   Tue May 5 12:02:04 2020 -0700

    Forwardprop: opt the forwardprop utility function out of run_functions_eagerly
    
    If the function did execute eagerly it would be very inefficient.
    
    Fixes #39075.
    
    PiperOrigin-RevId: 309992909
    Change-Id: I3e31778390beb7a2808a33aa5fe18a5e9bd41bab

commit 958fbebe7092c1dae84e8449952b1cbdbfa8f2b1
Author: Shanqing Cai <cais@google.com>
Date:   Fri May 1 12:45:24 2020 -0700

    [tfdbg2] Various improvements to DebugDataReader for DebuggerV2
    
    This is related to https://github.com/tensorflow/tensorboard/pull/3564
    
    1. Add DebuggedGraph.get_op_creation_digest()
    2. Remove DebuggedGraph.get_op_type(), which is superseded by
       DebuggedGraph.get_op_creation_digest() and is not used anywhere.
    3. Add DebuggedGraph.add_op_consumers() and DebuggedGraph.get_op_consumers()
       to enable efficient tracking of the downstream consuming ops of a graph
       op.
    4. Add host_name and stack_frame_ids to data class GraphOpCreationDigest.
    
    PiperOrigin-RevId: 309455936
    Change-Id: I104084c1ef8b887f69733702a2f4c3190fa5402f

commit e2395e193522a5a8db1730c5409d7a1f4b15ab06
Author: Derek Murray <mrry@google.com>
Date:   Thu Apr 30 10:12:15 2020 -0700

    [Single-threaded executor] Optimize the handling of `OpKernel::const_tensor()`.
    
    This change applies an optimization that already takes place in the default `ExecutorState`: if a kernel produces a single constant tensor, we compute the `const Tensor*` once, and forward it to the downstream kernels without modifying the refcount. As a result, we invoke fewer virtual function calls and make fewer small temporary allocations. This makes `tf.constant()` and various DT_RESOURCE-producing kernels more efficient when using the single-threaded executor.
    
    As an enabling step, this change re-uses the `Entry` structure from the default executor, which has support for storing a union of a (manually-constructed) `Tensor` or a `const Tensor*` as appropriate.
    
    PiperOrigin-RevId: 309248989
    Change-Id: Id0bdf19e34caee7cd5ca3ac907f4ffaa61244934

commit ad35e8330d90a63ea4a9bc04829cbe1ce04ddb75
Author: Derek Murray <mrry@google.com>
Date:   Fri Apr 17 11:51:17 2020 -0700

    [Executor] Avoid unnecessary calls to `InlinedVector::clear()` and `resize()`.
    
    This change should benefit execution for graphs with large runs of inexpensive kernels, or where execution is dispatched by a single thread.
    
    The executor temporarily stores the outputs of an op in an `EntryVector`. `ExecutorState::ProcessOutputs()` resizes the vector to `item.num_outputs` elements before filling in the entries retrieved from the `OpKernelContext`. `ExecutorState::Process()` then clears the vector after calling `PropagateOutputs()`.
    
    This change makes two edits to avoid calls to `resize()` and `clear()`:
    
    1. We no longer clear the `EntryVector` between operations. Instead, we call `Entry::ClearVal()` on all of the elements that were touched by the last operation, which releases any leftover tensor references.
    
    2. We no longer resize the `EntryVector` to `item.num_outputs` in `ProcessOutputs()`. Instead, we resize it to the maximum of the current size and `item.num_outputs`. This avoids a deallocation/reallocation when the entries cannot be stored inline.
    
    This change also modifies the type of `outputs` passed to `ProcessOutputs()` from `EntryVector*` to a C-style `Entry*` array, to provide more efficient access (one fewer branch) to the individual elements.
    
    PiperOrigin-RevId: 307085587
    Change-Id: I0cda746b8e07e4f3f57aab3282df6b38b5653f88

commit 4c36ade963b0a7f1c8d2ea480d5b8c0922f6bebf
Author: Derek Murray <mrry@google.com>
Date:   Thu Apr 2 14:55:31 2020 -0700

    [Executor] Implement `SimplePropagatorState` and use it when a graph has no v1-style control flow.
    
    `SimplePropagatorState` provides a more efficient version of `PropagateOutputs()` thanks to the following simplifications:
    * No logic for propagating dead tensors.
    * No special propagation logic for handling control-flow nodes.
    * No dynamic allocation of or pointer chasing into `FrameState` or `IterationState` instances once the executor starts running a step.
    
    Note that `SimplePropagatorState` is compatible with graphs containing only v2-style (i.e. "functional") control flow, because the new style uses ops that require no special treatment from the executor.
    
    PiperOrigin-RevId: 304483519
    Change-Id: I7a1e8df973fc8ff1dbb0025ff89210bb658230be

commit 7d529df64cdf2cbf5d9b2b213c244df006967f42
Author: Adrian Kuegel <akuegel@google.com>
Date:   Thu Apr 2 02:02:05 2020 -0700

    Don't replace Transposes with Bitcasts on the GPU backend.
    
    We can generate the index for accessing the memory more efficiently if we still
    know which dimensions are permuted.
    Outside of fusion nodes, we still want to replace transposes with bitcasts, so
    we add another run of AlgebraicSimplifier at the end of OptimizeHloModule().
    
    PiperOrigin-RevId: 304354090
    Change-Id: I7314476397a6e24dd32b4a85f90d0fa243db382f

commit bd530a65d5712b0734c0b6c9af5aa83ccd9e7387
Author: Derek Murray <mrry@google.com>
Date:   Wed Apr 1 14:26:25 2020 -0700

    [Executor] Split `ExecutorState` into `PropagatorState` and `ExecutorState<PropagatorStateType>`.
    
    This change is part of an ongoing refactoring to simplify "executor.cc" and enable the substitution of more efficient implementations of `PropagateOutputs()`.
    
    PiperOrigin-RevId: 304262448
    Change-Id: I46a2d7fcdde89a71c502d272f35adfd34b0c4cab

commit 0c5bd2d4c77ec26b1c831c4665cf97a236496f47
Author: Derek Murray <mrry@google.com>
Date:   Fri Mar 27 14:45:30 2020 -0700

    Optimize (legacy, reference-typed) `VariableOp::Compute()`.
    
    The `cinfo_` member can be initialized at construction time, so there is no need to acquire a mutex in the `Compute()` method.
    
    The changes in "ops_testutil.cc" update the test harness to use a non-deprecated method for creating kernels in C++ tests. The deprecated API did not set the resource manager in `OpKernelConstruction`.
    
    Note that this op is still rather inefficient because it looks up the variable in the `ResourceMgr` every time it is invoked (for backwards compatibility reasons, relating to state invalidation via `Session::Reset()`). However, new code—and all TF2 code—should use resource variables, which avoid this codepath.
    
    PiperOrigin-RevId: 303410876
    Change-Id: I29e114bb863fe8a1f483d4ce1e034f5f13f1a116

commit 423c2cae269cee41adc3131e50f0d0160ec3a74e
Author: Berkin Ilbeyi <berkin@google.com>
Date:   Fri Mar 6 11:24:33 2020 -0800

    [XLA] When allocating for later uses, use an use_times dict to improve compile time complexity.
    
    We were iterating the last use time one by one. This CL makes it more efficient
    by finding longer allocations that are actually used.
    
    PiperOrigin-RevId: 299396736
    Change-Id: Iac245018bb53b8d8ea346474321bab3bd7d2909d

commit 2c88f1f9f5a71c6c2dc61f01707f8a936a89ca1f
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Tue Mar 3 17:05:21 2020 -0800

    Materialize constants inside regions of TFL While
    
    If constant folding produces a constant while folding operations inside a TFL While, then keep it within the region of the While. This is more efficient on TFLite runtime when outlined to functions again.
    
    PiperOrigin-RevId: 298728560
    Change-Id: I305f5b0ce6559a94c4239d4484b81ea4470e7c68

commit 4b204acd3f297056252b81f3c3bee716dd3c871f
Author: Gaurav Jain <gjn@google.com>
Date:   Sun Mar 1 00:41:51 2020 -0800

    Speed up querying of kernel input properties
    
    * Store the input devices in the KernelAndDeviceOp class during Init.
      This allows index-based access to be faster due to the std::vector and
      the results are preserved in the kernel cache.
    * Use array-style access for inlined vectors since index-based access in
      a for loop is less efficient.
    
    PiperOrigin-RevId: 298152600
    Change-Id: If0b89ffdec78f7344c1c47b74d05cbfa2b9d01ee

commit 0e4f3a99d439c41add66513aa065e5c0656167d7
Author: Sanjoy Das <sanjoy@google.com>
Date:   Sun Feb 23 14:50:55 2020 -0800

    Add a TF_DEBUG_TRT_ALLOW_INEFFICIENT_TRANSPOSE debug flag
    
    If set, TF_DEBUG_TRT_ALLOW_INEFFICIENT_TRANSPOSE lets the TensorRT bridge lower
    inefficient transpose operations.
    
    PiperOrigin-RevId: 296773482
    Change-Id: Ifee5ce2d24de996336e753c48a7229fccff749ab

commit 8aa4fe59eb98147609dc690c1244dde315312cd4
Author: Derek Murray <mrry@google.com>
Date:   Thu Feb 6 13:26:38 2020 -0800

    [Rendezvous] Add a performance counter for tracking how many dead tensors are sent.
    
    This could provide useful input for identifying where a graph with control flow is partitioned in an inefficient way with a large number of cross-device dead edges, and could be refactored into a more efficient graph (e.g. with a multi-device function call inside one branch of a conditional).
    
    PiperOrigin-RevId: 293662534
    Change-Id: I4fc37a903129bbeffa38fdece17a4316fc26d8d9

commit 97b4c2c413d9c880e78e4d2616500cb30b773203
Author: Adrian Kuegel <akuegel@google.com>
Date:   Mon Feb 3 06:05:29 2020 -0800

    Replace IsFusedIrEmitterInefficient with FusionNodeIndexingEvaluation class.
    
    This avoids having to recompute everything from scratch for the whole fusion
    computation. Instead the class keeps the data structures up-to-date after each
    fusion operation.
    Also refactor FusionNodeIndexingEvaluation and support initializing it with a
    non-empty fusion node.
    For now, IsFusedIrEmitterInefficient is still used for the FusionMerger pass.
    
    PiperOrigin-RevId: 292904527
    Change-Id: I435ca6104a95e188250732f9000ea6ea7dfa1956

commit 97da75856c224853a84a1a65ef31f12143278030
Author: Adrian Kuegel <akuegel@google.com>
Date:   Mon Feb 3 01:38:46 2020 -0800

    Add a FusionNodeIndexingEvaluation class.
    
    This will replace the function IsFusedIrEmitterInefficient, at least for the
    regular GpuInstructionFusion and CpuInstructionFusion passes. It can be
    integrated in a fusion pass and avoids having to recompute everything from
    scratch for the whole fusion computation. Instead it keeps the data structures
    up-to-date after each fusion operation.
    
    PiperOrigin-RevId: 292872040
    Change-Id: Ia58a5df286b330fe5a6adb38ba63af48d8d7c74b

commit 32ac70c62a80899ff4b0dc72a608b824958566e7
Author: Terry Heo <terryheo@google.com>
Date:   Mon Jan 27 17:58:52 2020 -0800

    Add MemoryPlanner::ResetAllocationsAfter()
    
    In the previous workaround for dynamic intermediate tensors handling, it calls
    MemoryPlanner::ResetAllocations() to handle resized tensors. Instead of reset
    all the allocation plan, it's more efficient to invalidate allocations only
    after the current execution node.
    
    With the following simple LSTM keras model, benchmark_model shows that
    the execution time improves about 40%.
    
    tf.keras.models.Sequential([
        tf.keras.layers.Input(shape=(28, 28), name='input'),
        tf.keras.layers.LSTM(20),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')
    ])
    
    PiperOrigin-RevId: 291840506
    Change-Id: I30e210f25b9631b9d417675d7217c8b41a07987f

commit 55b7bde1f6ee9d9be06953f15809d59ba73bc11d
Author: Adrian Kuegel <akuegel@google.com>
Date:   Thu Jan 16 03:48:13 2020 -0800

    Use DepthwiseConvolutionConverter before ConvolutionGroupConverter.
    
    A recent change in shape_inference required the usage of ConvolutionGroupConverter
    instead of DepthwiseConvolutionConverter. This meant that the filter
    shape got expanded before we called into cuDNN, which is less efficient
    than handling depthwise convolutions directly with cuDNN.
    Now that this change is reverted, go back to using DepthwiseConvolutionConverter.
    However it cannot handle cases with batch_group_count > 1 if input batch
    is not equal to batch_group_count. For this, we still need the
    ConvolutionGroupConverter.
    
    PiperOrigin-RevId: 290037172
    Change-Id: I5b4a1f8eea92392e39ae9cce8b4122f86f7e992e

commit 7835b713e766809f91913a3be2f7d8185b52d36f
Author: Derek Murray <mrry@google.com>
Date:   Fri Jan 3 09:06:14 2020 -0800

    Add Variant::emplace(), based on the C++17 `std::variant<Types...>::emplace()`.
    
    For some variant values (e.g. Tensor) the move constructor must perform a non-trivial amount of copying (e.g. copying the TensorShapeRep). In this case, creating a variant value in place with the new method will be more efficient.
    
    PiperOrigin-RevId: 288000918
    Change-Id: Ib47a9406586e562db5a5c4085d47e7b83702723b

commit 8e6539f5ea47bac3423c5d63f0cd4b18a6479558
Author: Benoit Jacob <benoitjacob@google.com>
Date:   Mon Dec 16 08:31:51 2019 -0800

    Limit rectangularness to avoid using too tiny kernel blocks in the case of highly rectangular destination matrices (gemv-ish cases), which would result in too few iterations of the kernel inner loop to be fully efficient. Now aim to have at least 8 iterations of the kernel inner loop if possible.
    
    PiperOrigin-RevId: 285778165
    Change-Id: Id8826153464b4622677f14da8b0b1b0b60a98ecf

commit 4ad5238778e3f919e9fe899eea3137b1dab81d80
Author: River Riddle <riverriddle@google.com>
Date:   Fri Dec 13 14:52:39 2019 -0800

    Refactor various canonicalization patterns as in-place folds.
    
    This is more efficient, and allows for these to fire in more situations: e.g. createOrFold, DialectConversion, etc.
    
    PiperOrigin-RevId: 285476837
    Change-Id: I510ef7dde07df380bd81dbe59942175a871826e0

commit 1aee1190ab9a4c80f281d2a2595bbc5ecc7ff342
Author: River Riddle <riverriddle@google.com>
Date:   Tue Dec 10 13:20:50 2019 -0800

    Refactor the various operand/result/type iterators to use indexed_accessor_range.
    
    This has several benefits:
    * The implementation is much cleaner and more efficient.
    * The ranges now have support for many useful operations: operator[], slice, drop_front, size, etc.
    * Value ranges can now directly query a range for their types via 'getTypes()': e.g:
       void foo(Operation::operand_range operands) {
         auto operandTypes = operands.getTypes();
       }
    
    PiperOrigin-RevId: 284834912
    Change-Id: If6e8954c8a934b378b4090e701b3fd9cc43f704e

commit 902e8f4bd534d5b440c90f2c42dd126ca90a8fd6
Author: River Riddle <riverriddle@google.com>
Date:   Mon Dec 9 15:24:10 2019 -0800

    Refactor the Block support classes.
    
    Each of the support classes for Block are now moved into a new header BlockSupport.h. The successor iterator class is also reimplemented as an indexed_accessor_range. This makes the class more efficient, and expands on its available functionality.
    
    PiperOrigin-RevId: 284646792
    Change-Id: Ib1a4385a415e3127e506c7bb1141648be97b1890

commit 8a2ad877e9100934ed3f4725424dce86185b6b36
Author: Jian Li <jianlijianli@google.com>
Date:   Fri Dec 6 11:46:24 2019 -0800

    Add quantization support to all variants of LSTM.
    - peephole coefficients are quantized to 16 bits symmetric. Int16 is used because the calculation is a 16x16 vector vector elementwise multiplication.
    - without projection, hidden tensor becomes the output and reuses the quantization parameters of the output
    - with layer normalization, the gate matmul uses intermediate result as output; without layer normalization, gate matmul is fed into activation directly so 2^(-12) is the output scale.
    
    PiperOrigin-RevId: 284230412
    Change-Id: Ibfa66dc6fc2614de28b0ba92e8fb2d42a338aab4

commit a034a3ad800056d8838309c84bc1ea8d9a58cd3e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Dec 6 10:08:15 2019 -0800

    Add conversions of GPU func with memory attributions to LLVM/NVVM
    
    GPU functions use memory attributions, a combination of Op attributes and
    region arguments, to specify function-wide buffers placed in workgroup or
    private memory spaces. Introduce a lowering pattern for GPU functions to be
    converted to LLVM functions taking into account memory attributions. Workgroup
    attributions get transformed into module-level globals with unique names
    derived from function names. Private attributions get converted into
    llvm.allocas inside the function body. In both cases, we inject at the
    beginning of the function the IR that obtains the raw pointer to the data and
    populates a MemRef descriptor based on the MemRef type of buffer, making
    attributions compose with the rest of the MemRef lowering and transparent for
    use with std.load and std.store. While using raw pointers instead of
    descriptors might have been more efficient, it is better implemented as a
    canonicalization or a separate transformation so that non-attribution memrefs
    could also benefit from it.
    
    PiperOrigin-RevId: 284208396
    Change-Id: Ie330774f90df0c459325fd7146d81cb46da98b39

commit dc4aab853cd9883c0ff2cd181307a303abf8bca7
Author: Taylor Robie <taylorrobie@google.com>
Date:   Mon Nov 25 17:28:35 2019 -0800

    Reduce keras eager overhead by 20% by more efficiently managing the trainable state of Model sub-layers.
    
    In the Keras API, Model.compile() freezes the trainable state for a model and its sub layers. This is relevant for applications such as GANs where the the trainability of a layer depends on the model using it. However for simpler training loops, iterating over all layers to set a property and then iterating over them to set it back after is somewhat expensive. So by only updating the trainable state when it has changed (which it almost never does for normal supervised training) significantly decreases the per-step overhead.
    
    PiperOrigin-RevId: 282467340
    Change-Id: I55ea13df0abb2c2f3785fcd581dfd969e9778ac8

commit 5d2c4009987a6b33a683d6cbf1ade560e1f5b59b
Author: Derek Murray <mrry@google.com>
Date:   Mon Nov 25 14:30:31 2019 -0800

    [tf.data] Use a more efficient source in MapBenchmark.
    
    Currently, we use `Dataset.from_tensors(0).repeat(None)` as the source of dummy
    data in MapBenchmark. Consuming this dataset involves repeatedly creating and
    destroying a TensorDataset iterator, and the cost of doing this dominates the
    MapDataset execution time (for small chains). Switching to a
    `Dataset.range(num_elements)` has much lower overhead per element.
    
    From running the benchmark on my workstation (with increased num_elements), the
    execution time of "MapBenchmark.chain_length_1_single_threaded" reduces by more
    than 50%:
    
    Before:
    
    entry {
      name: "MapBenchmark.chain_length_1_single_threaded"
      iters: 5
      wall_time: 1.71906495094e-06
      extras {
        key: "num_elements"
        value {
          double_value: 1000000.0
        }
      }
    }
    
    After:
    
    entry {
      name: "MapBenchmark.chain_length_1_single_threaded"
      iters: 5
      wall_time: 8.35798978806e-07
      extras {
        key: "num_elements"
        value {
          double_value: 1000000.0
        }
      }
    }
    
    PiperOrigin-RevId: 282434351
    Change-Id: I7f726be65af35c5401c8c9a54c0b84bf27b9fa0f

commit a858c19b0c10a89639a4897155952d8c3bbd26de
Author: Elena Zhelezina <elena.zhelezina@arm.com>
Date:   Wed Sep 18 17:56:26 2019 +0100

    New implementation of TANH/Sigmoid 16-bit activation functions using LUT.
    
    We think the reference functions for 16-bit activation are too complex for
    efficient implementation on resource constrained platforms and propose
    to replace the functions with a lookup table approach as follows:
    
    First rescale the input data to fixed range of -10.7 to +10.7
    Use a 256-entry lookup table for Sigmoid followed by linear interpolation
    to efficiently derive the result.
    
    The Sigmoid LUT table is used for the TANH function,
    because tanh(x) = 2*sigmoid(2*x) -1 and we take into account the symmetry is taked.
    
    The proposed reference kernel implementation also has higher accuracy than the existing one.
    On the current functions we measure a difference of up to 6.3 for sigmoid and 11.7 for
    tanh in quantized units compared to the floating point reference implementation over
    the 16-bit input range (representing -8.0 to +8.0). For the implementation of this patch we
    see the error reduced to less than 1.5 quantized units compared to floating point
    reference for both tanh and sigmoid.
    
    Change-Id: I4d1406928db65740c1750c9cd7bfffab30771419

commit 09659f8eea1a58ac22d74a34e15a4aae2557088c
Author: Derek Murray <mrry@google.com>
Date:   Wed Nov 20 11:23:43 2019 -0800

    Add ability for Executor subclasses to override the synchronous Run() method.
    
    This change enables executors that have a more efficient synchronous implementation to use that implementation instead of requiring a callback to be created, and performing atomic operations to notify completion. This change also updates DirectSession to invoke the synchronous Run() method when the session is configured to run the graph on the caller thread (e.g. by setting `ConfigProto.inter_op_parallelism_threads = -1`).
    
    PiperOrigin-RevId: 281562211
    Change-Id: I2e8a32a440a82a32516555be8b2f64b373c21289

commit 7ef97d3b0a6734f02f4418d683f2d9a3322bff5d
Author: River Riddle <riverriddle@google.com>
Date:   Tue Nov 12 13:03:39 2019 -0800

    NFC: Change DictionaryAttr::get(StringRef) to use binary search instead of a linear scan.
    
    The elements of a DictionaryAttr are guaranteed to be sorted by name, so we can use a more efficient lookup when searching for an attribute.
    
    PiperOrigin-RevId: 280035488
    Change-Id: I6ad9f499bd0f8a26c3993b8498c29e124c56c0af

commit 14225a9f2cf9033ec54ce9bd2462b0dec34f21fe
Author: River Riddle <riverriddle@google.com>
Date:   Tue Nov 12 13:03:39 2019 -0800

    NFC: Change DictionaryAttr::get(StringRef) to use binary search instead of a linear scan.
    
    The elements of a DictionaryAttr are guaranteed to be sorted by name, so we can use a more efficient lookup when searching for an attribute.
    
    PiperOrigin-RevId: 280035488

commit c3973c78f03c50d8514c14c2866ab30e708aea24
Author: Gaurav Jain <gjn@google.com>
Date:   Sat Oct 12 01:24:25 2019 -0700

    Rename internal_convert_to_tensor for performance
    
    Calling ops.internal_convert_to_tensor is more efficient than calling
    ops.convert_to_tensor due to skipping the deprecated_argument_lookup and
    also less python function calling overhead. We thus swap these functions
    names so we can optimize most code paths.
    
    PiperOrigin-RevId: 274321742

commit d3e4201098ce96873f5d5c2688435965d886b018
Author: Shanqing Cai <cais@google.com>
Date:   Thu Oct 3 06:41:48 2019 -0700

    [tfdbg] Add Python implementation of DebugEventsWriter
    
    - Based on pybind11 wrapping of the C++ implementation.
    - Add `WriteSerializedNonExecutionDebugEvent` and `WriteSerializedExecutionDebugEvent` to support efficient writing of protos at the interface between Python and C++
    - Change the two cyclic buffer deques to hold strings. This is also to support efficient writing at the interface between Python and C++.
    
    PiperOrigin-RevId: 272649638

commit 8a2d062f08cefee2b792aa0a6aade9074d48131d
Author: Allen Lavoie <allenl@google.com>
Date:   Mon Sep 23 13:45:51 2019 -0700

    Forwardprop: enforce nesting between gradient tapes and forward accumulators
    
    Previously only accumulators were prevented from watching jvps from "outer" accumulators, but GradientTape otherwise ends up watching all jvps for tensors/variables it's watching, meaning forward-over-back isn't efficient.
    
    This doesn't really fix the issue for functions, where there's a hacky "is the tape watching any jvps" flag which only works efficiently if there's a single GradientTape. Once we generate function gradients from tapes this change should apply to them too.
    
    PiperOrigin-RevId: 270751233

commit c5fe7ab411cc40cd9c8c44d3962f825b956500e0
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Mon Sep 23 11:24:19 2019 -0700

    Avoid extra space when setting attributes on import
    
    interleaveComma adds space along with the comma, which requires that the space
    either be stripped or split with string variant used. This is both inefficient
    and easy to forget and end up with spaces in names.
    
    PiperOrigin-RevId: 270720594

commit a8fcbb6c9d8f53e786b708bff86c253224596b4d
Author: Tiezhen WANG <wangtz@google.com>
Date:   Tue Sep 17 18:59:00 2019 -0700

    TFLM: support logistic (sigmoid) floating path.
    
    The current impl for quantization scheme is going to be very inefficient without opdata suppoert. They will be supported in the following work.
    
    PiperOrigin-RevId: 269704427

commit e0e1efbe0811aa0913ad8400c532b33c76425427
Author: Gaurav Jain <gjn@google.com>
Date:   Thu Sep 5 15:15:06 2019 -0700

    Add incompatible_shape_error attribute to equal op
    
    When tensor equality is enabled, if there is an incompatible shape we
    currently throw and exception. Ideally we'd like to return False when
    calling __eq__ and True when calling __ne__. We thus modify the Equal
    and NotEqual ops to return a boolean upon a shape incompatibility. Due
    to this change the shape inference logic needs to be changed to either
    return a scalar bool if the shapes are incompatible, or else return an
    unknown shape to allow for either a boolean Tensor or scalar to be
    returned.
    
    Note the behavior of tf.math.equal & tf.math.not_equal is unchanged as
    they both use optimistic shape inference logic when dealing with unknown
    dimensions which allows for more efficient graphs rather than inserting
    Rank operations.
    
    This distinction between __eq__ & tf.math.equal is also found in numpy
    and as a result the tf.debugging.assert_equal and
    tf.debugging.assert_none_equal APIs needed to be change to utilize the
    numpy operations.
    
    PiperOrigin-RevId: 267466043

commit 4eabecafdd121ec6272d91a69b23b47c08fc373c
Author: Derek Murray <mrry@google.com>
Date:   Mon Aug 26 10:48:36 2019 -0700

    Implement `Operation._get_attr_{bool,int}()` for use in op wrappers.
    
    Generated op wrappers reflect on the attrs of the created `Operation` in order to record a gradient. The default `Operation.get_attr()` method involves protobuf serialization and deserialization. For a small type, such as a boolean, it is much more efficient to invoke the specialized `TF_OperationGetAttrBool()` directly.
    
    PiperOrigin-RevId: 265491188

commit a41d8a5506f78f820f0dcab5ed786d665ba7688f
Author: Xiao Yu <fishx@google.com>
Date:   Fri Aug 23 14:18:39 2019 -0700

    Make NodeNameMapping::Uniquify more efficient.
    
    PiperOrigin-RevId: 265133264

commit 25aca37ed6cf5649b94aa884082cfe7f6eccf434
Author: Derek Murray <mrry@google.com>
Date:   Thu Aug 22 09:44:21 2019 -0700

    Change `hasattr` in `Graph.get_collection()` to use try/except.
    
    The current implementation of `hasattr` in Python 2.7 and 3.6 calls `getattr` under the hood. Since we subsequently make a second call to get the attribute, it is more efficient to "ask for forgiveness than permission" in this case.
    
    PiperOrigin-RevId: 264855401

commit 439c0df6f0202e3644c41a17c12d2505870b44f8
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 21 03:27:04 2019 -0700

    Introduce `indices_are_sorted` attribute for gather/scatter HLO
    
    If the attribute is set to `true` then the backend can assume that the
    gather/scatter indices supplied by the user are sorted what should enable
    the generation of more efficient code.
    
    If the attribute is set to `true` but the indices are not sorted then
    the behavior is implementation defined.
    
    PiperOrigin-RevId: 264574093

commit 2917ad1d24cc39a228eac5248ce5d56aafe73f2d
Author: Sergei Lebedev <slebedev@google.com>
Date:   Fri Aug 16 09:23:23 2019 -0700

    Ported tf_stack.extract_stack to C++
    
    This change also removes extract_stack_file_and_line because extract_stack
    is now efficient enough to be used ~everywhere.
    
    def f(n, callback):
      if n == 0:
        return callback()
      else:
        return f(n - 1, callback)
    
    >>> %timeit f(16, lambda: None)  # Baseline
    1000000 loops, best of 3: 1.09 ?s per loop
    
    Before:
    
    >>> %timeit f(16, tf_stack.extract_stack_file_and_line)
    100000 loops, best of 3: 17.7 ?s per loop
    >>> %timeit f(16, tf_stack.extract_stack)
    100000 loops, best of 3: 18.5 ?s per loop
    
    After:
    
    >>> %timeit f(16, tf_stack.extract_stack)
    100000 loops, best of 3: 3.89 ?s per loop
    
    PiperOrigin-RevId: 263784818

commit 679babcb89537e0df8763ca09bd1b7680d959878
Author: Bixia Zheng <bixia@google.com>
Date:   Tue Aug 13 11:38:18 2019 -0700

    Rewrote the implementation of the complex sqrt and rsqrt methods.
    
    The old implementations of sqrt and rsqrt just called the pow function, which
    was very inefficient.
    
    PiperOrigin-RevId: 263180636

commit ef11a4763452c84cfa7494c713a976475c5d9cca
Author: Blake Hechtman <blakehechtman@google.com>
Date:   Wed Aug 7 10:26:14 2019 -0700

    [XLA:CLIENT] Add a dense version of TorchGather since that is sometimes more efficient.
    
    PiperOrigin-RevId: 262163732

commit 464ff69893984e9b10736b93b37d95c0a8db9d89
Author: Lei Zhang <antiagainst@google.com>
Date:   Tue Aug 6 07:02:35 2019 -0700

    [spirv] Provide decorations in batch for op construction
    
    Instead of setting the attributes for decorations one by one
    after constructing the op, this CL changes to attach all
    the attributes for decorations to the attribute vector for
    constructing the op. This should be simpler and more
    efficient.
    
    PiperOrigin-RevId: 261905578

commit fabfe4cd17f1b7ee799a0776e9c03fc20b92b96b
Author: Lei Zhang <antiagainst@google.com>
Date:   Tue Aug 6 07:02:35 2019 -0700

    [spirv] Provide decorations in batch for op construction
    
    Instead of setting the attributes for decorations one by one
    after constructing the op, this CL changes to attach all
    the attributes for decorations to the attribute vector for
    constructing the op. This should be simpler and more
    efficient.
    
    PiperOrigin-RevId: 261905578

commit e6f75bb0e0b41bb67250b5ce98af8f5caf645f5f
Author: Taylor Robie <taylorrobie@google.com>
Date:   Wed Jul 31 16:40:12 2019 -0700

    Make traceback collection more efficient by decreasing the number of thread local lookups.
    
    PiperOrigin-RevId: 261023893

commit 5883d3a4dc0034172d38cffbb116af8810d9fedb
Author: Allen Lavoie <allenl@google.com>
Date:   Thu Jul 18 17:40:05 2019 -0700

    Fix forwardprop of a function inside a function
    
    We were recording the function call twice when graph building, and the first recording didn't have a gradient function registered. This change explicitly pauses the tape so we record once with record_operation, like we do executing eagerly.
    
    Adds a benchmark for forwardprop of a function call wrapped in a function. I'm planning to do exactly this to make it efficient from eager, so it's worth tracking (looks like it's fine at the moment, inlining/pruning makes it fast).
    
    (All reported in examples/second)
    Function benchmarks:
    forwardprop_in_defun_matmul_100_by_784_CPU           2846
    forwardprop_in_defun_matmul_256_by_2096_CPU           486
    forwardprop_in_defun_of_defun_matmul_100_by_784_CPU  2950
    forwardprop_in_defun_of_defun_matmul_256_by_2096_CPU  483
    
    Eager benchmarks:
    forwardprop_matmul_100_by_784_CPU                    1548
    forwardprop_matmul_256_by_2096_CPU                    430
    forwardprop_of_defun_matmul_100_by_784_CPU           1006
    forwardprop_of_defun_matmul_256_by_2096_CPU           183
    
    PiperOrigin-RevId: 258879462

commit 4499d732014ef7fec5fd1fb418dc46751b4fb60d
Author: Derek Murray <mrry@google.com>
Date:   Wed Jul 17 11:14:10 2019 -0700

    Avoid copying a FunctionDef in CapturedFunction.
    
    The recently added `FunctionLibraryDefinition::CopyFunctionDefFrom()` method performs a more efficient shallow copy.
    
    PiperOrigin-RevId: 258604819

commit 498df5d8c4a48eca93e74d43fbaaad8004d4a04a
Author: Taylor Robie <taylorrobie@google.com>
Date:   Wed Jul 17 09:20:58 2019 -0700

    Update keras v2 optimizers to reuse coefficients which are shared across all updates, which reduces the total number of ops created by between 5% (for simple optimizers such as SGD and Adagrad) and 25% (for complicated optimizers such as Adam and NAdam). Separate copies are made for each device and dtype.
    
    The effect of this change on run time is fairly minimal since Grappler is expected to consolidate most of these ops; however it does improve graph construction time.
    
    PiperOrigin-RevId: 258581998

commit 4acec889a11490b3d6903bba0604f013b1f60e1c
Author: Alex Zinenko <zinenko@google.com>
Date:   Mon Jul 15 06:40:07 2019 -0700

    Introduce loop coalescing utility and a simple pass
    
    Multiple (perfectly) nested loops with independent bounds can be combined into
    a single loop and than subdivided into blocks of arbitrary size for load
    balancing or more efficient parallelism exploitation.  However, MLIR wants to
    preserve the multi-dimensional multi-loop structure at higher levels of
    abstraction. Introduce a transformation that coalesces nested loops with
    independent bounds so that they can be further subdivided by tiling.
    
    PiperOrigin-RevId: 258151016

commit acab6a20512f29be48b8252db00a388d2c57c29c
Author: Allen Lavoie <allenl@google.com>
Date:   Fri Jul 12 11:02:54 2019 -0700

    Use a tf.function to more efficiently compute op jvps
    
    Allows the unused backward computation to be pruned out.
    
    Does not change custom_gradient or function forward-mode computations.
    
    Some fiddling with the memory checking on the unit tests, since tf.function creates persistent symbolic Tensors the first time it's called. This means we need to do warmup runs and ignore Tensors allocated there.
    
    Forward gradients still need some followups after this:
      - Functions should have a special-cased forward function so that they're efficient when executing eagerly.
      - Watching variables on an accumulator should be possible
    
    After those the remaining case is custom gradients, which are probably fine to leave as they are for now (they work, they're just a bit less efficient than they could be if the user provided a jvp or told us the code was safe to wrap in a tf.function).
    
    From //tensorflow/python/eager:benchmarks_test:
    
    benchmark_forwardprop_in_defun_matmul_256_by_2096_CPU 487 examples/second no change
    benchmark_forwardprop_matmul_256_by_2096_CPU          406 examples/second 1.6x speedup
    benchmark_forwardprop_of_defun_matmul_256_by_2096_CPU 176 examples/second no change
    
    benchmark_forwardprop_in_defun_matmul_100_by_784_CPU 2872 examples/second no change
    benchmark_forwardprop_matmul_100_by_784_CPU          1766 examples/second 1.4x speedup
    benchmark_forwardprop_of_defun_matmul_100_by_784_CPU  909 examples/second no change
    
    PiperOrigin-RevId: 257832992

commit 572db7bf76c4f5caea9db1136bfc6532c22b0b38
Author: George Karpenkov <cheshire@google.com>
Date:   Fri Jun 21 10:10:18 2019 -0700

    [XLA] Provide a more generic infrastructure to pass may-alias hints
    
    Currently, may-alias hints can be passed from the compiler to the buffer assignment
    through the FusionCanShareFunction callback.
    This has a number of disadvantages:
    
     - Only aliasing inside fusion is supported. It's often desirable to alias
       inside custom calls, which have efficient inout parameter implementations.
    
     - FusionCanShareFunction returns a boolean, which requires an all-or-nothing
       approach: either the function returns whether aliasing is permitted,
       or the function is not passed at all.
    
    This change replaces FusionCanShareFunction with MayAliasHint callback,
    which solves these problems:
    
     - MayAliasHint returns absl::optional<bool>, which allows the callback to say
       "I don't know", delegating to the default behavior.
    
     - The callback is called outside of fusion, allowing aliasing inside non-fused
       instructions.
    
    PiperOrigin-RevId: 254418380

commit 8efc1dadae1f4b4472122a2923abafb075483204
Author: Mehdi Amini <aminim@google.com>
Date:   Tue Jun 18 09:38:16 2019 -0700

    Add a setAttrList() method on mlir::Operation
    
    This is an efficient method to copy attributes from one operation to
    another.
    
    PiperOrigin-RevId: 253806004

commit fd6e9f41c073511cedafe323619d1e0c71348aa4
Author: River Riddle <riverriddle@google.com>
Date:   Thu Jun 13 13:22:32 2019 -0700

    Add several utility 'getValues<T>' functions to DenseElementsAttr that return ranges as opposed to filling a SmallVector. This is much more efficient for the general case and allows for avoiding constructing APInt/APFloat/Attribute when possible.
    
    PiperOrigin-RevId: 253092550

commit 222df6844f8621706049bfd9f7e16cbadf72e8ed
Author: Anudhyan Boral <anudhyan@google.com>
Date:   Tue Jun 18 00:13:59 2019 -0700

    Register GPU kernels for EinsumOp.
    
    This change is mostly boilerplate to make the nvcc compiler happy. Most of the heavy lifting in EinsumOp is done by BatchMatmul/Reduction functors and Eigen Tensor Ops which already have GPU kernels defined for them. This lets us easily obtain an efficient implementation on the GPU.
    
    PiperOrigin-RevId: 253736113

commit b9fefcb525fd25629f8909c4c8efc24da84a52c9
Author: Stella Laurenzo <laurenzo@google.com>
Date:   Wed May 15 15:04:20 2019 -0700

        Upstreaming Quantizer tool (part 2).
    
        This adds some additional core types and utilities, notably the constraint analysis graph (CAG) structures, associated metadata and configuration policy object base class.
    
        The CAG is not particularly memory efficient as it stands now. I had started some work to turn it into a form that could be better managed by a bump pointer allocator but abandoned that for now in favor of having something that does semantically what I was going for as a starting point.
    
    --
    
    PiperOrigin-RevId: 248413133

commit a0077aff0be3aeec9df388677a07f988155a2f50
Author: Bixia Zheng <bixia@google.com>
Date:   Wed May 15 13:45:00 2019 -0700

    [XLA:CPU/GPU] Adjust fusion heuristic to allow the fusing of Philox HLO
    expansion.
    
    Change the factor used by IsFusedIrEmitterInefficient from 8 to 15.
    
    PiperOrigin-RevId: 248396671

commit 802aa09f9eef556b3cfa943bdc7afe4b24694ff3
Author: Eugene Zhulenev <ezhulenev@google.com>
Date:   Fri May 3 15:55:22 2019 -0700

    Use partial packets for coefficient finalization in gemm_pack_colmajor
    
    PiperOrigin-RevId: 246588955

commit eb03daf8c03cc5c7737afaa1123347976cc1eb35
Author: Sergei Lebedev <slebedev@google.com>
Date:   Thu Apr 25 13:40:54 2019 -0700

    Removed _keras_mask from EagerTensor
    
    It does not have to always be part of an EagerTensor and could instead
    be stored in a __dict__.
    
    Note that as a side-effect
    * an EagerTensor with a _keras_mask always has a materialized __dict__ and
      consumes ~280 bytes more;
    * EagerTensor._keras_mask lookup is slightly less efficient.
    
    PiperOrigin-RevId: 245298840

commit 144412e1d2236d873dea271a96cc507c79959c07
Author: Benoit Jacob <benoitjacob@google.com>
Date:   Wed Apr 24 07:20:10 2019 -0700

    Introduce a CpuBackendContext class, to be passed to any runtime
    op implementation on CPU that may need a context object (e.g.
    for an optimized GEMM implementation, or to get a thread-pool).
    So far we had been either passing backend-specific objects
    (such as gemmlowp::GemmContext) entrenching usage of specific
    libraries (gemmlowp), or we had been omitting to pass any such
    object, which was also in a way entrenching usage of specific
    libraries not using such context objects (e.g. Eigen for GEMM).
    
    This CL migrates for now only some GEMM-using ops to taking a
    CpuBackendContext, that is: FullyConnected, LstmCell, Conv.
    A subsequent CL will migrate other ops.
    
    Once all ops take a CpuBackendContext, we will be able to switch
    their implementation backends much more easily and incrementally.
    In particular, this is one of the main steps to enable the
    integration of ruy as one implementation path.
    
    The main difficulty in this CL was how to perform this change
    of signature of the runtime ops functions, without breaking
    dependents. Indeed, these runtime ops are directly used by much
    more code than just the TFLite interpreter, whence the existing
    legacy_* ops files where we have been conserving legacy signatures
    as we changed the signatures used by TFLite.
    
    To limit this difficulty to only the optimized ops functions, this
    CL changes reference ops to no longer take any context argument.
    They didn't use it anyway. Dropping that now removes the hassle
    of doing the gemmlowp -> cpu_backend transition in reference code.
    
    In optimized ops, we make such a gemmlowp -> cpu_backend wholesale
    transition for the aforementioned op types (other ops to follow),
    and for compatibility we keep old gemmlowp signatures in
    legacy_* files. This results in a substantial amount of lines added
    in legacy_*, as we choose to keep that old code around as an independent
    implementation rather than as just calling into the new signatures,
    as we have done in the past for other legacy functions. The rationale
    is that there is no alternative that will be regression-free for all
    legacy users (so even if we tolerate incurring some regression,
    alternatives are at a minimum difficult to pass through regression
    tests). Indeed:
     - for legacy float paths not taking any context argument, making
       such paths call into new paths using a cpu_backend_context would
       have required either:  creating short-lived cpu_backend_context
       objects, which would be inefficient with new implementations
       strongly relying on such context objects being reused (like ruy);
       using a global singleton guarded by a lock, which would be
       inefficient in multithreaded use cases (most Android JNI users
       implicitly are; some applications use explicit multithreading
       around NN inference); or using a thread-local cpu_backend_context
       which would have surprising overhead/footprint/behavior in
       implicitly-multithreaded use cases such as again Android JNI.
     - for legacy 8bit paths taking a gemmlowp context argument, the
       situation was more tractable, we could have allowed constructing
       cpu_backend_context objects wrapping around an existing
       gemmlowp_context. However, that would still have had the disadvantage
       of forcing to keep gemmlowp code in the new cpu_backend_context
       code, negating some of the binary-size improvements that we
       are otherwise hoping to get from a ruy transition.
    
    PiperOrigin-RevId: 245039802

commit 44bed497bd1c4e1c7cd09147a394b2ab4ef85ec8
Author: Youlong Cheng <ylc@google.com>
Date:   Mon Apr 22 18:17:14 2019 -0700

    Build efficient all-reduce ring for TPU model parallelism.
    
    For non-model parallelism case, TF2XLA bridge reorders the replica ids to build an efficient all-reduce ring.
    For model parallelism case, we disabled this reordering for correctness since we don't want to mess up user's input pipeline or weight shading, etc (see go/tpu-ids).
    
    This guarantees the correctness but it sacrifices the performance, advanced model parallelism users(for example MeshTensorFlow) chose to build the efficient ring by themselves.
    
    With this cl, we are going to move the ring build logic to device_assignment. This usually happens at the beginning of TF graph constructing, user will know how we map the replica id to physical coordinate and build the input-pipeline accordingly.
    
    PiperOrigin-RevId: 244773805

commit 4c540c1b8eec589f370f10c0fa197fcb31554fde
Author: James Keeling <jtkeeling@google.com>
Date:   Fri Apr 12 09:33:23 2019 -0700

    Stop using tf_stack.convert_stack in registry.py
    
    Stack details can be found by calling tf_stack.extract_stack. Additional info (for example the line contents) can then be found by calling tf_stack.convert_stack on the output. However the code in registry.py was doing this despite only needing the output from extract_stack. This is inefficient, as convert_stack requires calling stat on source code files, which can be very expensive.
    
    This change:
    1) Just uses extract_stack, without convert_stack
    2) Adds a limit to the extract_stack call
    3) Fixes a rare bug where the location tag was set to a string rather than a tuple when the stack is not available. Note that this never happens in normal Python usage, but can happen when other languages bind to Python (for example, in external R bindings).
    
    PiperOrigin-RevId: 243278293

commit 8bfa8d2c1227162f9dbaf5135c8c9d5a80e6eed2
Author: James Keeling <jtkeeling@google.com>
Date:   Fri Apr 12 09:25:57 2019 -0700

    Use tf_stack in tf_decorator.py.
    
    The implementation of extract_stack in tf_stack is more efficient than the built-in one, because it does not stat source code files unnecessarily. I add a limit argument to allow the callsite to remain the same.
    
    Here are some timings in a colab. Note that the real-world performance improvement will probably be larger, as more files will need to be accessed and they are likely to be on a slower filesystem.
    BEFORE: 10000 loops, best of 3: 117 ?s per loop
    AFTER: 100000 loops, best of 3: 4.43 ?s per loop
    PiperOrigin-RevId: 243277147

commit 34fd2a5e9bcdb40957ece90fec46a37e6e9248b2
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 8 04:54:48 2019 -0700

    Fix crash when forget_layer_norm_coefficients tensor has no value
    
    PiperOrigin-RevId: 242442133

commit 6bd6a4d057dbf2f40f11f12c57b2107184f9b2b8
Author: Lei Zhang <antiagainst@google.com>
Date:   Wed Mar 20 09:01:58 2019 -0700

    Change getBroadcastedShape() to return result shape via parameter
    
    This is a more efficient way than returning SmallVector directly.
    
    PiperOrigin-RevId: 239407024

commit 889b8aae707d1322f44fc77284704d22687b02aa
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Tue Jan 22 13:58:52 2019 -0800

    Allocate private/local buffers for slices accurately during fusion
    
    - the size of the private memref created for the slice should be based on
      the memref region accessed at the depth at which the slice is being
      materialized, i.e., symbolic in the outer IVs up until that depth, as opposed
      to the region accessed based on the entire domain.
    
    - leads to a significant contraction of the temporary / intermediate memref
      whenever the memref isn't reduced to a single scalar (through store fwd'ing).
    
    Other changes
    
    - update to promoteIfSingleIteration - avoid introducing unnecessary identity
      map affine_apply from IV; makes it much easier to write and read test cases
      and pass output for all passes that use promoteIfSingleIteration; loop-fusion
      test cases become much simpler
    
    - fix replaceAllMemrefUsesWith bug that was exposed by the above update -
      'domInstFilter' could be one of the ops erased due to a memref replacement in
      it.
    
    - fix getConstantBoundOnDimSize bug: a division by the coefficient of the identifier was
      missing (the latter need not always be 1); add lbFloorDivisors output argument
    
    - rename getBoundingConstantSizeAndShape -> getConstantBoundingSizeAndShape
    
    PiperOrigin-RevId: 230405218

commit 46be3eaf583feb1dfda4a2fb46ddb57b3c90dcd0
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Thu Dec 13 10:47:09 2018 -0800

    FlatAffineConstraints - complete TODOs: add method to remove duplicate /
    trivially redundant constraints. Update projectOut to eliminate identifiers in
    a more efficient order. Fix b/120801118.
    
    - add method to remove duplicate / trivially redundant constraints from
      FlatAffineConstraints (use a hashing-based approach with DenseSet)
    - update projectOut to eliminate identifiers in a more efficient order
    
    (A sequence of affine_apply's like this (from a real use case) finally exposed
    the lack of the above trivial/low hanging simplifications).
    
      for %ii = 0 to 64 {
        for %jj = 0 to 9 {
          %a0 = affine_apply (d0, d1) -> (d0 * (9 * 1024) + d1 * 128) (%ii, %jj)
          %a1 = affine_apply (d0) ->
            (d0 floordiv (2 * 3 * 3 * 128 * 128),
            (d0 mod 294912) floordiv (3 * 3 * 128 * 128),
            (((d0 mod 294912) mod 147456) floordiv 1152) floordiv 8,
            (((d0 mod 294912) mod 147456) mod 1152) floordiv 384,
            ((((d0 mod 294912) mod 147456) mod 1152) mod 384) floordiv 128,
            (((((d0 mod 294912) mod 147456) mod 1152) mod 384) mod 128)
              floordiv 128) (%a0)
          %v0 = load %in[%a1#0, %a1#1, %a1#3, %a1#4, %a1#2, %a1#5]
            : memref<2x2x3x3x16x1xi32>
        }
      }
    
    - update FlatAffineConstraints::print to print number of constraints.
    
    PiperOrigin-RevId: 225397480

commit 3c6933d9bc6abc5d6066b84c35fe96092fb4cf26
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Tue Oct 30 13:45:10 2018 -0700

    FlatAffineConstraints API update - additional methods
    
    - add methods addConstantLowerBound, addConstantUpperBound, setIdToConstant,
      addDimsForMap
    - update coefficient storage to use numReservedCols * rows instead of numCols *
      rows (makes the code simpler/natural; reduces movement of data when new
      columns are added, eliminates movement of data when columns are added to the
      end).
    
    (addDimsForMap is tested in the child CL on memref bound checking: cl/219000460)
    
    PiperOrigin-RevId: 219358376

commit ea5c3dc837e49032c6fd19c4e1266cc61c7ef834
Author: Chris Lattner <clattner@google.com>
Date:   Tue Aug 21 08:42:19 2018 -0700

    Finish support for function attributes, and improve lots of things:
     - Have the parser rewrite forward references to their resolved values at the
       end of parsing.
     - Implement verifier support for detecting malformed function attrs.
     - Add efficient query for (in general, recursive) attributes to tell if they
       contain a function.
    
    As part of this, improve other general infrastructure:
     - Implement support for verifying OperationStmt's in ml functions, refactoring
       and generalizing support for operations in the verifier.
     - Refactor location handling code in mlir-opt to have the non-error expecting
       form of mlir-opt invocations to report error locations precisely.
     - Fix parser to detect verifier failures and report them through errorReporter
       instead of printing the error and crashing.
    
    This regresses the location info for verifier errors in the parser that were
    previously ascribed to the function.  This will get resolved in future patches
    by adding support for function attributes, which we can use to manage location
    information.
    
    PiperOrigin-RevId: 209600980

commit c1faf6658e1b74700b159645f64f95befeaa0195
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Thu Jul 19 14:08:50 2018 -0700

    Simplify affine binary op expression class hierarchy
    
    - Drop sub-classing of affine binary op expressions.
    - Drop affine expr op kind sub. Represent it as multiply by -1 and add. This
      will also be in line with the math form when we'll need to represent a system of
      linear equalities/inequalities: the negative number goes into the coefficient
      of an affine form. (For eg. x_1 + (-1)*x_2 + 3*x_3 + (-2) >= 0). The folding
      simplification will transparently deal with multiplying the -1 with any other
      constants. This also means we won't need to simplify a multiply expression
      like in x_1 + (-2)*x_2 to a subtract expression (x_1 - 2*x_2) for
      canonicalization/uniquing.
    - When we print the IR, we will still pretty print to a subtract when possible.
    
    PiperOrigin-RevId: 205298958

commit 6027fdf21d7f623286d831a88a9e32af63b215d4
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Mar 12 09:18:48 2019 -0700

    Add python wrapper for xla::Einsum in tf2xla
    
    Using xla::Einsum is more efficient in some cases as it dosn't do
    any unnecessary reshapes.
    
    PiperOrigin-RevId: 238029298

commit 517112e77fb68d164fb67a62ad57baadc6a20bc4
Author: Justin Lebar <jlebar@google.com>
Date:   Mon Feb 25 15:08:22 2019 -0800

    [XLA:GPU] Enhance for-loop analysis.
    
    XLA:GPU's "for-loop" analysis looks at `while` loops and tries to determine
    whether they run a constant number of times.  If so, the loop is emitted as a
    "ForThunk", which can be run more efficiently on the GPU than the more general
    WhileThunk.
    
    A problem with our for-loop analysis is that it runs very late in the pass
    pipeline, after fusion, layout-assignment, copy-insertion, etc.  At this point
    it's challenging to pattern-match the HLO to figure out whether or not a loop
    is a bona fide `for` loop.  We can try to brute-force the loop count, but that
    only works for relatively small loops.
    
    This patch makes two changes:
    
     - Moves `for` loop matching to a separate pass, run before layout assignment
       or fusion.  The loop count is stored in a backend-config on the while
       instruction.
    
     - Adds pattern-matching machinery for loop counts.
    
    PiperOrigin-RevId: 235610452

commit 398fce03079f77d0933f941cba3de080a3116859
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Feb 15 12:05:22 2019 -0800

    Add a Euclidean norm reduction kernel. This implements a fused sqrt(reduce_sum(x * conj(x))) kernels for CPU (using Eigen) and GPU (using CUB), which is more efficient than the composite implementation at the TF level. It will also be easier to avoid the issue of producing NaNs in the gradient at the origin.
    
    Adds tf.math.reduce_euclidian_norm() Python interface to call the fused reduction kernel directly.
    
    Gradients will be added in a followup change.
    
    PiperOrigin-RevId: 234188431

commit 7b37024e464c400dd8065373f1c3d8792ed5f42b
Author: Justin Lebar <jlebar@google.com>
Date:   Thu Jan 31 18:45:52 2019 -0800

    [XLA] Fix erf for f16 inputs, and improve precision in f32.
    
    Switch to using the f32 implementations.  Previously we were using the f64
    implementation with all constants truncated down to f32.
    
    Part of the problem is that it was computing
    
      erf(x) = x * polynomial1(x^2) / polynomial2(x^2)
    
    and assuming that we had enough precision that neither of the polynomials would
    overflow.  On f16, polynomial2 would overflow to inf even for quite reasonable
    values of x (e.g. 0.79), thus causing the result to be 0 incorrectly.
    
    This may reduce precision for f64, but that's a trade-off we're willing to make
    (especially since we were using f32 coefficients *anyway*).
    
    erf and erfc also now call each other when their inputs are out of range.
    
    Relevant to #25052.
    
    PiperOrigin-RevId: 231896451

commit 91ffe999b88e665fa4c6e6899cb8170cbd6fccb8
Author: Lukas Geiger <lukas.geiger94@gmail.com>
Date:   Mon Jan 28 14:05:00 2019 +0100

    Use efficient squared_difference instead of square(diff)

commit 9b91ea70e84501d0e264d783d54907bac8cca92b
Author: Sergio Guadarrama <sguada@google.com>
Date:   Sat Jan 26 12:43:32 2019 -0800

    Use more efficient squared_difference instead of square(diff)
    
    PiperOrigin-RevId: 231064313

commit 57d4745d24195699f93d1674171a03345269d2c1
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Jan 9 12:10:02 2019 -0800

    Compute reshape permutation statically.
    
    Aside from presumably being more efficient generally, this enables using the routines in this file inside of XLA. (which currently throws an error
    `Input 0 to InvertPermutation operator must be a compile-time constant.`)
    
    PiperOrigin-RevId: 228563007

commit 106b3c183546d2f4bde8c209ef9d01ba0fb2904b
Author: Jiri Simsa <jsimsa@google.com>
Date:   Mon Jan 7 14:55:46 2019 -0800

    [tf.data] Implementation of a "standalone" C++ API that encapsulates TensorFlow runtime internals. The new API facilitates efficient execution of a dataset input pipeline (represented as a GraphDef) in C++.
    
    PiperOrigin-RevId: 228241484

commit 9585116b80c985a790fb21fe7eb00def7916d092
Author: Eugene Zhulenev <ezhulenev@google.com>
Date:   Wed Dec 26 10:43:22 2018 -0800

    Add GraphTopologyView to efficiently traverse node-to-node connections.
    + Remove SimpleGraphView from topological sorting.
    
    PiperOrigin-RevId: 226932668

commit 350791003de42dbb17c53474a677b108f473b0ba
Author: Dan Moldovan <mdan@google.com>
Date:   Wed Dec 12 11:52:20 2018 -0800

    Reduce the cost of serializing ConversionOptions to code, by using a more efficient inspect.util.getqualifiedname, reducing its max_depth and falling back to caching the value in the namespace. The latter step makes it more difficult to run the generated code afterwards, but it should in turn speed up the conversion process. This also adds an extra check to tf_decorator to improve robustness.
    
    PiperOrigin-RevId: 225226256

commit 7fa9d6a1f2d5916f3873ea38ed59c69af4c54e70
Author: Derek Murray <mrry@google.com>
Date:   Tue Dec 4 08:52:57 2018 -0800

    Make `TensorBuffer::data()` non-virtual and move the pointer into the base class.
    
    All existing `TensorBuffer` subclasses already store a pointer to
    their buffer. Accessing that pointer by calling a virtual method is
    inefficient. We currently generate the following instruction sequence
    at the callsite (when compiling for x86_64 with a recent version of Clang):
    
    1dd002:         mov    (%rdi),%rax                 tensor.h:655
    1dd005:         callq  *0x10(%rax)                 tensor.h:655
    
    ...and the following implementation for `Buffer::data()`:
    
    236520:         mov    0x10(%rdi),%rax             tensor.h:888
    236524:         retq                               tensor.h:888
    
    With this change, we generate a single `mov` instruction inline at the call
    site, and avoid any branching.
    
    PiperOrigin-RevId: 223985477

commit 411cc508e1a63d648855014f0912663e780a0ff9
Author: Derek Murray <mrry@google.com>
Date:   Tue Nov 27 10:48:57 2018 -0800

    Optimize accesses to the "begin" and "end" tensors in `ValidateStridedSliceOp()`.
    
    1. Hoist the call to `Tensor::flat<T>()` on the begin and end tensors out of the loop over dimensions. This avoids revalidating the tensor type, shape, and alignment once per dimension.
    2. Use `Tensor::vec<T>()` instead of `Tensor::flat<T>()` because we have already checked that the corresponding input tensors are vectors, and the vector codepath is more efficient.
    
    PiperOrigin-RevId: 223017951

commit 2e902b354bcea0d7eb1319de2beeaf603c7d5ee5
Author: Igor Ganichev <iga@google.com>
Date:   Thu Nov 15 13:25:33 2018 -0800

    Support attributes on tf.function calls
    
    While FunctionDef has an OpDef that can contain attribute
    specification for each function, we don't use per function
    attribute specificaton at the moment. Instead we have just two
    attributes "executor_type" and "config" shared by all functions.
    These attributes are declared in PartitionedCall.
    
    This CL makes regular functions calls (not going through
    PartitionedCall) have the same two attributes. It is done
    by hardcoding them in eager/attr_builder. This is a bit hacky
    but quick and efficient. A cleaner alternative could be to have
    TF_GraphToFunction always add these attributes to OpDef of every
    FunctionDef it builds. Hardcoding these attributes in C API
    instead of letting users specify them from Python should be fine
    because they are consumed by FunctionLibraryRuntime.
    
    PiperOrigin-RevId: 221678560

commit ee61c166bb984935caa71053fe765ac9a9a724fc
Author: Dimitris Vardoulakis <dimvar@google.com>
Date:   Tue Nov 13 10:45:31 2018 -0800

    [TF:XLA] New HLO pass that detects a pattern of AllReduce and CrossReplicaSum and rewrites it, to use an efficient CrossReplicaSum implementation that fully utilizes the interconnect bandwidth.
    
    PiperOrigin-RevId: 221293415

commit 366dd0eabccbf5bf968c16cb985e79efffdf098a
Author: Derek Murray <mrry@google.com>
Date:   Tue Nov 6 07:36:30 2018 -0800

    Add a more efficient constructor for scalar `Tensor` objects in host memory.
    
    [tf.data] Optimize the creation of tensors in `tf.data.Dataset.range()`.
    
    This change improves the range benchmark from 148.7 ns/element to 122.4 ns/element.
    
    PiperOrigin-RevId: 220279090

commit e72c9ebe78a119715541f40ea99b1a8c89639968
Author: Todd Wang <toddwang@gmail.com>
Date:   Wed Oct 24 17:46:03 2018 -0700

    1.12.0-rc2 cherry-pick request: Various XLA scatter improvements. (#23235)
    
    * [XLA] Update Tf2Xla bridge to use Scatter HLO.
    
    PiperOrigin-RevId: 215687800
    
    * [XLA:GPU] Add an implementation of scatter for GPU
    
    This simple has a kernel that runs on every element of the updates tensor,
    figure out the right indices to perform the update, and applies it with an
    atomic operation.
    
    Currently we emit a CAS for plain (i.e. non-add) updates, which is inefficient.
    Also TuplePointsToAnalysis doesn't know that it should alias the operand and
    output buffers of a scatter, which would avoid a copy.
    
    PiperOrigin-RevId: 216412467
    
    * [XLA] Allow scatter to share the operand buffer with the output
    
    This avoids a copy.
    
    PiperOrigin-RevId: 216437329
    
    * [XLA:GPU] Elide the SequentialThunk when emitting scatter with no copy
    
    We have a 1-element thunk sequence if we're not copying. That's still two
    thunks and hlo profiling gets confused if it sees two thunks for the same
    instruction and one of them claims to be the whole instruction.
    
    PiperOrigin-RevId: 216448063
    
    * [XLA:GPU] Allow input fusion into scatter
    
    We fuse everything into the scatter now, and emit two kernels. The first kernel
    fills the output buffer with the computation fused into the scatter operand.
    The second kernel is a regular scatter, which also contains the fused
    operations from the updates and scatter_indices inputs.
    
    PiperOrigin-RevId: 216624225
    
    * [XLA:GPU] Adding a test case for Scatter where GPU implementation fails.
    
    PiperOrigin-RevId: 216798034
    
    * [XLA:GPU] Fix scatter oob check computation
    
    This was comparing the index after adding it to the window, and then comparing
    against the window dimension. This means that the bounds check was only correct
    for the first element of a window. Instead compare the scatter index, which is
    the same for all elements of a window.
    
    PiperOrigin-RevId: 216921512
    
    * [XLA:GPU] Elide tuple roots of the entry computation
    
    The tuple buffer is never read, so stop emitting code to fill it. A typical
    root tuple consists of a H2D memcpy and a host callback, both of which are
    somewhat slow.
    
    This helps tiny models and inference benchmarks, where the host/device syncs
    can be a significant part of the runtime of the entire computation.
    
    PiperOrigin-RevId: 216968475

commit 5d9a7fdf4f02c2db487a03e7ad2d520f8847c4e3
Author: Benjamin Kramer <kramerb@google.com>
Date:   Tue Oct 9 13:32:24 2018 -0700

    [XLA:GPU] Add an implementation of scatter for GPU
    
    This simple has a kernel that runs on every element of the updates tensor,
    figure out the right indices to perform the update, and applies it with an
    atomic operation.
    
    Currently we emit a CAS for plain (i.e. non-add) updates, which is inefficient.
    Also TuplePointsToAnalysis doesn't know that it should alias the operand and
    output buffers of a scatter, which would avoid a copy.
    
    PiperOrigin-RevId: 216412467

commit 23a88ec5e913ba7086a9aef57875447ccf96e4b5
Author: Blake Hechtman <blakehechtman@google.com>
Date:   Thu Sep 20 15:42:23 2018 -0700

    It is more computationally efficient to represent resize bilinear as a
    depthwise convolution instead of a full convolution now that it exists in XLA.
    
    PiperOrigin-RevId: 213896333

commit 76a5936cd283d9a32c89635577b2da9c8e46785b
Author: Derek Murray <mrry@google.com>
Date:   Thu Sep 6 14:13:56 2018 -0700

    Enable unused "_Arg" nodes to be pruned from a function body.
    
    Previously, because "_Arg" nodes are considered to be "stateful", these nodes were unconditionally included in the seed set of nodes for pruning a function body. Since an "_Arg" node has no visible side effect, we can safely prune these, which makes small projection functions (like `lambda x, y: y`) more efficient.
    
    PiperOrigin-RevId: 211867380

commit 680e1754b49362858cda8fd6cea52e1cc4c41e6b
Author: Derek Murray <mrry@google.com>
Date:   Wed Sep 5 17:25:13 2018 -0700

    Deprecate `tf.train.input_producer()` and related APIs.
    
    These APIs are based on queue runners, which have been deprecated and will be removed in TensorFlow 2.0. They have been replaced with `tf.data.Dataset`, which provides a more efficient version of the same functionality.
    
    PiperOrigin-RevId: 211727844

commit ebf6d259fd4c57114c17646e40fdcfa4a1472972
Author: Derek Murray <mrry@google.com>
Date:   Wed Sep 5 15:15:20 2018 -0700

    Deprecate `tf.ReaderBase` and related APIs.
    
    These APIs are based on queue runners, which have been deprecated and will be removed in TensorFlow 2.0. They have been replaced with `tf.data.Dataset`, which provides a more efficient version of the same functionality.
    
    PiperOrigin-RevId: 211708268

commit a3c1ccd1da64040eeb139a0c6c1fc34ae46d7290
Author: Derek Murray <mrry@google.com>
Date:   Wed Sep 5 14:33:37 2018 -0700

    Deprecate `tf.train.batch()` and related APIs.
    
    These APIs are based on queue runners, which have been deprecated and will be removed in TensorFlow 2.0. They have been replaced with `tf.data.Dataset`, which provides a more efficient version of the same functionality.
    
    PiperOrigin-RevId: 211700442

commit d29eb6d1c9d1e4b2f601864f53878674f219fe6f
Author: Allen Lavoie <allenl@google.com>
Date:   Tue Sep 4 14:03:08 2018 -0700

    Remove reference cycles when constructing distribution objects
    
    self -> _parameters -> self cycles were creating work for Python's garbage collector in training loops, where Distribution objects may be created repeatedly when executing eagerly. This CL just fixes that narrow memory issue; I'm not convinced dict(locals()) is super efficient, so we may want to follow up on that for performance.
    
    Adds a few unit tests tests with run_test_in_graph_and_eager_modes(assert_no_eager_garbage=True). It'd be nice to expand this coverage over time.
    
    Includes a small test_util simplification to support this (TFP tests don't like reset_default_graph for some reason). Testing for cycles in the TFP repo will need to wait on the Normal changes from the TF repo syncing.
    
    PiperOrigin-RevId: 211520394

commit f689cb82869b75a4bf1374fe96ef8ffa9d87acc9
Author: Derek Murray <mrry@google.com>
Date:   Thu Aug 30 13:00:08 2018 -0700

    Deprecate `tf.train.QueueRunner` and related APIs.
    
    Queue runners will be removed in TensorFlow 2.0. They have been replaced with `tf.data` input pipelines, which provide a more efficient version of the same functionality.
    
    PiperOrigin-RevId: 210964268

commit 11f1dab4fce23c73073e32cda910a2a1a87c394f
Author: Alexandre Passos <apassos@google.com>
Date:   Thu Aug 30 09:49:11 2018 -0700

    StridedSlice gradient more efficient in tfe.
    
    PiperOrigin-RevId: 210927458

commit 729e39b1a4f0f7a6b3e35a04bf8bbba5e921862b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 29 20:23:07 2018 -0700

    Improve the GPU memory use discipline of CollectiveReduce.
    
    GPU memory allocation can be done in one of two modes: efficient (but
    complex and therefore somewhat risky) or conservative (simpler, but less
    efficient).  The main difference is that 'efficient' allocation allows
    the same memory area to be allocated to mutiple independent uses
    simultaenously, when it should be the case that those uses will in
    fact be serial and thus temporally disjoint, while 'conservative'
    allocation will always obey the invarient that one piece of memory is
    allocated to at most one use at any point in time.
    
    If GPUDevice::RequiresRecordingAccessedTensors() returns false, then
    the TF runtime uses efficient memory allocation for GPU ops.  That is, GPU
    ops are nominally synchronous and their tensor Ref's are deleted
    immediately after the ops returns although really the corresponding GPU
    kernel is only guaranteed to have been enqueued on the compute stream
    and may not have yet begin execution.
    
    If RequiresRecordingAccessedTensors() returns true, then conservative
    memory allocation is used, i.e. Refs on the tensors accessed by a GPU op
    are held until the corresponding kernel is guaranteed to have completed
    execution and no part of the op will touch them again.
    
    Efficient GPU memory allocation should be safe when the following criteria
    are all met:
    
    1. All GPU kernels are executed serially on a single compute stream.
    2. All GPU kernel outputs and temp buffers are allocated by
       the GPU Op in the executor thread in which it is originally called.
    3. Any read of a GPU tensor computed by a GPU kernel that is not
       by another kernel on that same GPU first synchronizes on
       the compute stream that produced it.
    4. Any read by a GPU kernel of a value that was not produced by another
       GPU kernel first synchronizes on the entity that produced it,
       e.g. a copy stream.
    5. All direct allocations of GPU memory that are not for kernel outputs
       or temp buffers are conservative in duration.
    6. Any use of directly allocated GPU memory that is not part of a kernel
       execution first synchronizes on the compute stream to ensure that
       any prior granted uses of the same region have expired before this new use.
    
    These conditions together should be sufficient for safety, and
    correspond to established practice, though it may be possible to
    contrive other sets of rules that are also sufficient.
    
    Collective Ops for GPUs are unusual in that they are async (as TF
    Ops) and they can directly allocate GPU memory in CPU threads that are
    asynchronous to the launching executor thread.  This CL corrects a
    couple of subtle misuse errors related to conditions 2 and 6.
    
    PiperOrigin-RevId: 210841522

commit 59483d0f695436d7bda688cd2ee8f1212071e41a
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 15 17:11:59 2018 -0700

    The code for splitting constants to ensure single user had a side effect of deleting constants which did not have any users. It also made an extra clone when number of users reduced to one. While it did not affect correctness, but it's cleaner and more efficient to address these issues.
    
    PiperOrigin-RevId: 208910596

commit 12eb80cb9b4b51631a7cdfc9fce476a8b2ea225b
Author: Rohan Jain <rohanj@google.com>
Date:   Fri Aug 10 17:05:25 2018 -0700

    Speeding up MultiDeviceIterator by more efficient locking. We create a background thread that tries to keep a host side buffer for each device full. When a GetNext request comes in, we return from the buffer if available or else we schedule a callback to be called when the background thread eventually fetches an element for it.
    
    PiperOrigin-RevId: 208292329

commit 4d58bfb2324dbc647b294824e29ba9e75eece3ba
Author: Sanjoy Das <sanjoy@google.com>
Date:   Fri Aug 3 15:21:37 2018 -0700

    [XLA:CPU] Migrate aot/runtine.{h,cc} to xla_compiled_cpu_function.{h,cc}
    
    As a follow-on cleanup for cl/206980796 ("Overhaul XLA:CPU's calling
    convention.") I want to introduce a BufferInfo class that encapsulates whether a
    buffer is a constant, an entry parameter or a temp without using the fragile
    "size < 0" scheme I have today.  To do this efficiently I need a place to put
    the BufferInfo class that will be visible to MallocContiguousBuffers.  Instead
    of creating (what seemed to me) an odd layering with BufferInfo in aot/runtime.h
    I decided to pull in the runtime into xla_compiled_cpu_function since that's the
    only user.
    
    PiperOrigin-RevId: 207333245

commit 2c442d26f36a0f167685fd31b9ecdb4e290c2b29
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jul 16 17:13:42 2018 -0700

    Implement digamma for XLA
    
    Compute the Lgamma function using Lanczos' approximation from "A Precision Approximation of the Gamma Function". SIAM Journal on Numerical Analysis series B. Vol. 1:
    digamma(z + 1) = log(t(z)) + A'(z) / A(z) - kLanczosGamma / t(z)
    t(z) = z + kLanczosGamma + 1/2
    A(z) = kBaseLanczosCoeff + sigma(k = 1, n, kLanczosCoefficients[i] / (z + k))
    A'(z) = sigma(k = 1, n, kLanczosCoefficients[i] / (z + k) / (z + k))
    
    PiperOrigin-RevId: 204834091

commit 3618796b3bee7bd0eb06425d6a069d28b95e6f42
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jul 16 15:14:39 2018 -0700

    Implement lgamma for XLA
    Add support for Real and Imag for real floating point types.
    
    Compute the Lgamma function using Lanczos' approximation from "A Precision Approximation of the Gamma Function". SIAM Journal on Numerical Analysis series B. Vol. 1:
    lgamma(z + 1) = (log(2) + log(pi)) / 2 + (z + 1/2) * log(t(z)) - t(z) + A(z)
    t(z) = z + kLanczosGamma + 1/2
    A(z) = kBaseLanczosCoeff + sigma(k = 1, n, kLanczosCoefficients[i] / (z + k))
    
    PiperOrigin-RevId: 204815805

commit cead016fe01e8f0ff732a080203b29990d475c98
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Jul 4 03:06:18 2018 -0700

    Minor performance improvement for ComputeReachability
    
    We have two versions of HloReachabilityMap::SetReachabilityToUnion where
    one of them is slightly more efficient by not returning if the
    reachability have been changed or not. This change migrates the users
    not caring about the return value to the faster variant.
    
    PiperOrigin-RevId: 203256625

commit aac398674301532d0b6cb9a767325fcd03839df5
Author: Yuanzhong Xu <yuanzx@google.com>
Date:   Wed Jun 27 15:05:11 2018 -0700

    [XLA] Use subshape pointers as map keys in BFloat16Propagation.
    
    Using simple keys is more efficient.
    
    PiperOrigin-RevId: 202377039

commit 394add116efd9839e1be5342c085e6510c265687
Author: Yuanzhong Xu <yuanzx@google.com>
Date:   Wed Jun 27 15:05:11 2018 -0700

    [XLA] Use subshape pointers as map keys in BFloat16Propagation.
    
    Using simple keys is more efficient.
    
    PiperOrigin-RevId: 202377039

commit b62d76d932f93ff324d2598cdeac792fa61135a4
Author: Benjamin Kramer <kramerb@google.com>
Date:   Fri Jun 15 11:10:03 2018 -0700

    [XLA] Switch PostOrder accessors to use std::vector instead of std::list.
    
    std::list is just hilariously inefficient and the postorder list creation has
    been rewritten not to not depend on splicing anymore so there's no need for the
    list. While there remove the old unused postorder list creation code.
    PiperOrigin-RevId: 200743677

commit e1347ba769b98e260d36e895be2963af35c88d18
Author: Kay Zhu <kayzhu@google.com>
Date:   Wed May 9 13:07:35 2018 -0700

    [XLA] First step in adding Literal slice classes, to improve interface safety
    and prepare for enabling more efficient interfacing from Tensor to Literal to
    reduce host to device latency.
    
    More specically:
    * Introducing a new LiteralBase abstract base class that contains all immutable
    methods of from the old Literal class.
    
    * Introducing a subclass LiteralSlice to replace original LiteralView class.
    LiteralSlice class is read-only and does not own Shape nor any buffer through
    the Pieces. Change a number of callers to use LiteralSlice directly.
    
    * Change Literal class to explicitly own the underlying Shape as well as owning
    the underlying buffer via Piece.
    
    * Conversion from Literal to LiteralSlice is now done via an implicit
    conversion constructor instead of inheritance.
    
    * Decouple ShapeTree from Literal classes.
    
    * Use copy-and-swap for assignment constructors.
    
    * Other minor cleanups.
    
    PiperOrigin-RevId: 196016576

commit ab02bce13e49fbd001c6db241d213dc2886a5792
Author: Alexandre Passos <apassos@google.com>
Date:   Mon Apr 30 14:34:01 2018 -0700

    Do not cast int64 to int32 in keras embedding lookups.
    
    Often when working on the GPU with tf int64s are more efficient as int32s will
    be copied back and forth to the host quite a bit.
    
    PiperOrigin-RevId: 194846629

commit f0df6701d01954073e912f24f7c983de4f091a1e
Author: joel-shor <joelshor@google.com>
Date:   Fri Apr 20 14:01:02 2018 +0300

    [tf.data] Check in a strictly faster rejection resampling
    transformation.
    
    This transformation is faster because it rejects fewer data. This
    is done by occasionally sampling from the original data distribution
    in an efficient way.
    
    Tested:
    bazel test :resample_test

commit a77dcb5e56dbbbcc3383cb0b39cd79dd88135635
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Apr 13 15:23:08 2018 -0700

    Add broadcasting to all LinearOperators.
    
    This will broadcast in cases where batch shapes are not equal (but tries to determine statically if this is the case). The broadcasting is not as efficient as doing the broadcast in C++, but makes for the API to at least be completely broadcastable.
    
    PiperOrigin-RevId: 192832919

commit 5a6d5a1b3982e59548340422f831ada6f5d5e0be
Author: Francois Chollet <fchollet@google.com>
Date:   Thu Apr 12 19:01:10 2018 -0700

    Enable efficient feeding of symbolic tensors to placeholders in the Keras backend.
    
    PiperOrigin-RevId: 192707345

commit 5d81b72b9c1a7edd1a84c13b1dc753b310545e56
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 2 11:35:00 2018 -0700

    [XLA] Redesign: improve error handling:
    - For every op creation method, check whether there's any existing error, if so, don't do anything and returns an empty op. To do this efficiently, make the NoteErrorOrReturn method accept a lambda, and check first_error_ before evaluating the lambda.
    - Return error instead of TF_CHECK_RET, because the second seems to always print ERROR logs.
    
    PiperOrigin-RevId: 191322082

commit 97731cb122f53552bd15351e046a256f78cca444
Author: Skye Wanderman-Milne <skyewm@google.com>
Date:   Fri Mar 30 14:56:08 2018 -0700

    Raise exception in SWIG on bad TF_Status from C API.
    
    This change provides an alternative mechanism to
    tf.raise_exception_on_not_ok_status(), which is inefficient and
    error-prone (people often use the status multiple times in the with
    block, but it's only checked when the context manager exits). Instead,
    it uses SWIG to automatically raise an exception when a C API method
    fails. Note that this removes the status argument from affected
    methods.
    
    For now, I've only applied this typemap to C API methods. It would be
    good to expand this to all uses of raise_exception_on_not_ok_status.
    
    PiperOrigin-RevId: 191121016

commit 9a7a63aff142658db6d54027815a54a267be808a
Author: Justin Lebar <jlebar@google.com>
Date:   Thu Mar 29 10:30:31 2018 -0700

    [XLA:GPU] Assume that tuple sub-buffers are available at runtime.
    
    Previously we assumed this was not the case, and allowed front-ends to
    pass in a pointer to tuple without also passing in pointers to
    sub-buffers.
    
    This mostly worked: Whenever we wanted a tuple sub-buffer, we'd just
    chase the tuple's pointers in our emitted kernel.
    
    But this doesn't work if we ever need a pointer to that sub-buffer on
    the host.  Which we do if e.g. the sub-buffer is an input to a cudnn
    call.
    
    There are various ways to make this work, but by far the simplest and
    most efficient is simply to specify away this problem, and say that the
    front-end *must* give us all the pointers we want.  This is what the
    earlier change, "Assert that all buffers and sub-buffers passed to XLA
    have an explicit pointer" did.
    
    This change adds a testcase and lets us skip some pointer chasing when
    we have a tuple whose sub-buffers are known statically.
    
    PiperOrigin-RevId: 190949743

commit 50e1888fa89bce621e988a92ede3dc362e37b248
Author: Justin Lebar <jlebar@google.com>
Date:   Tue Mar 27 17:16:31 2018 -0700

    [XLA] Assert that all buffers and sub-buffers passed to XLA have an explicit pointer.
    
    In the past, we allowed sub-buffers to be null if the top-level tuple
    was non-null.
    
    This doesn't actually work well on the GPU: For ops that are implemented
    using cudnn or cublas, we have to have a pointer to the sub-buffer on
    the host in order to make the call.  Retrieving it from the GPU in an
    efficient manner is complicated, and the best we can come up with isn't
    all that efficient (fundamentally having to pull data down from the GPU
    blocks the ability of the CPU to "run ahead" of the GPU).
    
    Since TF wasn't making use of our flexibility *anyway*, we add the
    requirement that XLA be given non-null pointers to all sub-buffers.
    
    Changes to the XLA:GPU backend to take advantage of this will come
    separately.
    
    PiperOrigin-RevId: 190700021

commit 53b2181ea5cff054d40c583f05da942a9a56a283
Author: Jeremy Lau <lauj@google.com>
Date:   Tue Feb 27 15:32:16 2018 -0800

    Make RecentRequestIds more efficient.
    
    PiperOrigin-RevId: 187242940

commit 785ee91c0d4f9a0e8eafa082f725c25ae134c9b3
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Feb 16 14:06:26 2018 -0800

    Optimization of quantized LSTM cell for the common case of batch size 1,
    where it needs efficient matrix*vector ("GEMV") code, but it's not
    exactly the same as the case of stand-alone fully-connected layers
    as here the output activations are 16bit-quantized.
    
    PiperOrigin-RevId: 186044068

commit 428d034227c9e7b637de0194d80cac3976a37eef
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Feb 16 13:20:13 2018 -0800

    Fix pontential issue with number of blocks launched for depthwise kernels: the number of work_elements was too small, which could return a block_count that is too small to cover all elements.
    
    We also have been ignoring the suggested thread_per_block, so were potentially launching more blocks than necessary to fill the GPU (which is inefficient, but functionally correct).
    
    Changing 'assert(false && ...' to LOG(FATAL) because it shouldn't be debug only.
    
    PiperOrigin-RevId: 186037306

commit 972fa89023f8f27948321c388fa3f1f7857833c3
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Feb 15 12:50:03 2018 -0800

    Add auc_with_confidence_intervals
    
    This method computes the AUC and corresponding confidence intervals using an efficient algorithm.
    
    PiperOrigin-RevId: 185884228

commit 5dd585abb84c5d13af0017f78741e29505f7b5f7
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Feb 15 11:34:10 2018 -0800

    Make conversions from ShapedBuffer <-> ScopedShapedBuffer efficient by
    moving memory ownership instead of copying.
    
    PiperOrigin-RevId: 185871648

commit 1baac7862739525351d25202800dc04e8ec3868b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Feb 8 10:20:26 2018 -0800

    Make MklCpuAllocator a VisitableAllocator, instead of just an Allocator.
    This allows it to work more efficiently with RDMA networking.
    
    PiperOrigin-RevId: 185013628

commit 39010bef7f72709a87a275060878baac815744c2
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Feb 2 19:40:30 2018 -0800

    A more efficient implementation of the Op using batch operations.
    
    PiperOrigin-RevId: 184367562

commit 1699bc041e624cdaf249a80136b467743357fbfc
Author: Peter Hawkins <phawkins@google.com>
Date:   Wed Jan 31 12:28:13 2018 -0800

    [TF:XLA] Implement Acos, Asin, Atan in terms of Atan2 using half-angle formulae. This may not be the most efficient implementation but it is better than no implementation.
    
    PiperOrigin-RevId: 184029858

commit 548df15375488fc06ff663670f88734f3ece4814
Author: Derek Murray <mrry@google.com>
Date:   Tue Jan 30 13:26:51 2018 -0800

    [tf.data] Add `IteratorContext::allocator()`.
    
    This enables the various iterator implementations to use the actual allocator for the device on which they are running, rather than defaulting to `cpu_allocator()` (which is typically a plain malloc). In future, this will enable allocating iterator outputs in CUDA-pinned memory (and GPU memory).
    
    PERFORMANCE NOTE: In sessions where `ConfigProto.force_gpu_compatible == True`, this change has the effect of allocating all input pipeline tensors in CUDA-pinned memory. Previous if this flag was set, only the tensors allocated during function execution would be allocated in this space, and other tensors (e.g. the result of a `Dataset.batch()` would be allocated using `cpu_allocator()` (i.e. `malloc()`). This change should lead to more efficient communication between a host-side input pipeline and GPUs, but it may also create more pressure on the CUDA host allocator (whose default maximum size is 64GB). The "TF_CUDA_HOST_MEM_LIMIT_IN_MB" environment variable can be used to override this value.
    
    This change is a starting point for working on issue #13610.
    
    PiperOrigin-RevId: 183881907

commit dcddfdf045f06c9cfc7579bb61ac23d3a3b4a44e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jan 11 19:23:24 2018 -0800

    Improve performance of several utility functions in TensorFlow
    
    framework/types.h defines a variety of functions on DataType enums. Some of these functions are implemented by allocating arrays in the heap.  Even though DataTypeVector is a typedef for InlinedVector, it only stores 4 elements inline. Many of the vectors used in types.h/types.cc contain more than 4 elements.
    
    To make matters worse, some of these functions are called quite frequently under load, so we're wasting time allocating and copying arrays.
    
    The set of distinct DataType values is so small, however, that we can represent a set of DataType values as a bitmask, and use bit-shifts and tests instead of sequential scans of arrays.
    
    Even the functions that do not allocate, such as DataTypeCanUseMemcpy(), are needlessly inefficient (read: they use control-flow and indirect jumps when a simple table-based load would do; they are also not inlined).  These costs were significant enough that they consumed about 1.2% of CPU cycles under heavy load.
    
    The surprising cost of DataTypeCanUseMemcpy() inspired this change. I went ahead and made the change fully general, by adding a DataTypeSet type and changing all of the utility functions in framework/types.h to use it (with the exception of DataTypeAlwaysOnHost because it uses a _REF type), for the sake of generality and performance.
    
    PiperOrigin-RevId: 181695458

commit 814e4a7830b506ed26ed22b9b1bc7233d6185467
Author: Derek Murray <mrry@google.com>
Date:   Tue Jan 9 11:56:51 2018 -0800

    Add experimental `FunctionLibraryRuntime::InstantiateOptions::overlay_lib`.
    
    This option makes it possible to instantiate functions from a library
    that has been loaded separately from the runtime's own library. We
    plan to use this as part of the `tf.data` checkpoint restore process,
    which might load an iterator whose state includes functions that
    aren't present in the original graph. (This is currently achieved by
    creating an isolated `FunctionLibraryRuntime` for each function-using
    `Dataset`, but that is inefficient and prevents using features of the
    main runtime, such as cross-device function calls.)
    
    PiperOrigin-RevId: 181352217

commit 0cce4840f561bd7f8b06603e0dc1dcbf05c46a03
Author: Benoit Steiner <bsteiner@google.com>
Date:   Tue Jan 2 21:45:51 2018 -0800

    Fixed a typo that resulted in the graph being processed in reverse topological
    order. This made shape inference far less efficient than it should be in some cases.
    
    PiperOrigin-RevId: 180629882

commit d4091eec522e41093e6e10601af79c75bee14c80
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Dec 22 15:50:19 2017 -0800

    Replaces custom _lengths_to_masks function with the official, more efficient sequence_mask function that supersedes it.
    
    PiperOrigin-RevId: 179971521

commit 96f3023b6a8b154c3840776c5feff3e028860a36
Author: Derek Murray <mrry@google.com>
Date:   Wed Dec 20 20:54:25 2017 -0800

    [tf.data] Add `tf.contrib.data.parse_single_example()`.
    
    The new op is a fused implementation of the existing
    `tf.parse_single_example()`, which is more efficient when parsing a
    single Example at a time.
    
    PiperOrigin-RevId: 179768512

commit 1b4c6096e5024119dbed898ecaad63e3afd58ef0
Author: Derek Murray <mrry@google.com>
Date:   Mon Dec 11 15:39:00 2017 -0800

    [tf.data] Use a more efficient dispatch mechanism for functions in datasets.
    
    This change adds an overload of the `FunctionLibraryRuntime::Run()` method
    that allows users to pass argument and return value containers in a
    `CallFrameInterface` object, rather than using the current (and expensive for
    large arities) default `FunctionCallFrame` implementation. It also specializes
    `CapturedFunction` to use this interface.
    
    Note that the new overload currently only supports local function execution,
    and more restructuring will be required to take advantage of it in the remote
    function execution case.
    
    This change should especially benefit datasets where each element has a large
    number of components (typically when training data have many features).
    
    PiperOrigin-RevId: 178684431

commit 5d3d7fa81b87aa3c1137366f062c4f4ab9681a09
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Nov 28 10:55:32 2017 -0800

    RevBlock: memory-efficient implementation of a series of reversible residual
    layers.
    
    PiperOrigin-RevId: 177185950

commit b7a74edb5e6e134df4d66ad66b486aafd29c4ac4
Author: codrut3 <grosu.codrut@gmail.com>
Date:   Mon Nov 20 22:58:53 2017 +0200

    Use cub::ReduceByKey to count partition indices (#14665)
    
    * Use cub::ReduceByKey to count how many times each partition index appears.
    
    This implements a suggestion by @ekelsen. It replaces the
    previously custom-made counting method and is likely more
    efficient.
    
    * Remove CubReduceAdd and use instead cub::Sum.

commit 44be285351ea465db6b4c32807fb1503c5e74531
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Nov 3 16:38:56 2017 -0700

    Don't generate ConjugateTranspose nodes for real tensors. Doing so is not an error, but makes graph rewriting optimizations slightly less efficient.
    Use dtype.is_complex instead of dtype in (dtypes.complex64, dtypes.complex128) in a few places.
    
    PiperOrigin-RevId: 174531912

commit 913a96bccee065cbd34f4d24c70e225023c1987b
Author: Igor Ganichev <iga@google.com>
Date:   Thu Nov 2 10:57:54 2017 -0700

    Optimize tf.split for eager mode
    
    In eager mode, we know the shapes of input tensors and can use
    more efficient methods for retrieving shape and rank. This change
    reduces SPINN training time by about 1%. While 1% is not a lot, it is
    a small localized change to a very commonly used op.
    
    Also:
      - Adapt split_op_test to run in both modes
      - Decrease the number of splits in _testHugeNumberOfTensorsVariable
        from 10k to 1k. I don't see much value in having such large
        operations in a unit test. This reduces the total testing time
        of split_test_op from 40 seconds to 4.6 seconds.
      - Change TensorFlowTestCase.evaluate() to create a session if no default
        session is setup.
    PiperOrigin-RevId: 174349642

commit 06a79f5af7c861e695cfc20b7778519950aac9ba
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Oct 26 17:00:14 2017 -0700

    Move EyeFunctor to a separate file, and change it to a more efficient implementation (similar to matrix_set_diag).
    
    PiperOrigin-RevId: 173611865

commit 355e25ebcab64e833dfc987638c3e6c79d838266
Author: Benoit Steiner <bsteiner@google.com>
Date:   Tue Oct 24 19:47:46 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    ---
    Commit 9f8523640 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 173145770
    
    ---
    Commit 01b6b0638 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cut tracing memory cost
    
    PiperOrigin-RevId: 173144626
    
    ---
    Commit 5e23e0e67 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Erase cloned instructions on the fly when merging fusion nodes.
    
    This avoids the awkward situation where an RNG which is clearly eligible for fusion becomes ineligible mid-fusion because it suddenly has an extra (dead) user.
    
    PiperOrigin-RevId: 173141716
    
    ---
    Commit 1038927c0 authored by Saurabh Saxena<srbs@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add SerializeIterator op that serializes an IteratorResource into a variant tensor.
    Add DeserializeIterator op that builds IteratorResource from a variant tensor.
    Move BundleReaderWrapper and BundleWriterWrapper from dataset.h to iterator_ops.cc.
    Add generic key-value store interfaces IteratorStateReader and IteratorStateWriter for reading/writing state of iterators.
    Get rid of IteratorBundleReader and IteratorBundleWriter.
    
    PiperOrigin-RevId: 173140858
    
    ---
    Commit 57f3e529d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change
    
    PiperOrigin-RevId: 173136642
    
    ---
    Commit 0e56ffb7b authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix breakages in OSS builds
    
    See example breakages logs at:
    http://ci.tensorflow.org/job/tensorflow-cl-cpu-python3-pip/10847/console
    http://ci.tensorflow.org/job/tensorflow-cl-gpu/11008/console
    
    1. CL/172477381 added the no_oss tag to tests with oss_serial tags, which broke the logic of OSS_SERIAL tests in pip.sh and run_pip_test.sh. This CL fixes that.
    
    2. The nccl_kernels BUILD target in contrib/nccl/BUILD was missing some dependencies. This CL adds the missing ones.
    
    Fixes: #13918
    PiperOrigin-RevId: 173133914
    
    ---
    Commit 3ed049b67 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Allows calling keras layers in eager mode.
    
    PiperOrigin-RevId: 173129805
    
    ---
    Commit 4ec6f2b07 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switching contrib.summaries API to be context-manager-centric
    
    PiperOrigin-RevId: 173129793
    
    ---
    Commit 03b02ffc9 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Put Bazel mirror URLs first
    
    PiperOrigin-RevId: 173127955
    
    ---
    Commit 46ab25e4d authored by David Majnemer<majnemer@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add support for convolutions with no spatial dimensions
    
    PiperOrigin-RevId: 173126950
    
    ---
    Commit fc56349b7 authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.data] Convert dataset arguments to tensors as early as possible.
    
    This change raises a `TypeError` earlier if (for example) the `batch_size`
    argument to `Dataset.batch()` has the incorrect type.
    
    PiperOrigin-RevId: 173126678
    
    ---
    Commit 4f7503a87 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Support for registering multiple minibatches with register_fully_connected()
    
    PiperOrigin-RevId: 173121735
    
    ---
    Commit 2845bfcd6 authored by Tim Harley<tharley@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid listing all modified Enter/RefEnter nodes on INFO, use VLOG(1) instead.
    
    Leave a single, simple, message on INFO.
    
    PiperOrigin-RevId: 173121726
    
    ---
    Commit 434695921 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: _check_registration() supports multiple towers.
    
    PiperOrigin-RevId: 173115870
    
    ---
    Commit 670dddf4a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Multi-minibatch support for
    tf.contrib.kfac.fisher_blocks.FullyConnectedKFACBasicFB.
    
    PiperOrigin-RevId: 173109677
    
    ---
    Commit dc13a8e2f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix import of meta graphs with partitioned variables into a scope.
    
    Saver inspects SliceInfo to decide the variable name when creating a
    checkpoint. Before this fix even if a partitioned variable ("weights")
    was imported into a scope "a" it would still be checkpointed as ("weights")
    instead of ("a/weights") since import_scoped_meta_graph was not adjusting
    the SliceInfo.
    
    WARNING: if you use import_meta_graph on graphs with partitioned_variables WITH an import_scope argument AND then create a Saver to write/read checkpoints this change
    may break your checkpoint loading.
    PiperOrigin-RevId: 173105796
    
    ---
    Commit eea089bdb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Multi-tower support for ConvDiagonalFB.
    
    PiperOrigin-RevId: 173105412
    
    ---
    Commit 9b9cbbe2a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 Tperm type support for `Transpose` (#13909)
    
    * Add int64 Tperm type support for `Transpose`
    
    This fix adds int64 Tperm support for `Transpose`. In
    `array_ops.cc`, `Transpose` and `ConjugateTranspose`
    have been specified as accepting int32 and int64 perm
    types. However, only int32 kernels has been registered.
    
    This fix adds the int64 perm support by removing
    the constraint on Tperm, resolve the type at runtime,
    and copying the data type accordingly to correctly handle
    the int64/int32 types.
    
    Additional tests have been added as well.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 of perm in Transpose.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add namespace to hide PermutationHelper
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Enable use_gpu=True for perm type test.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * extra // namespace annotation
    
    * Adding a comment about int32 casting that should be safe.
    
    Permutations only contain values that refer to dimensions, and the maximum number of dimensions we have is 254, so an int32 is always safe here.
    
    ---
    Commit ac0004e71 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 shape support on GPU for stateless random ops. (#13908)
    
    * Add int64 shape support on GPU for stateless random ops.
    
    This fix adds int64 shape support on GPU for stateless random ops
    `StatelessRandomUniform`, `StatelessRandomNormal`, `StatelessTruncatedNormal`.
    
    The int64 shape for stateless random ops is already supported on CPU
    with int32/int64 processed properly through `MakeShape`.
    
    However, on GPU a type constraint `.TypeConstraint<int32>("T")`
    has been improperly added. Such a type constraint actually prevents
    an int64 shape type to run on GPU. (As a comparision, no type constraint
    on CPU).
    
    This fix removes the type constraint and allows int64 shape to be run on GPU.
    
    This fix also adds test cases for int64 shape support on stateless random ops.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 shape support for stateless random ops.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int32 to shape types tested.
    
    ---
    Commit 0d437c3be authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 padding support for MirrorPad (#13907)
    
    * Add int64 padding support for MirrorPad
    
    This fix adds int64 padding support for `MirrorPad`.
    In the `array_ops.cc` the `MirrorPad`/`MirrorPadGrad`
    has been specified as supporting int64 padding. The related
    kernels does not have the int64 padding registered though.
    This fix adds the int64 padding support. This fix also adds
    additional test cases for coverage.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update template for CPU and GPU support of int64 paddings.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 padding support for MirrorPad
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Put eigen header first like before, just in case.
    
    ---
    Commit 690003cc0 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add `int64` type `multiples` support for `tf.tile` (#13884)
    
    * Add `int64` type `multiples` support for `tf.tile`
    
    In the doc of `tf.tile` (tf.tile.__doc__) both `int32`
    and `int64` are supported for `multiples`. However, the kernel
    for `int64` is not registered yet.
    
    This fix adds the support of `int64` `multiples` so that the
    behavior matches the description of the docs.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update functors for int64 multiples support in `tf.tile`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update test cases for int64 of multiples in `tf.tile`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add GPU and non GPU tests
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * format with clang-format -i
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Move Tmultiples after T (as it is  auxilliary)
    
    And use `use_gpu=True`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit fd8d517b9 authored by Yunxing Dai<yunxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add tests for convolution 1D
    RELNOTES: n/a
    
    PiperOrigin-RevId: 173060283
    
    ---
    Commit 40c475b48 authored by formath<jinpengliu@163.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    add segment_reduction_ops to tf_op_files (#13901)
    
    ---
    Commit bfa4ec194 authored by Tayo Oguntebi<10927929+tayo@users.noreply.github.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Update node_def.proto comments (#13874)
    
    The device field had outdated comments.
    
    Note: We could consider adding tpu as an example here, e.g. "gpu" | "cpu" | "tpu".  Thoughts?
    ---
    Commit c9cb5a58d authored by formath<jinpengliu@163.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    protobuf lib path bug fix for benckmark on osx (#13878)
    
    ---
    Commit 1c1dad105 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 axis support for reduction ops. (#13891)
    
    * Add int64 axis support for reduction ops.
    
    This fix is a follow up to PR 13863. In PR 13863 the
    program crash is fixed if int64 axis is passed to reduction ops,
    e.g. reduce_sum, reduce_max, etc. However, 13863 does not
    process the case of int64 support, it merely fixes the crash.
    
    This fix adds the support for int64 axis of reduction ops.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for mean, prod, sum
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for min and max.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for reduce_all and reduce_any
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 axis support of reduce_any and reduce_all
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 17096081e authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Improve resize_bicubic performance by reorganizing loops (#13840)
    
    * Improve resize_bicubic performance by reorganizing loops
    
    This fix tries to address the issue raised in 13693 where
    performance of `resize_bicubic` is not on par with opencv.
    
    This fix rearranges the loops so that it is the same for
    num_channel=40 and num_channel=3:
    
    Pre-fix:
    ```
    CHANNEL=40
    opencv: 145.08ms
    tf: 314.26ms
    
    CHANNEL=3
    opencv: 11.95ms
    tf: 8.95ms
    ```
    
    Post-fix:
    ```
    CHANNEL=40
    opencv: 144.25ms
    tf: 214.55ms
    
    CHANNEL=3
    opencv: 11.78ms
    tf: 14.07ms
    ```
    
    This fix fixes 13693.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Keep special handling of `num_channels=3` for `resize_bicubic`
    
    This commit keeps special handling of `num_channels=3` for
    `resize_bicubic`:
    Without special handling:
    ```
    opencv: 11.78ms
    tf: 14.07ms
    ```
    With special handling:
    ```
    opencv: 11.74ms
    tf: 9.46ms
    ```
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Expand Benchmark test for resize_bicubic
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update from review feedback.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit b927df57f authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Update protobuf.cmake to b04e5cba356212e4e8c66c61bbe0c3a20537c5b9 (#13893)
    
    This fix tries to address the issue raised in 8187 where
    protobuf.cmake used different version as bazel.
    
    The reason for discrepancy was due to the fact that a customerized
    protobuf was needed with Windows patch. Since the patch has been
    merged in (https://github.com/google/protobuf/pull/2203),
    it makes sense to update protobuf.cmake so that the same version
    of cmake is used.
    
    This fix fixes 8187.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    ---
    Commit d1183ca6a authored by Vijay Vasudevan<vrv@google.com>
    Committed by GitHub<noreply@github.com>:
    Give each variable a unique name in accumulate_n_v2_eager_test. (#13886)
    
    ---
    Commit a69945810 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update pin for bazel-toolchains to latest version
    
    PiperOrigin-RevId: 173002530
    
    ---
    Commit 9d55c249c authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix doc in TF_CALL_ when invoked in mobile platform (#13881)
    
    * Fix doc in TF_CALL_ when defined(IS_MOBILE_PLATFORM) && !defined(__ANDROID_TYPES_FULL__)
    
    This is a small doc fix that includes bool as part of the types
    that is supported in mobile (IS_MOBILE_PLATFORM && !__ANDROID_TYPES_FULL__),
    as bool is clearly invoked in the following define.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Also add bool to android full version.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit ba49d8583 authored by Bjarke Hammersholt Roune<broune@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Slight change to reduce_test to avoid generating inf, which was triggering an inf detector unnecessarily.
    
    PiperOrigin-RevId: 172965466
    
    ---
    Commit 93e8f3c67 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding Python ApiDef overrides.
    
    PiperOrigin-RevId: 172960496
    
    ---
    Commit 0d6a2e353 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change.
    
    PiperOrigin-RevId: 172960439
    
    ---
    Commit 62df65c72 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add dtype argument to Mean and Accuracy object-oriented metrics.
    
    PiperOrigin-RevId: 172957714
    
    ---
    Commit d7409d32b authored by Simone Cirillo<my.accounts@gmx.se>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix import of spatial_softmax from tensorflow.contrib.layers (#13833)
    
    ---
    Commit df8bce63d authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix crash when `int64` axis is passed to `tf.reduce_sum` (#13863)
    
    * Fix crash when `int64` axis is passed to `tf.reduce_sum`
    
    This fix tries to fix the crash triggered by `int64` axis passed
    to `tf.reduce_sum`:
    ```
    ubuntu@ubuntu:~/tensorflow2$ (cd && python)
    Python 2.7.12 (default, Nov 19 2016, 06:48:10)
    [GCC 5.4.0 20160609] on linux2
    Type "help", "copyright", "credits" or "license" for more information.
    >>> import tensorflow as tf
    >>> v = tf.reduce_sum([1,2,3], tf.constant(0, tf.int64))
    2017-10-20 15:55:06.993430: F tensorflow/core/framework/tensor.cc:601] Check failed: dtype() == expected_dtype (9 vs. 3)
    ubuntu@ubuntu:~/tensorflow2$
    ```
    
    The issue is caused by the fact that shape inference in `common_shape_fns.cc`
    only assumes int32 without proper handling of diffent types. In `math_ops.cc`
    both int32 and int64 are mentioned.
    
    NOTE that this fix does not address the issue that int64 is not supported.
    To allow int64 axis it is more than adding a template in `ReductionOp` as the type
    of the axis seems to be decided by some other ways in Eigen.
    
    This fix merely fixed the crash so that an error message will return without
    exit from the python program "No OpKernel was registered to support Op 'Sum' with these attrs".
    
    Still, I think its worth to at least allow the program to continue in case of unsupported kernel.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update implementation with a template helper function.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 29c7b4658 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding the Stanford Tensorflow class to community resources.
    
    PiperOrigin-RevId: 172956049
    
    ---
    Commit f758b24a8 authored by Alexandre Passos<apassos@google.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Variable name for the eager test (#13873)
    
    ---
    Commit a5fe66b15 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removed some unnecessary broadcasts in binary ops where only one input needs
    broadcasting (which is a fairly common case, even in the fallback path).
    
    PiperOrigin-RevId: 172950493
    
    ---
    Commit c77090a0a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix issues where int64 crops could not be passed to batch_to_space. (#13862)
    
    * Fix issues where int64 crops could not be passed to batch_to_space.
    
    This fix tries to address the issue where int64 `crops` could
    not be passed to `batch_to_space` even though both int32 and
    int64 are specified as supported in the docs (tf.batch_to_space.__doc__)
    
    The reason is that BatchToSpace kernel puts a constraint of int32 to crops
    data types.
    
    This fix removed the constraint so that int64 `crops` could be supported.
    
    NOTE: Just removing the constraint should work and it is not necessary
    to add specification to the kernel class template, as `SubtleMustCopyFlat`
    called in the class already correctly handled both int32 and int64 cases.
    Besides, other data types (e.g., float or double) will not be passed to the
    kernel as they are guarded by the specification in `array_ops.cc`.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Also remove int64/int32 type constraints for SpaceToBatch kernels
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 crops of batch_to_space and space_to_batch
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Fix test failures.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 494837936 authored by Joshua V. Dillon<jvdillon@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make `tf.contrib.distributions` quadrature family accept a `Tensor` for
    `quadrature_grid_and_probs` argument.
    
    PiperOrigin-RevId: 172950094
    
    ---
    Commit 9c825d32c authored by Jinze Bai<baijinze1994@163.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Merge two GPU kernel launching to one in DiagOp. (#13859)
    
    ---
    Commit c0ca50a47 authored by Yan Facai (???)<facai.yan@gmail.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    ENH: add Relu6GradGrad (#13268)
    
    * ENH: add Relu6GradGrad
    
    * TST: add test case
    
    * CLN: import nn_grad
    
    * TST: add init value
    
    ---
    Commit 8ff33271e authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Dump the computation's SessionModule as part of the tf_compile rule.
    
    PiperOrigin-RevId: 172946149
    
    ---
    Commit ebcae4a5e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add streaming_precision_recall_at_equal_thresholds
    
    This helper method computes streaming tp, fp, tn, fp, precision, and recall for the user in a way that exhibits O(T + N) time and space complexity (instead of O(T * N)), where T is the number of thresholds and N is the size of the predictions tensor.
    
    Thanks to Frank Chu for the efficient algorithm!
    
    PiperOrigin-RevId: 172946073
    
    ---
    Commit ccfd9c1e5 authored by Sanjoy Das<sanjoy@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Log Hlo IR during AOT compilation
    
    PiperOrigin-RevId: 172944165
    
    ---
    Commit 985031a10 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Allows tfe.enable_eager_execution(device_policy=tfe.DEVICE_POLICY_WARN).
    
    PiperOrigin-RevId: 172943398
    
    ---
    Commit 703182d85 authored by Mingxing Tan<tanmingxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add performance guide for fused decode_and_crop_jpeg optimization.
    
    PiperOrigin-RevId: 172943116
    
    ---
    Commit 66b1f4383 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make Network compatible with eager mode. Currently it only allows to instantiate a Network in eager mode using the regular Keras API, and call it on eager tensors.
    
    PiperOrigin-RevId: 172942569
    
    ---
    Commit 41df2cec2 authored by ashankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Testing pending CL: 172939383
    
    ---
    Commit 37fd95179 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplifies capturing code in graph_callable to use recent function improvements.
    
    PiperOrigin-RevId: 172937003
    
    ---
    Commit d1e7382af authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 172924803
    
    PiperOrigin-RevId: 173347587

commit ebcae4a5e3bf5c840d73a0d90f1b5bf01a68f82c
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Oct 20 15:55:17 2017 -0700

    Add streaming_precision_recall_at_equal_thresholds
    
    This helper method computes streaming tp, fp, tn, fp, precision, and recall for the user in a way that exhibits O(T + N) time and space complexity (instead of O(T * N)), where T is the number of thresholds and N is the size of the predictions tensor.
    
    Thanks to Frank Chu for the efficient algorithm!
    
    PiperOrigin-RevId: 172946073

commit fafff08cbc3b952d60ee98914c234bb6af09b968
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Oct 20 11:57:40 2017 -0700

    Adds the k-MC2 algorithm for efficient seeding of mini batch k-means in TensorFlow.
    
    PiperOrigin-RevId: 172914154

commit e3be40d099e1c5da869b7dfaf8d5891a8c2af312
Author: Jeffrey A. Dean <jeff@google.com>
Date:   Tue Oct 10 15:36:59 2017 -0700

    Slightly rework tf.matmul to be more efficient (important for eager mode)
    
    PiperOrigin-RevId: 171745141

commit 244b8d6b0767c0fb63e58e56f58d03bd97c27822
Author: Andrew Myers <andru@cs.cornell.edu>
Date:   Fri Sep 29 16:44:17 2017 -0400

    Java API Generics Phase 2 (#11535)
    
    * Phase 1 of the proposed generic Java API.
    
    This adds new classes to represent each of the possible tensor types,
    and some scripting support for generating those classes. There is
    essentially no effect on existing classes, except that DataType is
    made slightly more efficient.
    
    All tests pass.
    
    * Addressed Asim's review.
    
    * Hoisted copyright into a separate declaration. Maybe it should go
    in a separate file?
    
    * Added private constructors to TF types and shortened their javadoc to be
    more standard.
    
    * Added more explanation about the enum relationship.
    
    * Used more-idiomatic import statement.
    
    * Rename zero column.
    
    * Removed the datatype code from tftypes.csv
    
    * Fix the default value for Double, add one for UInt8.
    
    * Got rid of 'boxed type' column in CSV file
    
    * Somehow I did not notice that TFType.java was not checked in.
    
    * Phase 2 : Tensor, Output and friends are now parameterized.
    
    * All tests now pass.
    
    * Cleaned up and added some Javadoc and made some static fields private.
    
    * Made Outputs more convenient to use.
    Improved Javadoc regarding this functionality.
    Added explicit type parameters to examples and tests to make them better models of expected practice.
    
    * Removed extra copy of method.
    
    * This change to the Android demo app should allow it to compile successfully
    
    * Backed out unnecessary but presumably harmless removal of calls to clear().
    
    * Change from Unicode times symbol to x, to be more consistent with
    the rest of the Javadoc.
    
    * Updated Constant and ConstantTest with generics.
    
    * Registered UInt8 like all the other data types.
    
    * Removed the UINT8 test because UINT8 doesn't seem to be fully supported in next
    layer down. That probably should be fixed but it's orthongonal to this change.
    
    * * Added some missing pieces so that uint8 seems now to be supported fully by the Java API,
    addressing #12797.
    * Resurrected the uint8 test case.
    * Allowed arrays of bytes to be used to construct both tensors of strings and tensors of uint8.
    * Simplified the computation of the number of dimensions of a Java object representing a tensor.
    
    * Get rid of tab characters that violate the Google Java style guide. My IDE
    was not configured correctly.
    
    * Fix javadoc nit.
    
    * Replace testUInt8 with the generic version.
    
    * Ran formatter on code.
    
    * Addressed some of Asim's comments.
    
    - implemented constant() methods in terms of each other to reduce code duplication
    - improved a spec regarding when types are checked
    - got rid of an unnecessary method that used wildcards
    
    * Back out change to comments in Operand.java
    
    * This is what things look like if we make Tensor run on DataType as much as
    possible. Only Tensor.expect() is still using class objects as a way to
    represent tensor datatypes. It can be moved off to class Tensors when Tensors
    exists, though it will not be as convenient as when it's a method of Tensor.
    
    * Fixed build errors. This is is being committed primarily so Asim can take a look at it conveniently.
    More work will be needed before merging.
    
    * - Changed from TF-prefixed types to regular Java classes, e.g. Integer instead of
    TFInt32. Deleted most classes in org.tensorflow.types, including TFType.
    - Made Tensor mostly work in terms of Class<T> since that is the user-facing
      interface.
    - Moved zeroValue() stuff off to the testfile where it belongs
    
    * Remove unnecessary run-time check.
    
    * Updated Android inference test to latest Java API changes.
    
    * Address Asim's comments (thanks!)
    
    - Removed now-gratuitous run-time type-check.
    - Fixed non-Google-styled if.
    - Reworded/fixed a few comments as requested.
    - Removed all uses of unsafe casts and @SuppressWarnings in test cases.
    - Cleaned up constant() implementations in LabelImage example.
    - Removed reference to Tensors class (next PR!)
    
    * Ran gformat on everything.
    
    * Fixed an old typo in a comment.
    Removed a couple of unnecessary casts from the example program.
    
    * Fixed the last suppressed warnings.

commit e55574f28257bdacd744dcdba86c839e661b1b2a
Author: drpngx <drpngx@users.noreply.github.com>
Date:   Fri Sep 15 19:38:25 2017 -0700

    Branch 168917534 (#13077)
    
    * Use HLO name, rather than pointer address, for profile counter name.
    
    This removes a source of nondeterminism in IR generation.
    
    PiperOrigin-RevId: 168779489
    
    * Eager gradient tape doesn't keep tensors alive.
    
    PiperOrigin-RevId: 168782341
    
    * Add missing back-quote
    
    PiperOrigin-RevId: 168785422
    
    * Add in a comment that I forgot to add to a previous commit; NFC.
    
    PiperOrigin-RevId: 168786760
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168787665
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168788051
    
    * Fix typo "comptuation" (computation)
    
    PiperOrigin-RevId: 168799777
    
    * Fix a bug in export GTFlow model to shared format with sparse float split
    
    PiperOrigin-RevId: 168802503
    
    * Add signature def utility functions for inspection of input and output types and shapes.
    
    PiperOrigin-RevId: 168820997
    
    * Apply const qualifiers whenever appropriate.
    
    PiperOrigin-RevId: 168824461
    
    * TFE: Clearer error message when enable_eager_execution is called more than once
    
    PiperOrigin-RevId: 168834147
    
    * [tf.contrib.data] Add colocation constraints between Iterator and Datasets.
    
    This restores the colocation behavior that was present when Dataset
    objects were passed as DT_RESOURCE tensors, and avoids the (currently
    not supported) case where TensorFlow may attempt to split the dataset
    pipeline across devices.
    
    PiperOrigin-RevId: 168841061
    
    * Optimize C++ kernels for the matrix_band_part op, which is used in various ops operating on triangular or banded matrices:
     * Add benchmark for matrix_band_part.
     * Implement simple optimized CUDA kernel instead of calling Eigen generator.
     * Parallelize CPU kernel for matrix_band_part.
     * Support on-the-fly transposition in the underlying functors (to be used for future QR op in followup).
    
    Benchmarks:
    
    First column is of the form {device}_{shape}_{num_lower,num_upper}
    
    Test case                        Before       After    Speedup
    cpu_(10,16,16)_(-1,-1)          5.6505e-05  6.2108e-05  -9.92%
    cpu_(10,16,16)_(-1,0)           0.00010848  0.00010908  -0.55%
    cpu_(10,16,16)_(0,-1)            0.0001055  0.00011396  -8.02%
    cpu_(10,16,16)_(2,2)              0.000108  0.00011706  -8.39%
    cpu_(10,101,101)_(-1,-1)        0.00013697  6.0558e-05 +55.79%
    cpu_(10,101,101)_(-1,0)         0.00054002  0.00017703 +67.22%
    cpu_(10,101,101)_(0,-1)         0.00051188  0.00017607 +65.60%
    cpu_(10,101,101)_(2,2)          0.00050449  0.00016904 +66.49%
    cpu_(10,256,256)_(-1,-1)        0.00032043  5.6028e-05 +82.51%
    cpu_(10,256,256)_(-1,0)           0.001335   0.0004015 +69.93%
    cpu_(10,256,256)_(0,-1)          0.0013521  0.00038862 +71.26%
    cpu_(10,256,256)_(2,2)            0.001269  0.00039959 +68.51%
    cpu_(10,1000,1000)_(-1,-1)       0.0090729  6.3419e-05 +99.30%
    cpu_(10,1000,1000)_(-1,0)          0.01712   0.0047594 +72.20%
    cpu_(10,1000,1000)_(0,-1)         0.016647   0.0046474 +72.08%
    cpu_(10,1000,1000)_(2,2)          0.012737   0.0041161 +67.68%
    cpu_(10,1024,1024)_(-1,-1)       0.0093709  5.8889e-05 +99.37%
    cpu_(10,1024,1024)_(-1,0)         0.017075   0.0051999 +69.55%
    cpu_(10,1024,1024)_(0,-1)         0.016867    0.004617 +72.63%
    cpu_(10,1024,1024)_(2,2)          0.013191    0.003759 +71.50%
    cpu_(10,2048,2048)_(-1,-1)        0.028427  6.2466e-05 +99.78%
    cpu_(10,2048,2048)_(-1,0)         0.048134    0.017642 +63.35%
    cpu_(10,2048,2048)_(0,-1)         0.048773    0.017558 +64.00%
    cpu_(10,2048,2048)_(2,2)          0.036153    0.015452 +57.26%
    cpu_(10,10,4,4)_(-1,-1)         5.8055e-05  5.8055e-05  +0.00%
    cpu_(10,10,4,4)_(-1,0)          0.00015557   0.0001564  -0.54%
    cpu_(10,10,4,4)_(0,-1)          0.00015855  0.00015199  +4.14%
    cpu_(10,10,4,4)_(2,2)           0.00016379  0.00018096 -10.48%
    cpu_(10,10,10,10)_(-1,-1)       6.0558e-05  6.0558e-05  +0.00%
    cpu_(10,10,10,10)_(-1,0)          0.000368  0.00038695  -5.15%
    cpu_(10,10,10,10)_(0,-1)        0.00036263  0.00038612  -6.48%
    cpu_(10,10,10,10)_(2,2)         0.00038648  0.00042963 -11.17%
    cpu_(10,10,16,16)_(-1,-1)       6.9022e-05  5.7578e-05 +16.58%
    cpu_(10,10,16,16)_(-1,0)         0.0005815   0.0001874 +67.77%
    cpu_(10,10,16,16)_(0,-1)        0.00059354   0.0001924 +67.58%
    cpu_(10,10,16,16)_(2,2)         0.00062239  0.00019097 +69.32%
    cpu_(10,10,101,101)_(-1,-1)     0.00014806  6.2823e-05 +57.57%
    cpu_(10,10,101,101)_(-1,0)       0.0039785  0.00078249 +80.33%
    cpu_(10,10,101,101)_(0,-1)       0.0040585  0.00076556 +81.14%
    cpu_(10,10,101,101)_(2,2)        0.0039514  0.00077307 +80.44%
    cpu_(10,10,256,256)_(-1,-1)      0.0026824  6.0558e-05 +97.74%
    cpu_(10,10,256,256)_(-1,0)        0.017269   0.0031619 +81.69%
    cpu_(10,10,256,256)_(0,-1)        0.020287   0.0030774 +84.83%
    cpu_(10,10,256,256)_(2,2)         0.011919   0.0026599 +77.68%
    cpu_(10,10,1000,1000)_(-1,-1)     0.065783  5.6982e-05 +99.91%
    cpu_(10,10,1000,1000)_(-1,0)        0.1361    0.054533 +59.93%
    cpu_(10,10,1000,1000)_(0,-1)        0.1397    0.053405 +61.77%
    cpu_(10,10,1000,1000)_(2,2)        0.10173    0.048561 +52.26%
    cpu_(10,10,1024,1024)_(-1,-1)     0.066231  7.5579e-05 +99.89%
    cpu_(10,10,1024,1024)_(-1,0)       0.13615    0.059931 +55.98%
    cpu_(10,10,1024,1024)_(0,-1)       0.13745    0.064931 +52.76%
    cpu_(10,10,1024,1024)_(2,2)        0.10493    0.054258 +48.29%
    cpu_(10,10,2048,2048)_(-1,-1)      0.23487  6.6042e-05 +99.97%
    cpu_(10,10,2048,2048)_(-1,0)       0.41014     0.24283 +40.79%
    cpu_(10,10,2048,2048)_(0,-1)       0.43621     0.26393 +39.49%
    cpu_(10,10,2048,2048)_(2,2)        0.29919     0.22302 +25.46%
    
    gpu_(10,16,16)_(-1,-1)          0.00010753  0.00010753  +0.00%
    gpu_(10,16,16)_(-1,0)           0.00011253  0.00012445 -10.59%
    gpu_(10,16,16)_(0,-1)           0.00012493  0.00013399  -7.25%
    gpu_(10,16,16)_(2,2)              0.000108  0.00011754  -8.83%
    gpu_(10,101,101)_(-1,-1)        0.00011849  8.7976e-05 +25.75%
    gpu_(10,101,101)_(-1,0)         0.00012743  0.00012243  +3.93%
    gpu_(10,101,101)_(0,-1)         0.00012958  0.00012362  +4.60%
    gpu_(10,101,101)_(2,2)          0.00011504  0.00011504  +0.00%
    gpu_(10,256,256)_(-1,-1)        0.00013447  9.7513e-05 +27.48%
    gpu_(10,256,256)_(-1,0)         0.00018752  0.00014746 +21.36%
    gpu_(10,256,256)_(0,-1)         0.00017798  0.00016904  +5.02%
    gpu_(10,256,256)_(2,2)           0.0001514  0.00013697  +9.53%
    gpu_(10,1000,1000)_(-1,-1)       0.0005095  9.8586e-05 +80.65%
    gpu_(10,1000,1000)_(-1,0)       0.00088501  0.00056589 +36.06%
    gpu_(10,1000,1000)_(0,-1)       0.00090456  0.00055242 +38.93%
    gpu_(10,1000,1000)_(2,2)        0.00080955  0.00049639 +38.68%
    gpu_(10,1024,1024)_(-1,-1)      0.00050902  9.7036e-05 +80.94%
    gpu_(10,1024,1024)_(-1,0)       0.00098789  0.00058246 +41.04%
    gpu_(10,1024,1024)_(0,-1)            0.001  0.00059545 +40.46%
    gpu_(10,1024,1024)_(2,2)        0.00082254  0.00049961 +39.26%
    gpu_(10,2048,2048)_(-1,-1)        0.001495  9.8944e-05 +93.38%
    gpu_(10,2048,2048)_(-1,0)         0.003535   0.0017736 +49.83%
    gpu_(10,2048,2048)_(0,-1)        0.0034965   0.0017921 +48.75%
    gpu_(10,2048,2048)_(2,2)         0.0027704   0.0015399 +44.41%
    gpu_(10,10,4,4)_(-1,-1)         0.00011086  9.1076e-05 +17.85%
    gpu_(10,10,4,4)_(-1,0)           0.0001235  0.00013411  -8.59%
    gpu_(10,10,4,4)_(0,-1)          0.00011849   0.0001204  -1.61%
    gpu_(10,10,4,4)_(2,2)           0.00010896  0.00013256 -21.66%
    gpu_(10,10,10,10)_(-1,-1)       0.00010657  9.5844e-05 +10.07%
    gpu_(10,10,10,10)_(-1,0)        0.00011754  0.00013602 -15.72%
    gpu_(10,10,10,10)_(0,-1)        0.00011909  0.00012004  -0.80%
    gpu_(10,10,10,10)_(2,2)         0.00013196  0.00011349 +14.00%
    gpu_(10,10,16,16)_(-1,-1)       0.00012898  0.00010705 +17.01%
    gpu_(10,10,16,16)_(-1,0)        0.00014353  0.00012338 +14.04%
    gpu_(10,10,16,16)_(0,-1)        0.00011599  0.00012493  -7.71%
    gpu_(10,10,16,16)_(2,2)         0.00011539  0.00011349  +1.65%
    gpu_(10,10,101,101)_(-1,-1)     0.00014699  0.00010252 +30.25%
    gpu_(10,10,101,101)_(-1,0)       0.0002141  0.00015497 +27.62%
    gpu_(10,10,101,101)_(0,-1)       0.0002017  0.00015843 +21.45%
    gpu_(10,10,101,101)_(2,2)       0.00018394  0.00015402 +16.27%
    gpu_(10,10,256,256)_(-1,-1)     0.00032747  9.0003e-05 +72.52%
    gpu_(10,10,256,256)_(-1,0)      0.00074494  0.00040746 +45.30%
    gpu_(10,10,256,256)_(0,-1)      0.00072503  0.00042391 +41.53%
    gpu_(10,10,256,256)_(2,2)       0.00061846  0.00038004 +38.55%
    gpu_(10,10,1000,1000)_(-1,-1)    0.0032645  0.00010896 +96.66%
    gpu_(10,10,1000,1000)_(-1,0)      0.007543   0.0038971 +48.34%
    gpu_(10,10,1000,1000)_(0,-1)      0.006058   0.0039405 +34.95%
    gpu_(10,10,1000,1000)_(2,2)       0.005198    0.003448 +33.67%
    gpu_(10,10,1024,1024)_(-1,-1)    0.0034155  9.1434e-05 +97.32%
    gpu_(10,10,1024,1024)_(-1,0)      0.007099    0.004158 +41.43%
    gpu_(10,10,1024,1024)_(0,-1)      0.006843    0.003849 +43.75%
    gpu_(10,10,1024,1024)_(2,2)       0.005506   0.0031376 +43.02%
    gpu_(10,10,2048,2048)_(-1,-1)     0.013119  0.00010097 +99.23%
    gpu_(10,10,2048,2048)_(-1,0)      0.028533    0.015175 +46.81%
    gpu_(10,10,2048,2048)_(0,-1)      0.028458    0.014926 +47.55%
    gpu_(10,10,2048,2048)_(2,2)       0.022175    0.011797 +46.80%
    
    PiperOrigin-RevId: 168849471
    
    * * dataset_ops.read_batch_features() now discards keys for keyed Dataset.
    * dataset_ops.read_batch_features() ignores unnecessary repeat() when num_repeat == 1.
    
    PiperOrigin-RevId: 168855155
    
    * Migrate TFGAN eval to opensource.
    
    PiperOrigin-RevId: 168855880
    
    * [XLA] Remove superfluous locking from xla::ComputationBuilder.
    
    The class is thread compatible, not thread-safe. It is illegal to call non-const methods of the class concurrently. So the mutex is pointless.
    
    Also mark a couple of accessors const.
    
    PiperOrigin-RevId: 168857132
    
    * Add ConvertGraphDefToXla to convert from GraphDef to xla::Computation.
    
    The main logic is simply refactored from tfcompile, with some minor cleanups
    along the way.
    
    PiperOrigin-RevId: 168857174
    
    * Bugfix to tf.contrib.seq2seq beam_search_ops: GPU edge case of seq_len == 0.
    
    PiperOrigin-RevId: 168862288
    
    * [tf.contrib.data] Add `batch_and_drop_remainder` transformation.
    
    This transformation, which is designed for use with `Dataset.apply()`,
    acts like the default of behavior of `tf.train.batch()`, which will
    truncate a finite input source if its number of elements is not an
    exact multiple of the batch size. A benefit of using this
    transformation is that it gives a statically known shape to the output
    elements, because they are all exactly `batch_size` in the 0th
    dimension.
    
    PiperOrigin-RevId: 168863148
    
    * Minor renaming from tfcompile.Config to tf2xla.Config in comments.
    
    PiperOrigin-RevId: 168863860
    
    * Certain ops don't need eager gradients to keep their inputs / outputs alive.
    
    PiperOrigin-RevId: 168864350
    
    * [XLA] Add S64 while loop test.
    
    PiperOrigin-RevId: 168865653
    
    * tfdbg: fix a bug in list_inputs and list_outputs
    
    wherein a tensor name like "x:1" fails to be processed because it were not converted to the node name ("x" in this example) first.
    
    Also simplify analyzer_cli_test.py a little through a new helper function.
    
    PiperOrigin-RevId: 168867948
    
    * Adds multi_label_head in tf.contrib.estimator
    
    PiperOrigin-RevId: 168873313
    
    * Script that generates __init__.py files based on tf_api_names annotations.
    
    PiperOrigin-RevId: 168878737
    
    * Fixing the build command.
    
    PiperOrigin-RevId: 168881605
    
    * Make sure all checked threads are joined before they are terminated.
    
    PiperOrigin-RevId: 168884294
    
    * Output metrics in train mode for multihead.
    
    This is to be consistent with other heads who output the metric tensors in train mode. Outputting the metric tensors allow us for example to plot the metrics on the training set (and compare them to the metircs on the eval set).
    
    PiperOrigin-RevId: 168884726
    
    * Automated g4 rollback of changelist 168458634
    
    PiperOrigin-RevId: 168887778
    
    * Adds DNNEstimator to tf.contrib.estimator.
    
    PiperOrigin-RevId: 168887825
    
    * [tf.contrib.data] Expose `tf.contrib.data.batch_and_drop_remainder()`.
    
    PiperOrigin-RevId: 168888592
    
    * disabling timeout test in opensource build
    
    PiperOrigin-RevId: 168890483
    
    * Add ops that perform color transforms (including changing value, saturation and hue) in YIQ space.
    
    PiperOrigin-RevId: 168897736
    
    * Update the minimum requirement of espsilon for batch norm.
    
    PiperOrigin-RevId: 168897907
    
    * Adding support for capture-by-value.
    
    PiperOrigin-RevId: 168903482
    
    * disabling failing tsan test
    
    PiperOrigin-RevId: 168903876
    
    * disable asan for test timeout
    
    PiperOrigin-RevId: 168903999
    
    * Internal change.
    
    PiperOrigin-RevId: 168910187
    
    * Fix broken test: tensorflow/contrib/eager/python:datasets_test
    
    PiperOrigin-RevId: 168914742
    
    * [XLA:CPU] Implement map fusion.
    
    PiperOrigin-RevId: 168915358
    
    * Merge changes from github.
    END_PUBLIC
    
    I also integrated #13073 by hand to make TAP happy.
    
    ---
    Commit 92362d0f0 authored by Skye Wanderman-Milne<skyewm@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add WhileContext class and add plumbing for creating them.
    
    This change introduces WhileContext, which stores information about a
    while loop and will be used in future changes to generate while loop
    gradient graphs. Exit nodes in a while loop now have a pointer to
    their associated WhileContext. This will be used to retrieve the
    context for a given loop.
    
    This change adds an optional parameter to BuildWhileLoop() to create a
    WhileContext for the while loop (currently this is always true, but
    gradients will generate while loops without associated contexts). This
    change also adds a as-yet-unused option to BuildWhileLoop() to return
    the predicate output.
    
    PiperOrigin-RevId: 168562303
    
    ---
    Commit a4f6e7c1a authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add mel-scale conversion matrix support to tf.contrib.signal.
    
    PiperOrigin-RevId: 168560255
    
    ---
    Commit b00b6d23c authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a segmentation fault caused by invalid log directory in InternalFlush().
    
    PiperOrigin-RevId: 168557063
    
    ---
    Commit 2bc7a155a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    Add uint16 support for tf.decode_raw (#12719)
    
    * Add uint16 support for tf.decode_raw
    
    This fix tries to address the request raised in 10124 where
    uint16 support for tf.decode_raw is needed. tf.decode_raw
    already support half, float32, float64, int8, int16, int32, int64,
    uint8. And uint16 was not supported.
    
    This fix adds uint16 support for tf.decode_raw.
    
    This fix fixes 10124.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Fix test failure caused by uint16 support of decode_raw and add unit tests.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 009285c09 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove benchmark for TensorShapeOld.
    
    PiperOrigin-RevId: 168551108
    
    ---
    Commit dc1eda8a6 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix CHECK-failure crash if a non-tuple was passed to GetTupleElement.
    
    PiperOrigin-RevId: 168550703
    
    ---
    Commit 010922ed9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168549989
    
    ---
    Commit c8a6131e9 authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    make `tf.sets` examples executable
    
    Fixes #12969
    
    PiperOrigin-RevId: 168549712
    
    ---
    Commit bece65c6f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use a map instead of a vector of Children() in the BeamEntry.
    
    The assumption is that since the entries are sparse (they are all populated, but most are never Active()), using the map will save memory and make iterating over the Children() more efficient.
    
    PiperOrigin-RevId: 168548814
    
    ---
    Commit 0d5ab82ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168548642
    
    ---
    Commit 3331c574b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Implementing gradients for tf.image.resize_bicubic.
    
    PiperOrigin-RevId: 168547412
    
    ---
    Commit 4982ef0fa authored by Martin Wicke<wicke@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add the ability to warn only once if deprecated functionality is used, and make that the default.
    
    PiperOrigin-RevId: 168545655
    
    ---
    Commit 99423416a authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make shape inference error messages for the While HLO more readable. Build the error lazily.
    
    PiperOrigin-RevId: 168531083
    
    ---
    Commit d10374e45 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Discard some unneccessary logging commands.
    
    PiperOrigin-RevId: 168500721
    
    ---
    Commit 83cbabb85 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix wrong format of logging message.
    
    PiperOrigin-RevId: 168497373
    
    ---
    Commit eec4f1b3a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168494944
    
    ---
    Commit 69301f352 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168494220
    
    ---
    Commit 9d56f419c authored by Mingxing Tan<tanmingxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add crop_and_decode_jpeg_op that combines the crop and decode for better
    performance.
    
    PiperOrigin-RevId: 168493125
    
    ---
    Commit 48ddf64d0 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make large params test only run in opt builds.
    
    PiperOrigin-RevId: 168491913
    
    ---
    Commit 11d3ac29d authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add tests for large numbers of parameter / return values and while loops.
    
    PiperOrigin-RevId: 168487225
    
    ---
    Commit 3cd6bdef5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added test cases on R4 slice.
    
    PiperOrigin-RevId: 168482049
    
    ---
    Commit 46a81b5c3 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add cast S64 to F32 test.
    
    PiperOrigin-RevId: 168473650
    
    ---
    Commit 59bdf598d authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add an automatically-generated "tensorflow.python.platform.build_info" script.
    
    The motivation for this script is to provide better tools for
    diagnosing load-time errors (such as the ones that plague the Windows
    build due to DLL issues). Note that the script is intended to be
    self-contained, so that it is possible to import it without loading
    the entire TensorFlow runtime.
    
    This generated script currently contains a single symbol,
    `is_cuda_build`, which records whether the build has GPU support or not.
    
    PiperOrigin-RevId: 168471034
    
    ---
    Commit c3b86347f authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling tests that are passing
    
    PiperOrigin-RevId: 168466361
    
    ---
    Commit c728665ec authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add const qualifiers whenever appropriate.
    
    PiperOrigin-RevId: 168465926
    
    ---
    Commit bf96fcd13 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use the scalar cache in MeanGrad.
    
    PiperOrigin-RevId: 168462267
    
    ---
    Commit 1cada9ea2 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling test that passed after 100 runs w/o timing out
    
    PiperOrigin-RevId: 168458634
    
    ---
    Commit 00c865566 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Generate error (instead of segfault) when trying to copy string tensor
    to GPU in EagerTensor constructor.
    
    PiperOrigin-RevId: 168457320
    
    ---
    Commit 655f26fc7 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Resurrects autograd-free eager gradients.
    
    PiperOrigin-RevId: 168448557
    
    ---
    Commit 8f37f3002 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Cleanups to handling of arguments during XLA compilation:
    * combine resource kinds in XlaCompiler::Argument::Kind, use a separate XlaResource::Kind field to distinguish different kinds of resource.
    * merge XlaContext::HandleOrConstant and XlaExpression, which were almost identical.
    * remove XlaContext::Argument; instead, build XlaExpressions directly from XlaCompiler and add them to the XlaContext.
    
    PiperOrigin-RevId: 168439341
    
    ---
    Commit 7f5346a80 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168432070
    
    ---
    Commit 2ad85aa4d authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use xla/tests:xla_internal_test_main for all tests under tf/compiler/xla
    and remove any main() definitions in tests. This enables use of flags
    in all tests.
    
    PiperOrigin-RevId: 168424796
    
    ---
    Commit cd377811d authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Comment and error message consistency cleanup.
    
    PiperOrigin-RevId: 168422582
    
    ---
    Commit 7c19b82af authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf.sparse_reset_shape so that when shrinking the shape of an empty
    sparse tensor, the result has a shape of all zeros.
    
    PiperOrigin-RevId: 168419639
    
    ---
    Commit fcacb40d4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    FirstReadyManager for scheduling nodes in VirtualScheduler.
    The current FIFOManager may yield inefficient scheduling; _Recv pushed to the
    FIFO blocks other nodes that can run before _Recv due to the node order in FIFO.
    FirstReadyManager picks a node with the earliest time_ready in the queue,
    avoiding this problem.
    
    Also, fixed VirtualPlacer to properly set device when Node's device name does not
    include job name and to set GPU:0 as default device.
    
    PiperOrigin-RevId: 168418455
    
    ---
    Commit 7e47624f5 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Initial support for iteration over tf.contrib.data.Dataset objects.
    
    TODO:
    - Support function-valued operation attributes in eager
      (Required for MapDataset, FilterDataset etc. which encode the
      per-element computation in a TensorFlow function)
    PiperOrigin-RevId: 168418250
    
    ---
    Commit b0a397fce authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Remove unnecessary TFE_Context argument to TFE_OpSetDevice.
    
    PiperOrigin-RevId: 168417999
    
    ---
    Commit 86211d554 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Graph transform to flatten atrous (dilated) convolutions (i.e., a sequence of SpaceToBatchND-Conv-BatchToSpaceND ops) to a regular Conv op with upsampled filters.
    
    PiperOrigin-RevId: 168414124
    
    ---
    Commit 3438981ca authored by David G. Andersen<dga@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Apply exported symbol filtering to the c++ API analogously to
    what is filtered for the C API.
    Fixes bug reported in comments on #1924
    
    PiperOrigin-RevId: 168413719
    
    ---
    Commit 7e023d865 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:CPU] Remove code from parallel CPU backend outlining that was causing unnecessary copies to be inserted, and which is no longer necessary since we added co-located buffer support for kCall.
    *) All bitcast copy is no longer necessary as CopyInsertion will insert copies
    at the root of the computation for a parameter which is live-out.
    *) Copy if root does not define buffer no longer necessary because colocated
    assignment looks at points-to set of root instruction.
    
    PiperOrigin-RevId: 168412076
    
    ---
    Commit 5da4df92c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplify some code in grappler_item_builder.cc, no change in logic.
    
    PiperOrigin-RevId: 168409110
    
    ---
    Commit 82ec6241a authored by drpngx<drpngx@users.noreply.github.com>
    Committed by GitHub<noreply@github.com>:
    Add six and numpy imports
    ---
    Commit 9c4ce2452 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add flag parsing to more tests in xla/service specifically those which build
    HLO graphs. This enables, for example, dumping of the graphs with
    --xla_generate_hlo_graph. Also remove some superfluous tensorflow test_main
    dependencies.
    
    PiperOrigin-RevId: 168406746
    
    ---
    Commit d4efa695c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Relax the feed_nodes collection check, which triggers a false positive in some modes where the feed node collection is auto-generated. Keep it as a warning to help correct user-provided feed node lists.
    
    PiperOrigin-RevId: 168396408
    
    ---
    Commit cbc46a856 authored by Changming Sun<chasun@microsoft.com>
    Committed by gunan<gunan@google.com>:
    Add a missing template explicit instantiation of SetZeroFunctor (#12791)
    
    ---
    Commit 7bb08f5bf authored by Kevin Slagle<kjslag@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    fix ExponentialMovingAverage documentation so that ExponentialMovingAverage.apply is evaluated within control_dependencies (#12987)
    
    ---
    Commit e6b011763 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extend c++ gradient_checker to complex types.
    
    PiperOrigin-RevId: 168392949
    
    ---
    Commit 4086219a4 authored by Lyndon White<oxinabox@ucc.asn.au>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Correct minor typo in substr docs example (#12991)
    
    ---
    Commit f63aa7f49 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate core TFGAN functions to opensource.
    
    PiperOrigin-RevId: 168391923
    
    ---
    Commit bc6b60f1b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix tuple_losses bug caused by Python bug.
    
    PiperOrigin-RevId: 168386341
    
    ---
    Commit 7a8c63da3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate `leaky_relu` to `nn_ops.py`. Will be used for TFGAN.
    
    PiperOrigin-RevId: 168386268
    
    ---
    Commit f7ba16fdf authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Do not export from eval on train data steps.
    
    PiperOrigin-RevId: 168374021
    
    ---
    Commit 9b9e54b34 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding NCCL sum op, register all_sum gradient.
    Streamlining nccl test.
    
    PiperOrigin-RevId: 168347428
    
    ---
    Commit bc300318e authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update gemmlowp hash as the commit history seems to have changed in the
    repository.
    
    PiperOrigin-RevId: 168343607
    
    ---
    Commit 1e96d54d9 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Also accept non-k8 CPU types in build pip package. (#12975)
    
    * Also accept non-k8 CPU types in build pip package.
    Fixes #12735
    
    * Make the script work with `set -e`.
    
    ---
    Commit c0a4c7ffc authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix bug in ShapeUtil::ShapeIs that would lead to type inference errors.
    
    PiperOrigin-RevId: 168323589
    
    ---
    Commit 4af9be964 authored by Amy<amy@infosleuth.net>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    support passing in a source url to the mnist read_data_sets function, to make it easier to use 'fashion mnist' etc. (#12983)
    
    ---
    Commit 9f848734f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Tweak layer a bit to be eager friendly.
    
    PiperOrigin-RevId: 168312865
    
    ---
    Commit 60f15462b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change conv_input_scale and side_input_scale from attributes to inputs for improved flexibility, in fused_conv2d_bias_activation op.
    
    PiperOrigin-RevId: 168311988
    
    ---
    Commit 4b4e10f9c authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds dict support of eval metrics.
    
    PiperOrigin-RevId: 168310444
    
    ---
    Commit ab7f22de6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Move FusedConvBiasActivationShape out of common_shape_fns.cc to a lambda inside the op.
    
    PiperOrigin-RevId: 168300911
    
    ---
    Commit 3a98035fa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Augment metadata output with source-line info, as before.
    
    PiperOrigin-RevId: 168292527
    
    ---
    Commit 349188152 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Enable fused batch norm, which is 15-20% faster for training and inference.
    
    PiperOrigin-RevId: 168288154
    
    ---
    Commit 08587d45b authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added back persistent memory tracking in queue op. The new tracking logic has avoided the crash in previous implementation:  the queue_ passed to CreateTypedQueue may be unreffed if the resource is already created by another resource op that shares the same resource name and type.
    
    PiperOrigin-RevId: 168284509
    
    ---
    Commit 733063d55 authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Fixing awkward wording.
    
    ---
    Commit c7ad6bfef authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Removing accidental hash.
    
    ---
    Commit 53dbc761a authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Adding Windows self check script to docs.
    
    ---
    Commit ed1135994 authored by Andrew Harp<andrewharp@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add -latomic flag to benchmark_model target to fix Android x86 build.
    
    PiperOrigin-RevId: 168281337
    
    ---
    Commit c0348bb55 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf_export.py to take constant name as an argument instead of a constant.
    
    PiperOrigin-RevId: 168280613
    
    ---
    Commit c3d19e40a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cleanup training_ops to reduce code redudancy.
    
    PiperOrigin-RevId: 168280069
    
    ---
    Commit 123fb01ee authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set fused=False for batch norm, because the test assumes no bessel's
    correction. Fused=True would add bessel's correction to variance.
    
    PiperOrigin-RevId: 168274392
    
    ---
    Commit f0e8c545e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch resource variables from copy-on-read to copy-on-write.
    
    RELNOTES: Change the signature of (C++) GetInputTensorFromVariable in
    training_op_helpers to support new copy-on-write semenatics of resource
    variables.
    PiperOrigin-RevId: 168273249
    
    ---
    Commit 495cc8e47 authored by Yuan (Terry) Tang<terrytangyuan@users.noreply.github.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Minor wording change in timeseries module's README (#12938)
    
    * Minor wording change in timeseries module's README
    
    * Address comments
    
    ---
    Commit f13b876ed authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Making the default build from source version 1.4.0dev. The whl files that are built will be 1.3.0devDDMMYYYY.
    
    ---
    Commit 2356c0ff4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete ScopedTFStatus to avoid leaking it for long running trainers(1+day).
    
    PiperOrigin-RevId: 168259652
    
    ---
    Commit e15f4cae2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't remove all aliases from linalg namespace.
    Get rid of redundant aliases.
    
    PiperOrigin-RevId: 168257658
    
    ---
    Commit c58082642 authored by postBG<profile2697@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Fix minor typo in Programmers guide (#12965)
    
    * Fix minor typo in Programmers guide
    
    * change to "this"
    
    ---
    Commit 509372c2e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a lot of operations' flops calculations
    
    PiperOrigin-RevId: 168256746
    
    ---
    Commit 80ed8afc0 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add Flatten to core layers.
    
    PiperOrigin-RevId: 168254118
    
    ---
    Commit a6223c01a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix locking of variables in SparseProximalGradientDescent,
    AdagradDA, SparseAdagradDA.
    
    PiperOrigin-RevId: 168252530
    
    ---
    Commit abde00830 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    adding InputTensor class for symmetry with OutputTensor
    
    PiperOrigin-RevId: 168250085
    
    ---
    Commit 0451032ca authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix variable naming style guide violation.
    
    PiperOrigin-RevId: 168245542
    
    ---
    Commit a202a5a94 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168245371
    
    ---
    Commit f93e354cb authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Switch backend Dataset representation to DT_VARIANT.
    
    This change introduces a new `DatasetWrapper` type that wraps a
    `DatasetBase*` and can be stored in a DT_VARIANT tensor. All Dataset
    ops now consume and produce DT_VARIANT instead of DT_RESOURCE, and the
    underlying implementation is simplified because the `DatasetWrapper`
    can be passed directly by value without using the `ResourceMgr`.
    
    PiperOrigin-RevId: 168240571
    
    ---
    Commit a4042cd2a authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces the placeholder for _TrainingExecutor, which serves the implementation of tf.estimator.train_and_evaluate.
    
    PiperOrigin-RevId: 168240151
    
    ---
    Commit 10ba148f7 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch control_flow_ops library to use Resource variants of Stack operators, instead of deprecated Ref variants.
    
    PiperOrigin-RevId: 168234822
    
    ---
    Commit ca43fe82b authored by Ali Yahya<alive@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Improves the interfaces of tape.watch_variable() and implicit_grad().
    
    tape.watch_variable() replaces tape.watch() and now is called on ResourceVariable objects instead of their underlying handles.
    
    implicit_grad() now returns a list of (gradient, variable) pairs to be consistent with tf.Optimizer's interface.
    
    PiperOrigin-RevId: 168232055
    
    ---
    Commit b72862dfc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    internal change
    
    PiperOrigin-RevId: 168225993
    
    ---
    Commit da3280f4d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable tsan for sdca_estimator_test.
    
    PiperOrigin-RevId: 168186374
    
    ---
    Commit c936c1155 authored by Yifei Feng<yifeif@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix pip tests for contrib/gan.
    - Add *_impl.py so tests can still access removed symbols.
    - Add /python directory layer to make *_impy.py and __init__.py not in the same dir.
    
    PiperOrigin-RevId: 168161722
    
    ---
    Commit ce9a2b00f authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Performance guide update
    
    PiperOrigin-RevId: 168159289
    
    ---
    Commit 3bce4f9a0 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: expose tfe.num_gpus()
    
    PiperOrigin-RevId: 168154345
    
    ---
    Commit 67a7cbc28 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Changed the default eval throttle secs from 2 min to 10 mins.
    
    PiperOrigin-RevId: 168120323
    
    ---
    Commit 92bed178f authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168119914
    
    ---
    Commit 702d59582 authored by joshkyh<joshkyh@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Corrected hyperlink for audio training tutorial (#12923)
    
    ---
    Commit 877c9deca authored by Frank Chen<frankchn@gmail.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Reverse change eb75ded6 so that internal tests will pass. (#12933)
    
    As support for int64 global steps is not ready in TPUs, I am reversing this change so that our internal performance and regression tests will pass.
    ---
    Commit 665966438 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable grpc_session_test.
    
    PiperOrigin-RevId: 168078694
    
    ---
    Commit 405def792 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Switch CallInliner to use CallGraph::VisitNodes.
    
    PiperOrigin-RevId: 168078645
    
    ---
    Commit aba3466f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Exposes Head and factory methods in tf.contrib.estimator.
    
    PiperOrigin-RevId: 168071246
    
    ---
    Commit b76565b39 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Some profiler fixes and cleanup.
    
    PiperOrigin-RevId: 168069346
    
    ---
    Commit 32ffc5a81 authored by Jonas<sauercrowd@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Just a dot in order to be consistent (#12919)
    
    added a dot to the `7` to make clear it's a float (like every other number)
    ---
    Commit 0753b0c79 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Scope the scalar cache in the context.
    
    PiperOrigin-RevId: 168065417
    
    ---
    Commit 48deb206b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate TFGAN features to third_party.
    
    PiperOrigin-RevId: 168060880
    
    ---
    Commit d2ae1311f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixing an issue in the BUILD file of the LSH ops.
    
    PiperOrigin-RevId: 168056645
    
    ---
    Commit 2f440eda4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expose NumpyReader for reading timeseries data.
    
    PiperOrigin-RevId: 168055838
    
    ---
    Commit be1916ce7 authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added functionality to allow `SqlDataset` to interpret a database column as various numeric types, including several integer types and `dtypes.float64`.
    
    PiperOrigin-RevId: 168055827
    
    ---
    Commit fa2000a0b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Supporting nightly windows pip packages.
    
    PiperOrigin-RevId: 168054959
    
    ---
    Commit a263ea626 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Treat eager tensors as constants during graph construction.
    
    Unless capturing is explicitly enabled.
    
    PiperOrigin-RevId: 168052675
    
    ---
    Commit 6e402d0d2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make TODO a bit more specific.
    
    PiperOrigin-RevId: 168051381
    
    ---
    Commit c779384bc authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added code example to the doc string for `SqlDataset`.
    
    PiperOrigin-RevId: 168049037
    
    ---
    Commit ff6dd474a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use self._in_graph_mode consistently in ResourceVariable
    instead of sometimes getting it from the context.
    
    Also: fix formatting of a comment and use a more precise test to detect
    if initial_value is set.
    PiperOrigin-RevId: 168047258
    
    ---
    Commit f331f528b authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removes "fast paths" which are not fast in eager mode.
    
    PiperOrigin-RevId: 168046278
    
    ---
    Commit 86f1713e5 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces TrainSpec and EvalSpec.
    
    PiperOrigin-RevId: 168040435
    
    ---
    Commit c8b9e92f0 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Move "register_function" to context.py
    
    This will allow function registration from other
    modules without having to import "function.py".
    (And besides, the function really does belong on the context).
    
    PiperOrigin-RevId: 168040411
    
    ---
    Commit 74137f994 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix signed int overflow issue in tensor_id.cc
    
    When a node name has a long numeric suffix, e.g.,
    "foo/y_0/gradient_debug_09684b60f2184c67b744721915034528" (as has happened with tfdbg GradientsDebugger),
    
    the parsing algorithm in ParseTensorName() may experience signed int overflow. Replacing the types with "unsigned int" resolves the issue.
    
    PiperOrigin-RevId: 168039195
    
    ---
    Commit 450c3b562 authored by Rohan Jain<rohanj@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Using rendezvous manager to pass args / rets between devices during function remote execution. This enables CPU->GPU remote device executions now.
    
    PiperOrigin-RevId: 168038285
    
    ---
    Commit 82cc6529f authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes the wording about StopIteration.
    
    PiperOrigin-RevId: 168034451
    
    ---
    Commit fb5588002 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a statement on install/index.md on what os are supported.
    
    PiperOrigin-RevId: 168032996
    
    ---
    Commit f83f6b9ef authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Handle higher-order HLOs (e.g. While) in CallInliner and test.
    
    PiperOrigin-RevId: 168029345
    
    ---
    Commit 8988ae365 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 167916124
    
    PiperOrigin-RevId: 168916710
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168917157
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168917534

commit a373b1f74215e44920bf9362a51bece530edf88a
Author: Patrick Nguyen <drpng@google.com>
Date:   Fri Sep 15 18:14:40 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    I also integrated #13073 by hand to make TAP happy.
    
    ---
    Commit 92362d0f0 authored by Skye Wanderman-Milne<skyewm@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add WhileContext class and add plumbing for creating them.
    
    This change introduces WhileContext, which stores information about a
    while loop and will be used in future changes to generate while loop
    gradient graphs. Exit nodes in a while loop now have a pointer to
    their associated WhileContext. This will be used to retrieve the
    context for a given loop.
    
    This change adds an optional parameter to BuildWhileLoop() to create a
    WhileContext for the while loop (currently this is always true, but
    gradients will generate while loops without associated contexts). This
    change also adds a as-yet-unused option to BuildWhileLoop() to return
    the predicate output.
    
    PiperOrigin-RevId: 168562303
    
    ---
    Commit a4f6e7c1a authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add mel-scale conversion matrix support to tf.contrib.signal.
    
    PiperOrigin-RevId: 168560255
    
    ---
    Commit b00b6d23c authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a segmentation fault caused by invalid log directory in InternalFlush().
    
    PiperOrigin-RevId: 168557063
    
    ---
    Commit 2bc7a155a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    Add uint16 support for tf.decode_raw (#12719)
    
    * Add uint16 support for tf.decode_raw
    
    This fix tries to address the request raised in 10124 where
    uint16 support for tf.decode_raw is needed. tf.decode_raw
    already support half, float32, float64, int8, int16, int32, int64,
    uint8. And uint16 was not supported.
    
    This fix adds uint16 support for tf.decode_raw.
    
    This fix fixes 10124.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Fix test failure caused by uint16 support of decode_raw and add unit tests.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 009285c09 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove benchmark for TensorShapeOld.
    
    PiperOrigin-RevId: 168551108
    
    ---
    Commit dc1eda8a6 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix CHECK-failure crash if a non-tuple was passed to GetTupleElement.
    
    PiperOrigin-RevId: 168550703
    
    ---
    Commit 010922ed9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168549989
    
    ---
    Commit c8a6131e9 authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    make `tf.sets` examples executable
    
    Fixes #12969
    
    PiperOrigin-RevId: 168549712
    
    ---
    Commit bece65c6f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use a map instead of a vector of Children() in the BeamEntry.
    
    The assumption is that since the entries are sparse (they are all populated, but most are never Active()), using the map will save memory and make iterating over the Children() more efficient.
    
    PiperOrigin-RevId: 168548814
    
    ---
    Commit 0d5ab82ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168548642
    
    ---
    Commit 3331c574b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Implementing gradients for tf.image.resize_bicubic.
    
    PiperOrigin-RevId: 168547412
    
    ---
    Commit 4982ef0fa authored by Martin Wicke<wicke@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add the ability to warn only once if deprecated functionality is used, and make that the default.
    
    PiperOrigin-RevId: 168545655
    
    ---
    Commit 99423416a authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make shape inference error messages for the While HLO more readable. Build the error lazily.
    
    PiperOrigin-RevId: 168531083
    
    ---
    Commit d10374e45 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Discard some unneccessary logging commands.
    
    PiperOrigin-RevId: 168500721
    
    ---
    Commit 83cbabb85 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix wrong format of logging message.
    
    PiperOrigin-RevId: 168497373
    
    ---
    Commit eec4f1b3a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168494944
    
    ---
    Commit 69301f352 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168494220
    
    ---
    Commit 9d56f419c authored by Mingxing Tan<tanmingxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add crop_and_decode_jpeg_op that combines the crop and decode for better
    performance.
    
    PiperOrigin-RevId: 168493125
    
    ---
    Commit 48ddf64d0 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make large params test only run in opt builds.
    
    PiperOrigin-RevId: 168491913
    
    ---
    Commit 11d3ac29d authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add tests for large numbers of parameter / return values and while loops.
    
    PiperOrigin-RevId: 168487225
    
    ---
    Commit 3cd6bdef5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added test cases on R4 slice.
    
    PiperOrigin-RevId: 168482049
    
    ---
    Commit 46a81b5c3 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add cast S64 to F32 test.
    
    PiperOrigin-RevId: 168473650
    
    ---
    Commit 59bdf598d authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add an automatically-generated "tensorflow.python.platform.build_info" script.
    
    The motivation for this script is to provide better tools for
    diagnosing load-time errors (such as the ones that plague the Windows
    build due to DLL issues). Note that the script is intended to be
    self-contained, so that it is possible to import it without loading
    the entire TensorFlow runtime.
    
    This generated script currently contains a single symbol,
    `is_cuda_build`, which records whether the build has GPU support or not.
    
    PiperOrigin-RevId: 168471034
    
    ---
    Commit c3b86347f authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling tests that are passing
    
    PiperOrigin-RevId: 168466361
    
    ---
    Commit c728665ec authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add const qualifiers whenever appropriate.
    
    PiperOrigin-RevId: 168465926
    
    ---
    Commit bf96fcd13 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use the scalar cache in MeanGrad.
    
    PiperOrigin-RevId: 168462267
    
    ---
    Commit 1cada9ea2 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling test that passed after 100 runs w/o timing out
    
    PiperOrigin-RevId: 168458634
    
    ---
    Commit 00c865566 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Generate error (instead of segfault) when trying to copy string tensor
    to GPU in EagerTensor constructor.
    
    PiperOrigin-RevId: 168457320
    
    ---
    Commit 655f26fc7 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Resurrects autograd-free eager gradients.
    
    PiperOrigin-RevId: 168448557
    
    ---
    Commit 8f37f3002 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Cleanups to handling of arguments during XLA compilation:
    * combine resource kinds in XlaCompiler::Argument::Kind, use a separate XlaResource::Kind field to distinguish different kinds of resource.
    * merge XlaContext::HandleOrConstant and XlaExpression, which were almost identical.
    * remove XlaContext::Argument; instead, build XlaExpressions directly from XlaCompiler and add them to the XlaContext.
    
    PiperOrigin-RevId: 168439341
    
    ---
    Commit 7f5346a80 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168432070
    
    ---
    Commit 2ad85aa4d authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use xla/tests:xla_internal_test_main for all tests under tf/compiler/xla
    and remove any main() definitions in tests. This enables use of flags
    in all tests.
    
    PiperOrigin-RevId: 168424796
    
    ---
    Commit cd377811d authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Comment and error message consistency cleanup.
    
    PiperOrigin-RevId: 168422582
    
    ---
    Commit 7c19b82af authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf.sparse_reset_shape so that when shrinking the shape of an empty
    sparse tensor, the result has a shape of all zeros.
    
    PiperOrigin-RevId: 168419639
    
    ---
    Commit fcacb40d4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    FirstReadyManager for scheduling nodes in VirtualScheduler.
    The current FIFOManager may yield inefficient scheduling; _Recv pushed to the
    FIFO blocks other nodes that can run before _Recv due to the node order in FIFO.
    FirstReadyManager picks a node with the earliest time_ready in the queue,
    avoiding this problem.
    
    Also, fixed VirtualPlacer to properly set device when Node's device name does not
    include job name and to set GPU:0 as default device.
    
    PiperOrigin-RevId: 168418455
    
    ---
    Commit 7e47624f5 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Initial support for iteration over tf.contrib.data.Dataset objects.
    
    TODO:
    - Support function-valued operation attributes in eager
      (Required for MapDataset, FilterDataset etc. which encode the
      per-element computation in a TensorFlow function)
    PiperOrigin-RevId: 168418250
    
    ---
    Commit b0a397fce authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Remove unnecessary TFE_Context argument to TFE_OpSetDevice.
    
    PiperOrigin-RevId: 168417999
    
    ---
    Commit 86211d554 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Graph transform to flatten atrous (dilated) convolutions (i.e., a sequence of SpaceToBatchND-Conv-BatchToSpaceND ops) to a regular Conv op with upsampled filters.
    
    PiperOrigin-RevId: 168414124
    
    ---
    Commit 3438981ca authored by David G. Andersen<dga@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Apply exported symbol filtering to the c++ API analogously to
    what is filtered for the C API.
    Fixes bug reported in comments on #1924
    
    PiperOrigin-RevId: 168413719
    
    ---
    Commit 7e023d865 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:CPU] Remove code from parallel CPU backend outlining that was causing unnecessary copies to be inserted, and which is no longer necessary since we added co-located buffer support for kCall.
    *) All bitcast copy is no longer necessary as CopyInsertion will insert copies
    at the root of the computation for a parameter which is live-out.
    *) Copy if root does not define buffer no longer necessary because colocated
    assignment looks at points-to set of root instruction.
    
    PiperOrigin-RevId: 168412076
    
    ---
    Commit 5da4df92c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplify some code in grappler_item_builder.cc, no change in logic.
    
    PiperOrigin-RevId: 168409110
    
    ---
    Commit 82ec6241a authored by drpngx<drpngx@users.noreply.github.com>
    Committed by GitHub<noreply@github.com>:
    Add six and numpy imports
    ---
    Commit 9c4ce2452 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add flag parsing to more tests in xla/service specifically those which build
    HLO graphs. This enables, for example, dumping of the graphs with
    --xla_generate_hlo_graph. Also remove some superfluous tensorflow test_main
    dependencies.
    
    PiperOrigin-RevId: 168406746
    
    ---
    Commit d4efa695c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Relax the feed_nodes collection check, which triggers a false positive in some modes where the feed node collection is auto-generated. Keep it as a warning to help correct user-provided feed node lists.
    
    PiperOrigin-RevId: 168396408
    
    ---
    Commit cbc46a856 authored by Changming Sun<chasun@microsoft.com>
    Committed by gunan<gunan@google.com>:
    Add a missing template explicit instantiation of SetZeroFunctor (#12791)
    
    ---
    Commit 7bb08f5bf authored by Kevin Slagle<kjslag@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    fix ExponentialMovingAverage documentation so that ExponentialMovingAverage.apply is evaluated within control_dependencies (#12987)
    
    ---
    Commit e6b011763 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extend c++ gradient_checker to complex types.
    
    PiperOrigin-RevId: 168392949
    
    ---
    Commit 4086219a4 authored by Lyndon White<oxinabox@ucc.asn.au>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Correct minor typo in substr docs example (#12991)
    
    ---
    Commit f63aa7f49 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate core TFGAN functions to opensource.
    
    PiperOrigin-RevId: 168391923
    
    ---
    Commit bc6b60f1b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix tuple_losses bug caused by Python bug.
    
    PiperOrigin-RevId: 168386341
    
    ---
    Commit 7a8c63da3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate `leaky_relu` to `nn_ops.py`. Will be used for TFGAN.
    
    PiperOrigin-RevId: 168386268
    
    ---
    Commit f7ba16fdf authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Do not export from eval on train data steps.
    
    PiperOrigin-RevId: 168374021
    
    ---
    Commit 9b9e54b34 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding NCCL sum op, register all_sum gradient.
    Streamlining nccl test.
    
    PiperOrigin-RevId: 168347428
    
    ---
    Commit bc300318e authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update gemmlowp hash as the commit history seems to have changed in the
    repository.
    
    PiperOrigin-RevId: 168343607
    
    ---
    Commit 1e96d54d9 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Also accept non-k8 CPU types in build pip package. (#12975)
    
    * Also accept non-k8 CPU types in build pip package.
    Fixes #12735
    
    * Make the script work with `set -e`.
    
    ---
    Commit c0a4c7ffc authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix bug in ShapeUtil::ShapeIs that would lead to type inference errors.
    
    PiperOrigin-RevId: 168323589
    
    ---
    Commit 4af9be964 authored by Amy<amy@infosleuth.net>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    support passing in a source url to the mnist read_data_sets function, to make it easier to use 'fashion mnist' etc. (#12983)
    
    ---
    Commit 9f848734f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Tweak layer a bit to be eager friendly.
    
    PiperOrigin-RevId: 168312865
    
    ---
    Commit 60f15462b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change conv_input_scale and side_input_scale from attributes to inputs for improved flexibility, in fused_conv2d_bias_activation op.
    
    PiperOrigin-RevId: 168311988
    
    ---
    Commit 4b4e10f9c authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds dict support of eval metrics.
    
    PiperOrigin-RevId: 168310444
    
    ---
    Commit ab7f22de6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Move FusedConvBiasActivationShape out of common_shape_fns.cc to a lambda inside the op.
    
    PiperOrigin-RevId: 168300911
    
    ---
    Commit 3a98035fa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Augment metadata output with source-line info, as before.
    
    PiperOrigin-RevId: 168292527
    
    ---
    Commit 349188152 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Enable fused batch norm, which is 15-20% faster for training and inference.
    
    PiperOrigin-RevId: 168288154
    
    ---
    Commit 08587d45b authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added back persistent memory tracking in queue op. The new tracking logic has avoided the crash in previous implementation:  the queue_ passed to CreateTypedQueue may be unreffed if the resource is already created by another resource op that shares the same resource name and type.
    
    PiperOrigin-RevId: 168284509
    
    ---
    Commit 733063d55 authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Fixing awkward wording.
    
    ---
    Commit c7ad6bfef authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Removing accidental hash.
    
    ---
    Commit 53dbc761a authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Adding Windows self check script to docs.
    
    ---
    Commit ed1135994 authored by Andrew Harp<andrewharp@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add -latomic flag to benchmark_model target to fix Android x86 build.
    
    PiperOrigin-RevId: 168281337
    
    ---
    Commit c0348bb55 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf_export.py to take constant name as an argument instead of a constant.
    
    PiperOrigin-RevId: 168280613
    
    ---
    Commit c3d19e40a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cleanup training_ops to reduce code redudancy.
    
    PiperOrigin-RevId: 168280069
    
    ---
    Commit 123fb01ee authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set fused=False for batch norm, because the test assumes no bessel's
    correction. Fused=True would add bessel's correction to variance.
    
    PiperOrigin-RevId: 168274392
    
    ---
    Commit f0e8c545e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch resource variables from copy-on-read to copy-on-write.
    
    RELNOTES: Change the signature of (C++) GetInputTensorFromVariable in
    training_op_helpers to support new copy-on-write semenatics of resource
    variables.
    PiperOrigin-RevId: 168273249
    
    ---
    Commit 495cc8e47 authored by Yuan (Terry) Tang<terrytangyuan@users.noreply.github.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Minor wording change in timeseries module's README (#12938)
    
    * Minor wording change in timeseries module's README
    
    * Address comments
    
    ---
    Commit f13b876ed authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Making the default build from source version 1.4.0dev. The whl files that are built will be 1.3.0devDDMMYYYY.
    
    ---
    Commit 2356c0ff4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete ScopedTFStatus to avoid leaking it for long running trainers(1+day).
    
    PiperOrigin-RevId: 168259652
    
    ---
    Commit e15f4cae2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't remove all aliases from linalg namespace.
    Get rid of redundant aliases.
    
    PiperOrigin-RevId: 168257658
    
    ---
    Commit c58082642 authored by postBG<profile2697@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Fix minor typo in Programmers guide (#12965)
    
    * Fix minor typo in Programmers guide
    
    * change to "this"
    
    ---
    Commit 509372c2e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a lot of operations' flops calculations
    
    PiperOrigin-RevId: 168256746
    
    ---
    Commit 80ed8afc0 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add Flatten to core layers.
    
    PiperOrigin-RevId: 168254118
    
    ---
    Commit a6223c01a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix locking of variables in SparseProximalGradientDescent,
    AdagradDA, SparseAdagradDA.
    
    PiperOrigin-RevId: 168252530
    
    ---
    Commit abde00830 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    adding InputTensor class for symmetry with OutputTensor
    
    PiperOrigin-RevId: 168250085
    
    ---
    Commit 0451032ca authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix variable naming style guide violation.
    
    PiperOrigin-RevId: 168245542
    
    ---
    Commit a202a5a94 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168245371
    
    ---
    Commit f93e354cb authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Switch backend Dataset representation to DT_VARIANT.
    
    This change introduces a new `DatasetWrapper` type that wraps a
    `DatasetBase*` and can be stored in a DT_VARIANT tensor. All Dataset
    ops now consume and produce DT_VARIANT instead of DT_RESOURCE, and the
    underlying implementation is simplified because the `DatasetWrapper`
    can be passed directly by value without using the `ResourceMgr`.
    
    PiperOrigin-RevId: 168240571
    
    ---
    Commit a4042cd2a authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces the placeholder for _TrainingExecutor, which serves the implementation of tf.estimator.train_and_evaluate.
    
    PiperOrigin-RevId: 168240151
    
    ---
    Commit 10ba148f7 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch control_flow_ops library to use Resource variants of Stack operators, instead of deprecated Ref variants.
    
    PiperOrigin-RevId: 168234822
    
    ---
    Commit ca43fe82b authored by Ali Yahya<alive@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Improves the interfaces of tape.watch_variable() and implicit_grad().
    
    tape.watch_variable() replaces tape.watch() and now is called on ResourceVariable objects instead of their underlying handles.
    
    implicit_grad() now returns a list of (gradient, variable) pairs to be consistent with tf.Optimizer's interface.
    
    PiperOrigin-RevId: 168232055
    
    ---
    Commit b72862dfc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    internal change
    
    PiperOrigin-RevId: 168225993
    
    ---
    Commit da3280f4d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable tsan for sdca_estimator_test.
    
    PiperOrigin-RevId: 168186374
    
    ---
    Commit c936c1155 authored by Yifei Feng<yifeif@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix pip tests for contrib/gan.
    - Add *_impl.py so tests can still access removed symbols.
    - Add /python directory layer to make *_impy.py and __init__.py not in the same dir.
    
    PiperOrigin-RevId: 168161722
    
    ---
    Commit ce9a2b00f authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Performance guide update
    
    PiperOrigin-RevId: 168159289
    
    ---
    Commit 3bce4f9a0 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: expose tfe.num_gpus()
    
    PiperOrigin-RevId: 168154345
    
    ---
    Commit 67a7cbc28 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Changed the default eval throttle secs from 2 min to 10 mins.
    
    PiperOrigin-RevId: 168120323
    
    ---
    Commit 92bed178f authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168119914
    
    ---
    Commit 702d59582 authored by joshkyh<joshkyh@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Corrected hyperlink for audio training tutorial (#12923)
    
    ---
    Commit 877c9deca authored by Frank Chen<frankchn@gmail.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Reverse change eb75ded6 so that internal tests will pass. (#12933)
    
    As support for int64 global steps is not ready in TPUs, I am reversing this change so that our internal performance and regression tests will pass.
    ---
    Commit 665966438 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable grpc_session_test.
    
    PiperOrigin-RevId: 168078694
    
    ---
    Commit 405def792 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Switch CallInliner to use CallGraph::VisitNodes.
    
    PiperOrigin-RevId: 168078645
    
    ---
    Commit aba3466f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Exposes Head and factory methods in tf.contrib.estimator.
    
    PiperOrigin-RevId: 168071246
    
    ---
    Commit b76565b39 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Some profiler fixes and cleanup.
    
    PiperOrigin-RevId: 168069346
    
    ---
    Commit 32ffc5a81 authored by Jonas<sauercrowd@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Just a dot in order to be consistent (#12919)
    
    added a dot to the `7` to make clear it's a float (like every other number)
    ---
    Commit 0753b0c79 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Scope the scalar cache in the context.
    
    PiperOrigin-RevId: 168065417
    
    ---
    Commit 48deb206b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate TFGAN features to third_party.
    
    PiperOrigin-RevId: 168060880
    
    ---
    Commit d2ae1311f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixing an issue in the BUILD file of the LSH ops.
    
    PiperOrigin-RevId: 168056645
    
    ---
    Commit 2f440eda4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expose NumpyReader for reading timeseries data.
    
    PiperOrigin-RevId: 168055838
    
    ---
    Commit be1916ce7 authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added functionality to allow `SqlDataset` to interpret a database column as various numeric types, including several integer types and `dtypes.float64`.
    
    PiperOrigin-RevId: 168055827
    
    ---
    Commit fa2000a0b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Supporting nightly windows pip packages.
    
    PiperOrigin-RevId: 168054959
    
    ---
    Commit a263ea626 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Treat eager tensors as constants during graph construction.
    
    Unless capturing is explicitly enabled.
    
    PiperOrigin-RevId: 168052675
    
    ---
    Commit 6e402d0d2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make TODO a bit more specific.
    
    PiperOrigin-RevId: 168051381
    
    ---
    Commit c779384bc authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added code example to the doc string for `SqlDataset`.
    
    PiperOrigin-RevId: 168049037
    
    ---
    Commit ff6dd474a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use self._in_graph_mode consistently in ResourceVariable
    instead of sometimes getting it from the context.
    
    Also: fix formatting of a comment and use a more precise test to detect
    if initial_value is set.
    PiperOrigin-RevId: 168047258
    
    ---
    Commit f331f528b authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removes "fast paths" which are not fast in eager mode.
    
    PiperOrigin-RevId: 168046278
    
    ---
    Commit 86f1713e5 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces TrainSpec and EvalSpec.
    
    PiperOrigin-RevId: 168040435
    
    ---
    Commit c8b9e92f0 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Move "register_function" to context.py
    
    This will allow function registration from other
    modules without having to import "function.py".
    (And besides, the function really does belong on the context).
    
    PiperOrigin-RevId: 168040411
    
    ---
    Commit 74137f994 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix signed int overflow issue in tensor_id.cc
    
    When a node name has a long numeric suffix, e.g.,
    "foo/y_0/gradient_debug_09684b60f2184c67b744721915034528" (as has happened with tfdbg GradientsDebugger),
    
    the parsing algorithm in ParseTensorName() may experience signed int overflow. Replacing the types with "unsigned int" resolves the issue.
    
    PiperOrigin-RevId: 168039195
    
    ---
    Commit 450c3b562 authored by Rohan Jain<rohanj@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Using rendezvous manager to pass args / rets between devices during function remote execution. This enables CPU->GPU remote device executions now.
    
    PiperOrigin-RevId: 168038285
    
    ---
    Commit 82cc6529f authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes the wording about StopIteration.
    
    PiperOrigin-RevId: 168034451
    
    ---
    Commit fb5588002 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a statement on install/index.md on what os are supported.
    
    PiperOrigin-RevId: 168032996
    
    ---
    Commit f83f6b9ef authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Handle higher-order HLOs (e.g. While) in CallInliner and test.
    
    PiperOrigin-RevId: 168029345
    
    ---
    Commit 8988ae365 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 167916124
    
    PiperOrigin-RevId: 168916710

commit c82a933f449e637ee83244d2c40162e24cdde0e1
Author: Sanjoy Das <sanjoy@google.com>
Date:   Thu Sep 14 16:06:55 2017 -0700

    Lower vector-matrix dot to LLVM IR if the RHS of the dot can be made
    column major.
    
    The naive dot lowering to LLVM IR (already present in XLA today) is
    cache efficient if the dot has LHS of shape [1,K]{1,0} and RHS of
    shape [K x N]{0,1}.  This change teaches the layout assignment pass to
    exploit this property by converting a constant RHS matrix to a column
    major layout when possible.
    
    Couple of related things I had to touch in this change:
    
     - In LayoutAssignmentTest.TupleLayout we used to generate a kCopy to satisfy
       the conflicting constraints between the result and the constant shapes, but
       with this change we change the layout of the constants themselves.  So the
       EXPECT_FALSE is now an EXPECT_TRUE.
    
     - The extra instruction layout constraints added at the end of
       CpuLayoutAssignment::AddBackendConstraints seemed redundant.  The layout
       assignment pass already tries to make all unconstrained buffers have the
       default row-major layout.  Moreover, they were blocking this optimization in
       some cases by introducing conflicting constraints.
    
     - The changes to literal_util.h have to be made to deal with the
       Literal::Relayout calls we now get on literals of various types.
    
    PiperOrigin-RevId: 168761204

commit bece65c6f3605f00a72e4163e7e6d5ccda10cd81
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Sep 13 09:19:44 2017 -0700

    Use a map instead of a vector of Children() in the BeamEntry.
    
    The assumption is that since the entries are sparse (they are all populated, but most are never Active()), using the map will save memory and make iterating over the Children() more efficient.
    
    PiperOrigin-RevId: 168548814

commit fcacb40d4c5e2874f176b27ca75e7a1ce31fd87c
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Sep 12 12:18:54 2017 -0700

    FirstReadyManager for scheduling nodes in VirtualScheduler.
    The current FIFOManager may yield inefficient scheduling; _Recv pushed to the
    FIFO blocks other nodes that can run before _Recv due to the node order in FIFO.
    FirstReadyManager picks a node with the earliest time_ready in the queue,
    avoiding this problem.
    
    Also, fixed VirtualPlacer to properly set device when Node's device name does not
    include job name and to set GPU:0 as default device.
    
    PiperOrigin-RevId: 168418455

commit f911e7b055988699f5facf7efe33363726a71183
Author: Brennan Saeta <saeta@google.com>
Date:   Mon Aug 14 18:13:55 2017 -0700

    Add shard_dimensions to TPUConfig
    
    Most CPU-based input pipeline image operations operate in the tensor layout NHWC. While this is reasonable for CPUs, may devices operate most efficiently using alternate layouts. (e.g. NVidia GPUs opt for NCHW). This change allows us to perform the layout reshapes on the CPU ahead of feeding them into the device. This change allows us to adopt non-batch-major image layouts while supporting automatic sharding. This is useful both for image inputs, as well as RNNs which sometimes would like to be time-major ordered.
    
    PiperOrigin-RevId: 165257772

commit a614eed8f8d76aee17fcbc80c9b44a3538131845
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 9 18:46:43 2017 -0700

    Changed formula for FTRL L1 normalization to be simpler and more efficient.
    
    PiperOrigin-RevId: 164804532

commit aa28b80bb56adeee31ad77167a923f2485ec9df6
Author: Derek Murray <mrry@google.com>
Date:   Wed Aug 9 15:23:22 2017 -0700

    [tf.contrib.data] Add `Dataset.prefetch()` transformation.
    
    This transformation is a simpler (and potentially more efficient)
    replacement for `Dataset.map(lambda x: x, num_threads=1,
    output_buffer_size=N)`, avoiding the overhead of function invocation
    and simplifying the synchronization slightly.
    PiperOrigin-RevId: 164781954

commit b55c0523f5d2a17fdd43a11a590dc59e63365ab6
Author: Derek Murray <mrry@google.com>
Date:   Wed Aug 9 15:23:22 2017 -0700

    [tf.contrib.data] Add `Dataset.prefetch()` transformation.
    
    This transformation is a simpler (and potentially more efficient)
    replacement for `Dataset.map(lambda x: x, num_threads=1,
    output_buffer_size=N)`, avoiding the overhead of function invocation
    and simplifying the synchronization slightly.
    PiperOrigin-RevId: 164781954

commit 85d4102862c781af2346b4aa568054522e8946ea
Author: Andrew Myers <andru@cs.cornell.edu>
Date:   Sat Jul 15 20:08:11 2017 -0400

    Adding generics to the Java API - Phase 1 (#11251)
    
    * Phase 1 of the proposed generic Java API.
    
    This adds new classes to represent each of the possible tensor types,
    and some scripting support for generating those classes. There is
    essentially no effect on existing classes, except that DataType is
    made slightly more efficient.
    
    All tests pass.
    
    * Addressed Asim's review.
    
    * Hoisted copyright into a separate declaration. Maybe it should go
    in a separate file?
    
    * Added private constructors to TF types and shortened their javadoc to be
    more standard.
    
    * Added more explanation about the enum relationship.
    
    * Used more-idiomatic import statement.
    
    * Rename zero column.
    
    * Removed the datatype code from tftypes.csv
    
    * Fix the default value for Double, add one for UInt8.
    
    * Got rid of 'boxed type' column in CSV file
    
    * Somehow I did not notice that TFType.java was not checked in.

commit b1f9e2c89eb007cb4b9483d08dcace1e45e84164
Author: RJ Ryan <rjryan@google.com>
Date:   Tue Jul 11 09:51:54 2017 -0700

    Add an axis parameter to tf.gather. Fixes GitHub issue #11223.
    
    This brings tf.gather closer to compatibility with numpy.take.
    
    To emulate gathering over an axis generally requires inefficient workarounds, e.g. transpose/gather/transpose. This technique is gaining popularity (hundreds of uses inside and outside of Google), so it is worth supporting efficiently.
    
    For an `[a_0, ..., a_i, ..., a_n]` tensor, gathering `N` elements from axis `i` requires `(a_0*...*a_i-1) * N` copies of `(a_i+1 * ... * a_n)` elements each. The CPU kernel does this with memcpy which is far more efficient than transpose/gather/transpose since it requires no intermediate allocations and copies. The GPU kernel does the same number of copies but in parallel across multiple hardware threads.
    
    Since this is a backwards incompatible change, this adds a "GatherV2" op with an axis input, and simultaneously supports backwards compatibility with "Gather" ops by defaulting to axis 0 if a 3rd input is not present.
    
    PiperOrigin-RevId: 161541416

commit a6773e98e97956b7adf3aa51eb3548261f51d6f7
Author: RJ Ryan <rjryan@google.com>
Date:   Mon Jul 10 16:41:33 2017 -0700

    Add a PadV2 op with support for specifying a pad value.
    
    Added a `constant_values` keyword argument to the tf.pad Python API for compatibility with numpy.pad. For now, only scalar values are supported. To efficiently support specifying a `[D, 2]` tensor for `constant_values` to pick per-dimension pre/post constant values will require adding Eigen and XLA support first.
    
    PiperOrigin-RevId: 161460091

commit dd951bb50d454f026083097b6d6122dae696259c
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Jul 5 16:56:41 2017 -0700

    This cl is a more efficient reimplementation of non max suppression making it significantly faster in practice by reducing the number of unnecessary IOU computations.
    
    PiperOrigin-RevId: 161023977

commit 38faead386d9d19b9af10150ac9d0cddd7b788e8
Author: Mark Heffernan <meheff@google.com>
Date:   Thu Jun 29 16:51:03 2017 -0700

    [XLA] Move HLO reachability into its own file and make update-able.
    As part of the CL, change the underlying representation in the reachability map to BitVectors which allows efficient update by OR'ing the vectors together.
    
    PiperOrigin-RevId: 160591849

commit cf7c008ab150ac8e5edb3ed053d38b2919699796
Author: Yifei Feng <fengyifei2026@gmail.com>
Date:   Wed Jun 28 11:07:44 2017 -0700

    Branch 160346151 (#11094)
    
    * Properly handle ops that don't have a CPU kernel
    
    PiperOrigin-RevId: 159655906
    
    * Selected BUILD cleanup in tensorflow/contrib/...
    
    PiperOrigin-RevId: 159673079
    
    * Remove redundant `get` calls on smart pointers
    
    PiperOrigin-RevId: 159675809
    
    * PiperOrigin-RevId: 159698321
    
    * Migrate kernels to boosted_trees.
    
    PiperOrigin-RevId: 159698656
    
    * Fix a bug in the memory optimizer when two inputs to a node are both recomputed
    
    PiperOrigin-RevId: 159700457
    
    * Fixed memory leak that can be triggered by a failed node evaluation
    
    PiperOrigin-RevId: 159707380
    
    * Updates get_started tutorial.
    
    PiperOrigin-RevId: 159709158
    
    * [XLA] Remove unused factory in local_service
    
    PiperOrigin-RevId: 159712806
    
    * Fix typo in docstring
    
    PiperOrigin-RevId: 159714414
    
    * Migrate ops for new version of TensorForest.
    
    PiperOrigin-RevId: 159718610
    
    * Added parameterized tests to reduce window tests.
    
    PiperOrigin-RevId: 159721784
    
    * Use C API to implement Operation.device property
    
    PiperOrigin-RevId: 159723490
    
    * Several Estimator changes:
    - support configurable input_fn calling in Estimator subclasses.
    - pass params and config to the input_fn.
    - allow callables for model_fn and input_fn.
    
    PiperOrigin-RevId: 159725554
    
    * Fixed the scalar output for shard api when outputs_from_all_shards=True.
    
    PiperOrigin-RevId: 159726444
    
    * Automated g4 rollback of changelist 159718610
    
    PiperOrigin-RevId: 159728380
    
    * Adding missing deps to targets in llvm.BUILD. This was only working in non-sandboxed builds.
    
    PiperOrigin-RevId: 159729295
    
    * [XLA:HLO] Move sequence functions from hlo_ordering.h to hlo_scheduling.h.
    
    This is required for upcoming changes to convert the sequence creation functions
    (and HeapSimulator and BufferAssignment) over to using the new
    Hlo{Dataflow,Alias}Analysis.
    
    It's required because otherwise there's a dependency cycle:
    
    Hlo{Dataflow,Alias}Analysis depends on HloOrdering
    CreateMemoryMinimizingSequence will depend on Hlo{Dataflow,Alias}Analysis
    
    There's already a cycle here, if both HloOrdering and
    CreateMemoryMinimizingSequence are in the same file.  Also note that:
    
    MinimumMemoryForSequence depends on HeapSimulator
    HeapSimulator will depend on Hlo{Dataflow,Alias}Analysis
    Hlo{Dataflow,Alias}Analysis depends on HloOrdering
    
    Splitting out the sequence functions resolves the cycle.
    
    Refactoring only; no functional changes.
    
    PiperOrigin-RevId: 159731836
    
    * [XLA:HLO] Split Hlo{Value,Buffer} out of Hlo{Dataflow,Alias}Analysis.
    
    This will make dependencies cleaner for upcoming CLs that will convert
    HeapSimulator and HloOrdering to use the new analyses.
    
    No change in functionality.
    
    PiperOrigin-RevId: 159737265
    
    * Internal change
    
    PiperOrigin-RevId: 159738215
    
    * Suggest people need to do some build environment ./configur'ing.
    
    Fixes #4279
    
    PiperOrigin-RevId: 159738412
    
    * Rewrite SameDefinedShape function in ShapeRefiner
    
    PiperOrigin-RevId: 159745894
    
    * [XLA] Remove xla_cpu_*_eigen flags from CPU backends.
    
    These flags are currently de-facto unused; parallelism should be controlled
    through the cpu_parallel backend. For configuring Eigen, if needed, the options
    should be piped more directly to the code.
    
    PiperOrigin-RevId: 159746509
    
    * Updates layers tutorial and corresponding example.
    
    PiperOrigin-RevId: 159749528
    
    * Further BUILD cleanup
    
    PiperOrigin-RevId: 159749869
    
    * Use more efficient squared_difference
    
    PiperOrigin-RevId: 159751209
    
    * Add log_step_count_steps to RunConfig and allow it to flow to the MonitoredSession.
    
    PiperOrigin-RevId: 159753935
    
    * [XLA] Remove xla_hlo_test_generate_hlo_graph, which is now redundant.
    
    PiperOrigin-RevId: 159755688
    
    * Do not use SSE4.1 instructions on Android builds.
    
    PiperOrigin-RevId: 159756104
    
    * Add nonpublic helper `tf.distributions.util.tridiag` op.
    
    PiperOrigin-RevId: 159757904
    
    * [XLA] Remove dead "in-client" code.
    Remove Service::runs_in_client_process_ field and it's dead user. This was
    previously used by the "InProcess" methods which have been replaced with
    the LocalClient API.
    
    PiperOrigin-RevId: 159759455
    
    * [tf contrib seq2seq] Add monotonic attention mechanisms
    
    * Add monotonic_attention and safe_cumprod helper functions.
    * Add _BaseMonotonicAttentionMechanism base class.
    * Add BahdanauMonotonicAttention and LuongMonotonicAttention classes.
    
    These attention mechanisms are proposed in
    Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck,
    "Online and Linear-Time Attention by Enforcing Monotonic Alignments."
    ICML 2017.  https://arxiv.org/abs/1704.00784
    
    PiperOrigin-RevId: 159760073
    
    * Add ability for argmax to output int32 indices.  Default remains int64.
    
    Change is made in a backwards and forward compatible manner, since
    we add a new attribute with a default that remains the same, and
    simply register a few new kernels.
    
    PiperOrigin-RevId: 159761347
    
    * Automated g4 rollback of changelist 159746509
    
    PiperOrigin-RevId: 159763112
    
    * Raise ValueError if invalid dtype for random_uniform.
    
    PiperOrigin-RevId: 159764956
    
    * Internal change.
    
    PiperOrigin-RevId: 159769520
    
    * Support zero shapes for random_poisson. This matches random_uniform.
    
    PiperOrigin-RevId: 159771215
    
    * Blacklist the quantized ops since they have too many issues (incorrect shape
    functions, memory corruptions, ...)
    
    PiperOrigin-RevId: 159772801
    
    * Fixed the shape functions of the QuantizedAdd and QuantizedMul ops
    
    PiperOrigin-RevId: 159772841
    
    * Switch from assigning namedtuple.__new__.__defaults__ to overwriting __new__.
    
    Assigning __defaults__ relies on an implementation detail of CPython, confuses
    type checkers (and developers :)), and is error-prone since it doesn't make the
    relationship between parameter names and default values explicit.
    This CL switches to overloading __new__ instead.
    
    PiperOrigin-RevId: 159773922
    
    * Made sure that we can call the constant folding code twice safely.
    
    PiperOrigin-RevId: 159781607
    
    * Added batch_matmul op dependence to android_extended_ops
    
    PiperOrigin-RevId: 159787178
    
    * Fixes a TODO in head_test.
    
    PiperOrigin-RevId: 159789178
    
    * When configuring per-session thread pools, allow
    a pool to be a global pool. This allows a division
    between large and small pools, without needing to make
    new pool for each session.
    
    PiperOrigin-RevId: 159789678
    
    * Add a multi-head TensorForest estimator.
    
    PiperOrigin-RevId: 159820487
    
    * Have RestoreV2's shape fn set all outputs to unknown shape.
    
    PiperOrigin-RevId: 159835723
    
    * VectorExponential added to distributions.
    
    PiperOrigin-RevId: 159840822
    
    * Fold as many nodes as possible instead of giving up if there is any error.
    
    PiperOrigin-RevId: 159841935
    
    * Removed deprecated summary usage from estimators.
    Made name_space usage consistent.
    
    PiperOrigin-RevId: 159846928
    
    * Adding missing license notice to toolchain build files
    
    PiperOrigin-RevId: 159847551
    
    * [XLA] Remove unused flags and move debugging flag to debug options.
    
    PiperOrigin-RevId: 159849759
    
    * Fixes some docstrings in feature_column.
    
    PiperOrigin-RevId: 159850619
    
    * TpuEstimator: Replicate the input_fn to the worker CPU for each shard.
    
    The batch size is configured as follows:
    The user may specify a global batch size in their hyperparameters. If the 'batch_size' field is set, then we convert the global batch size into a per-shard batch size by dividing by num_shards before running their input_fn.
    
    PiperOrigin-RevId: 159851773
    
    * Modify beam search decoder to use symbolic shape for vocab size if the static shape is not present.
    
    PiperOrigin-RevId: 159852297
    
    * Generalize cluster initialization to span multiple mini-batches if necessary.
    
    PiperOrigin-RevId: 159852557
    
    * Use a single threaded session for SDCALinearRegressorTest to
    avoid incorrect threading test failures (tsan).
    
    PiperOrigin-RevId: 159852818
    
    * Migrate ops for new version of TensorForest.
    
    PiperOrigin-RevId: 159852889
    
    * Replaced constant inputs with variables to ensure most of the graph doesn't get
    optimized away
    
    PiperOrigin-RevId: 159853171
    
    * For candidate sampling, add facility to colocate the logit computation with the sharded embeddings.
    
    PiperOrigin-RevId: 159854706
    
    * Added a utility to create parsing spec for regressors (canned estimator)
    
    PiperOrigin-RevId: 159855254
    
    * Fix cuda_kernel_helper_test. std::numeric_limits<int32>::max() doesn't pass, so
    I didn't use that.
    
    PiperOrigin-RevId: 159869169
    
    * In tfcompile, prune nodes that are not reachable from the fetches before
    building the Graph. This allows loading a graph that contains ops not
    needed for the compiled binary.
    
    PiperOrigin-RevId: 159869692
    
    * Fix bugs related to distributions over integers.
    
    - Ensure that the max number of categories does not exceed largest integer-form float.
    - Make dtype inference consistent between Categorical and Multinomial
    distributions.
    - Improve documentation to better reflect that the Categorical
    distribution is analogous to `argmax{OneHotCategorical}` (itself being
    identical to `argmax{Multinomial(p,n=1)}` but not Multinomial.
    - Fix validation_args Heisenberg uncertainty: only validation logic should live under self.validate_args. E.g., validate_args=True would sometimes imply `x=floor(x)` which changes behavior thus making debugging impossible because enabling validation *changes* values.
    - Corrected `Geometric` swapping of validate_args` and `allow_nan_stats` default-values.
    
    Fixes #10149
    
    PiperOrigin-RevId: 159872532
    
    * Make HloModule clonable
    
    This CL makes HloModule clonable, which is necessary when we want to run the same compilation twice with the same input.
    
    PiperOrigin-RevId: 159874256
    
    * Internal change.
    
    PiperOrigin-RevId: 159876942
    
    * Implement alternative `monte_carlo.expectation_v2`. This function implements
    the reparameterization and score-gradient tricks and does not depend on
    tf.Distribution like inputs.
    
    PiperOrigin-RevId: 159877923
    
    * In SE_ASSIGN_OR_RETURN change ConsumeValueOrDie to the preferred std::move ValueOrDie.
    
    PiperOrigin-RevId: 159879754
    
    * If rank is unknown, do not add output shapes to transpose nodes.
    
    PiperOrigin-RevId: 159879840
    
    * Move sparse_fill_empty_rows to new, *significantly* faster, C++ kernel for everyone.
    
    Also fix a bug in the C++ op when the input ST has 0 elements.
    
    PiperOrigin-RevId: 159880044
    
    * Add support of label_keys to DebugClassifier
    
    PiperOrigin-RevId: 159883986
    
    * Register devices under their legacy names
    
    Because some higher level APIs continue to use the legacy name format,
    when using ClusterSpec propagation, we need to ensure that we register
    the devices under their legacy names as well as their canonical names.
    
    PiperOrigin-RevId: 159885777
    
    * [BatchNorm] Minor fixes to TF doc
    
    PiperOrigin-RevId: 159886125
    
    * Generating TBAA metadata causes the LLVM to miscompile after
    https://reviews.llvm.org/rL305938).  Disable TBAA (to stop the miscompiles)
    while we fix the root issue.
    
    PiperOrigin-RevId: 159895736
    
    * Improve score-trick to be a valid Csiszar f-Divergence yet numerically stable.
    
    PiperOrigin-RevId: 159896013
    
    * Support advisor in all places (Command line, APIs)
    Add expensive operation checker
    
    PiperOrigin-RevId: 159897279
    
    * Added canned estimators to Tensorflow library. List of added estimators:
    * DNNClassifier
    * DNNRegressor
    * LinearClassifer
    * LinearRegressor
    * DNNLinearCombinedClassifier
    * DNNLinearCombinedRegressor
    
    PiperOrigin-RevId: 159898954
    
    * Alligned how model-fns handled params among linear/dnn/combined estimators.
    
    PiperOrigin-RevId: 159899925
    
    * Fixed cmake tests.
    
    PiperOrigin-RevId: 159901417
    
    * [XLA:CPU] Add VLOGs to cpu_compiler.cc
    
    PiperOrigin-RevId: 159902919
    
    * Make occurence (op run times and op definition) selectable
    in all views to address the loop problem.
    
    When a node is in loop, its execution times are accumulated, its run times
    will increase.
    
    PiperOrigin-RevId: 159912429
    
    * [XLA] Small error message improvement in binop shape inference.
    
    PiperOrigin-RevId: 159920109
    
    * Follow upstream API change from r306058.
    
    PiperOrigin-RevId: 159938416
    
    * [TF:XLA] Update LLVM to upstream revision r306085.
    
    PiperOrigin-RevId: 159946562
    
    * [XLA] Remove unused xla_cpu flag and move another to DebugOptions.
    
    PiperOrigin-RevId: 159952124
    
    * Updates linear.md tutorial
    
    PiperOrigin-RevId: 159956867
    
    * Add TraceMe instrumentation of RunStep in GRPC distributed runtime.
    A unique ID is added to each RunStep call that allows the client and server
    events to be correlated.
    
    PiperOrigin-RevId: 159956950
    
    * [XLA] Add general F32 implementation for ReducePrecision operation.
    
    This only tests with parameter inputs (which is needed to ensure we actually test on GPUs as well as CPUs); there's no point in separately testing with constants.
    
    PiperOrigin-RevId: 159961430
    
    * Java: NativeLibrary: Fix URL in error message.
    
    And add some detail.
    Inspired by #11015
    
    PiperOrigin-RevId: 159962478
    
    * Increase rtol for util_test.
    
    PiperOrigin-RevId: 159971136
    
    * Re-enable IR dumping for the sequential CPU backend.
    
    PiperOrigin-RevId: 159974126
    
    * tfdbg: a few minor fixes and improvements
    
    * Let DumpingDebugWrapperSession and DumpingDebugHook create session_root if it doesn't exist
    * Add README.md to tensorflow/python/debug
    * Add section "Debugging Keras Models with TFDBG" in debugger.md
    
    PiperOrigin-RevId: 159976070
    
    * Add None check for save_path when restoring checkpoints as if something is wrong in tf.train.latest_checkpoint, it will often return None and it's nice to have a common sense check in restore for this. This way log.error says what has happened.
    
    PiperOrigin-RevId: 159979481
    
    * Don't crash if a metagraph fails to load.
    
    PiperOrigin-RevId: 159981628
    
    * Prepare to not include node_def.proto.h in node_def_util.h
    
    The goal is to make kernels mostly independent of proto headers, which will let
    us lock down our .so imports.  This CL makes a bunch of .cc files
    either include node_def.proto.h themselves or not need the definition of
    NodeDef; a second CL will make node_def_util.h not include node_def.proto.h.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 159982117
    
    * Add a few diagnostic flags to help narrow down issues with the LLVM
    backends.
    
    PiperOrigin-RevId: 159982441
    
    * Updated wide-n-deep tutorial code to use core version of estimators and feature-columns.
    
    PiperOrigin-RevId: 159984663
    
    * Modify ControlFlowContext to also respect import_scope in 'values_' and keys of 'external_values_'
    
    PiperOrigin-RevId: 159985290
    
    * Add item's graph to partition_graphs in virtual cluster's run method.
    Put node op name in timeline_label instead of node_name.
    
    PiperOrigin-RevId: 159986583
    
    * Use short-proto for logging purposes.
    
    A short proto will be output on a single log line, making it
    easier for certain automated tools to handle.
    
    PiperOrigin-RevId: 159994005
    
    * Sinh, ArcSinh, Cosh, LogCosh functions added to distributions/python/ops/trig.
    Care is taken to ensure a fair bit of stability.
    
    PiperOrigin-RevId: 159995514
    
    * Updates some examples in examples/learn.
    
    PiperOrigin-RevId: 159996397
    
    * Add kernel tests for boosted_trees.
    
    PiperOrigin-RevId: 160002696
    
    * Avoid doing unecessary work in the OptimizeGraph() function whenever possible
    
    PiperOrigin-RevId: 160003173
    
    * Use std::shared_ptr instead of core::RefCounted for Node::Properties
    
    Also changes Node::Properties to a struct and removes underscores from public member variables. This change should make it easier to work with Properties moving forward as the refcount will be automatically updated.
    
    PiperOrigin-RevId: 160003281
    
    * Make the CPU compiler dump optimized IR along with the unoptimized IR.
    
    PiperOrigin-RevId: 160005257
    
    * Disable flaky run_metadata_test.
    
    PiperOrigin-RevId: 160015399
    
    * BUILD cleanup in tensorflow/tools/...
    
    PiperOrigin-RevId: 160018623
    
    * SinhArcSinh bijector added.
    
    This two-parameter diffeomorphism from R --> R allows for skewness and fatter
    or thinner tails.  See docstring and also
    http://oro.open.ac.uk/22510/1/sinhasinh.pdf
    
    PiperOrigin-RevId: 160019380
    
    * Avoid hardcoded names for temporary files in tests.
    
    These tests (and examples that are run as tests) were using hardcoded names for
    temporary files.  This failed when multiple copies of these tests were run in
    parallel, or even successively by different users, where the second run could
    not overwrite files left by the first.
    
    This change uses the TEST_TMPDIR environment variable used by bazel's test
    runner to choose a temporary directory.   If that directory is not set,
    /tmp is used, as before.
    
    PiperOrigin-RevId: 160026924
    
    * Fix multinomial doc-string, input arg logits expects to log-probabilities and not log-odds.
    
    PiperOrigin-RevId: 160036709
    
    * Made TensorFlow documentation on LSTMs slightly more accurate.
    
    PiperOrigin-RevId: 160047054
    
    * Follow LLVM/ORC upstream API change in r306166.
    
    PiperOrigin-RevId: 160108102
    
    * Move resampler from sonnet to contrib.
    
    PiperOrigin-RevId: 160134565
    
    * [TPUEstimator] Make input_fn invoked properly with eval on CPU.
    
    PiperOrigin-RevId: 160151890
    
    * Deletes iris_val_based_early_stopping example, which uses deprecated ValidationMonitor.
    
    PiperOrigin-RevId: 160154863
    
    * [XLA] Move HLO dumping flags from service_flags to debug_options_flags
    
    This also removes the duplication in the xla_generate_hlo_graph flag.
    
    This CL also moves the actual dumping logic from Executable to the
    hlo_graph_dumper namespace, where it belongs; this is in preparation for
    removing the hlo_dumper callback altogether, since it isn't serving any role
    beyond what a direct call to hlo_graph_dumper would have (b/62872831 has more
    details).
    
    PiperOrigin-RevId: 160154869
    
    * Fix missing variable unref
    
    Direct leak of 56 byte(s) in 1 object(s) allocated from:
        #0 0xf5ee272 in operator new(unsigned long) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf5ee272)
        #1 0x1b51394c in tensorflow::AssignVariableOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*)::'lambda'(tensorflow::Var**)::operator()(tensorflow::Var**) const (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b51394c)
        #2 0x1b5136c0 in std::_Function_handler<tensorflow::Status (tensorflow::Var**), tensorflow::AssignVariableOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*)::'lambda'(tensorflow::Var**)>::_M_invoke(std::_Any_data const&, tensorflow::Var**) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b5136c0)
        #3 0x1b50b289 in std::function<tensorflow::Status (tensorflow::Var**)>::operator()(tensorflow::Var**) const (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b50b289)
        #4 0x1b50af88 in tensorflow::Status tensorflow::ResourceMgr::LookupOrCreate<tensorflow::Var>(basic_string<char, std::char_traits<char>, std::allocator<char> > const&, basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Var**, std::function<tensorflow::Status (tensorflow::Var**)>) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b50af88)
        #5 0x1b50ac10 in tensorflow::Status tensorflow::LookupOrCreateResource<tensorflow::Var>(tensorflow::OpKernelContext*, tensorflow::ResourceHandle const&, tensorflow::Var**, std::function<tensorflow::Status (tensorflow::Var**)>) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b50ac10)
        #6 0x1b512f1e in tensorflow::AssignVariableOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b512f1e)
        #7 0x1d1881c7 in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1d1881c7)
        #8 0xf96e0fe in tensorflow::KernelAndDevice::Run(std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf96e0fe)
        #9 0xf94f9c8 in TFE_Execute (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf94f9c8)
        #10 0xf94356d in TFE_Py_Execute(TFE_Context*, int, char const*, tensorflow::gtl::InlinedVector<TFE_TensorHandle*, 4>*, _object*, tensorflow::gtl::InlinedVector<TFE_TensorHandle*, 2>*, TF_Status*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf94356d)
    
    PiperOrigin-RevId: 160160101
    
    * Simplify strided_slice's shape handling
    
    Now that TensorShape and PartialTensorShape share memory representations, there's no need for an abstract class that makes TensorShape and TensorShapeProto look the same.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 160161618
    
    * Added a tool to report the static information that can be extracted from a TF model.
    
    PiperOrigin-RevId: 160162256
    
    * Properly handle RefEnter, RefExit and RefNextIteration nodes.
    
    PiperOrigin-RevId: 160162338
    
    * Switch tfprof to use proto3
    
    PiperOrigin-RevId: 160163483
    
    * Fixes to cuda_config.h.
    
    PiperOrigin-RevId: 160168545
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160171187
    
    * Adds notes to prevent overfitting for Experiment continous_train_and_eval.
    
    PiperOrigin-RevId: 160172692
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 160172985
    
    * Merge changes from github.
    END_PUBLIC
    
    Note: this CL will break builds.  cl/159887762 to follow to fix all the breakages.
    
    ---
    Commit 2336cdf7f authored by Maxwell Paul Brickner<mbrickn@users.noreply.github.com>
    Committed by gunan<gunan@google.com>:
    Updated link to use HTTPS (#10998)
    
    Howdy!
    
    I just updated a link to use https instead of http.
    
    Thanks!
    ---
    Commit ad0892df1 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Luke Iwanski<luke@codeplay.com>:
    [OpenCL] Fixes run_metadata_test for SYCL
    
     This test is designed to test CUDA specific behavior
    
    ---
    Commit 6b37a0725 authored by Todd Wang<toddwang@gmail.com>
    Committed by GitHub<noreply@github.com>:
    Update comments
    ---
    Commit 1699d904a authored by John Lawson<john@codeplay.com>
    Committed by Luke Iwanski<luke@codeplay.com>:
    [OpenCL] Fixes CUDA specific test run on SYCL (#56)
    
    The testBadParentValuesOnGPU should only be run on CUDA devices, as the
    test checks for particular CUDA behaviour. We don't actually provide a
    SYCL kernel for GatherTree and so it's not a problem that the tests
    don't target SYCL.
    ---
    Commit 3c1946230 authored by myPrecious<Moriadry@users.noreply.github.com>
    Committed by Shanqing Cai<cais@google.com>:
    Java API to get the size of specified input list of operations. (#10865)
    
    * Java API to get the size of specified input list of operations
    
    * remove unnecessary explain to avoid bring a new term to users.
    
    ---
    Commit e911c7480 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Luke Iwanski<luke@codeplay.com>:
    [OpenCL] REGISTER -> REGISTER6
    
    ---
    Commit fbf6c4cec authored by superryanguo<superryanguo@gmail.com>
    Committed by superryanguo<superryanguo@gmail.com>:
    Simplify the Quickstart section with the weblink is better
    
    ---
    Commit 72e2918cc authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by Taehoon Lee<taehoonlee@snu.ac.kr>:
    Fix typos
    
    ---
    Commit 90c4406b7 authored by Rishabh Patel<patelrishabh@users.noreply.github.com>
    Committed by GitHub<noreply@github.com>:
    Correct the learning rate as per the code snippet
    ---
    Commit 03da61134 authored by Todd Wang<toddwang@gmail.com>
    Committed by GitHub<noreply@github.com>:
    Update ir_array.cc
    ---
    Commit 2df6cd3ac authored by Todd Wang<toddwang@gmail.com>
    Committed by GitHub<noreply@github.com>:
    Another try
    ---
    Commit af0cbace1 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Transpose to go through Eigen (#10321)
    
    ---
    Commit fc7361081 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Registers RGBToHSV and HSVToRGB (#91) (#10848)
    
    * [OpenCL] Added RGBToHSV and HSVToRGB
    
    * Aligning '\'
    ---
    Commit 832894ef8 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Registers AdjustContrastv2 (#10949)
    
    * [OpenCL] Registers AdjustContrastv2 (#93)
    
    * [OpenCL] Extended adjust_contrast_op_benchmark_test for OpenCL (#96)
    
    * [OpenCL] Extended adjust_contrast_op_benchmark_test for OpenCL
    
    * simplified to #ifndef
    
    * Changed to "#if GOOGLE_CUDA"
    
    * Update adjust_contrast_op_benchmark_test.cc
    
    * Added comments
    
    ---
    Commit cb4c2f8d1 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Make TransferBufferToInFeed not virual so it compiles.
    
    ---
    Commit e89f04d80 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Fix calling Literal member functions.
    
    ---
    Commit 15a8df724 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Fix mac build
    clone from meheff's change:
    [XLA] Change return type of DeviceAssignment::Deserialize to fix build
    breakage on mac.
    The mac build had the following error:
    
    error: incomplete type 'xla::DeviceAssignment' used in type trait
    expression
    
    This was due to a static method returning a StatusOr<DeviceAssignment>
    inside of the definition of DeviceAssignment.
    
    ---
    Commit a54d43fa4 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Replace LiteralUtil to Literal in compiler/plugin/executor
    
    ---
    Commit 88a6bb80c authored by Guenther Schmuelling<guschmue@microsoft.com>
    Committed by Guenther Schmuelling<guschmue@microsoft.com>:
    expand inline for debug builds to limit number of symbols
    
    ---
    Commit 62fb49d31 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Fix visibility error for contrib/remote_fused_graph/pylib/BUILD.
    
    ---
    Commit 4c75252f2 authored by Mark Neumann<markn@allenai.org>
    Committed by Mark Neumann<markn@allenai.org>:
    fix initial test values to avoid numerical instability
    
    ---
    Commit b58d98353 authored by sj6077<epik03sj@gmail.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    Fixes of AutoParallel bug (#10368)
    
    * Fix the bug that auto_parallel could replicate variable snapshot name
    
    * Use NodeName in grappler:utils instead of substr, convert variables->variable_def of grappler item
    
    * remove variable_def from grappler item, exclude snapshot nodes from dont_replicate_nodes in auto_parallel
    
    ---
    Commit a286b7db8 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Make debug_test slice integer.
    
    ---
    Commit 97fcfdfa6 authored by Toby Boyd<tobyboyd@google.com>
    Committed by GitHub<noreply@github.com>:
    Fixed path to seq2seq.py and minor formatting
    ---
    Commit 63c1befb8 authored by Anish Shah<shah.anish07@gmail.com>
    Committed by Anish Shah<shah.anish07@gmail.com>:
    Improve docs for tf.nn.depthwise_conv2d_native
    
    ---
    Commit 8d42202b2 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Fix mismatched delete in mkl_tfconv_op.cc
    
    This fix fixes mismatched new[]-delete in mkl_tfconv_op.cc
    
    (the file went through clang-format so there are some additional
    changes)
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 26301bd55 authored by Danny Goodman<goodman.danny@gmail.com>
    Committed by Danny Goodman<goodman.danny@gmail.com>:
    fix error format
    
    ---
    Commit b3f33ad46 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make changes to prepare for the fused option of batch norm to be set to None (None means using fused batch norm if possible).
    
    PiperOrigin-RevId: 159649743
    
    ---
    Commit a4a469832 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add tests for select ops and while loops that produce tuples that contain predicates.
    
    PiperOrigin-RevId: 159645900
    
    ---
    Commit 980d3f2be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use C API to implement Operation.name property
    
    This name property is used in many existing tests including those that
    already run with C API enabled (math_ops_test, framework_ops_test,
    session_test, session_partial_run_test, math_ops_test_gpu, etc).
    
    PiperOrigin-RevId: 159645767
    
    ---
    Commit 26239c706 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Previously we didn't have an implementation of BatchNormInference and BatchNormTraining, which gives a linker error if anyone ever tries to call that. A dummy implementation is friendlier than a linker error.
    
    PiperOrigin-RevId: 159645612
    
    ---
    Commit f671c5caa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 159570549
    
    PiperOrigin-RevId: 160182040
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160183349
    
    * Merge changes from github followup.
    
    PiperOrigin-RevId: 160183498
    
    * Automated g4 rollback of changelist 160183498
    
    PiperOrigin-RevId: 160189134
    
    * Automated g4 rollback of changelist 160182040
    
    PiperOrigin-RevId: 160190881
    
    * [XLA] Disallow fuse X into Y if there are paths from X to Y which don't fuse
    
    Just because X can fuse into all of its consumers does not mean that those
    consumers can fuse into anything. Depending on the structure of the graph, this
    can either result in no performance win at all or, in the case of recurrent
    networks, a big performance deficit.
    
    PiperOrigin-RevId: 160194058
    
    * First draft of Tensors segment of the programmer's guide.
    
    PiperOrigin-RevId: 160196550
    
    * First draft of variables unit of programmer's guide.
    
    PiperOrigin-RevId: 160196566
    
    * Make xla::Literal moveable.
    
    PiperOrigin-RevId: 160197273
    
    * Automated g4 rollback of changelist 159897279
    
    PiperOrigin-RevId: 160198598
    
    * Updates text_classification example.
    
    PiperOrigin-RevId: 160200457
    
    * Fix backward compatibility test broken by rollback.
    
    PiperOrigin-RevId: 160222187
    
    * Support advisor in all places (Command line, APIs)
    Add expensive operation checker
    
    PiperOrigin-RevId: 160222348
    
    * [XLA] Simplify the fusion heuristic
    
    We had two different aspects of the fusion heuristic:
    - Don't fuse a producer into a consumer if there exists a path from the
      producer to the consumer which cannot be fused.
    - Don't fuse a producer into a consumer if any consumer of the producer cannot
      fuse.
    
    These can be combined into one, simpler, heuristic.
    
    PiperOrigin-RevId: 160222771
    
    * Automated g4 rollback of changelist 160196566
    
    PiperOrigin-RevId: 160222930
    
    * Automated g4 rollback of changelist 160196550
    
    PiperOrigin-RevId: 160222942
    
    * Lets the HParam parser also accept True and False as inputs, since that's how python prints booleans.
    
    PiperOrigin-RevId: 160234658
    
    * Automated g4 rollback of changelist 155070869
    
    PiperOrigin-RevId: 160249526
    
    * [TF:XLA] Inline the sigmoid operation instead of mapping it elementwise.
    
    PiperOrigin-RevId: 160274436
    
    * Make sure all convolution tests are testing non-trivial cases, i.e. where not all inputs are 0, leading to an all-0 output, which masks most possible bugs.
    We do not check-fail on 0-sized dimensions as tests for these special cases
    exist.
    
    PiperOrigin-RevId: 160274593
    
    * Explicitly use "dns" URI scheme when using DNS names or literal IP
    addresses with gRPC.  This avoids problems in environments in which the
    default URI scheme is something other than "dns".
    
    PiperOrigin-RevId: 160276862
    
    * Add RWSE (root weighted squared error) to the WALS estimator.
    
    PiperOrigin-RevId: 160276937
    
    * Don't include node_def.proto.h in node_def_util.h
    
    The goal is to make kernels mostly independent of proto headers, which will let us lock down our .so imports.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 160278032
    
    * [XLA] Add tuple support to Literal::CreateFromShape.
    
    PiperOrigin-RevId: 160278561
    
    * Updates some more examples in examples/learn.
    
    PiperOrigin-RevId: 160278757
    
    * Automated g4 rollback of changelist 160278032
    
    PiperOrigin-RevId: 160280961
    
    * Fixed the bug that Estimator does not make deepcopy of params in constructor
    
    PiperOrigin-RevId: 160281247
    
    * Clean out the config and params in TPUEstimator.
    
    PiperOrigin-RevId: 160281507
    
    * [XLA] Remove the "hlo dumper" parameter of xla::Compiler and its piping.
    
    This dumper is no longer necessary since the restructuring of HLO dumping and
    the addition of MaybeDumpHloModule which heeds to the right flags. The
    remaining bits didn't have additional functionality, but constituted a lot of
    boilerplate that has to be propagated throughout the backends.
    
    PiperOrigin-RevId: 160281798
    
    * [TF:XLA] Refactor the sigmoid op as a rescaled tanh.
    
    PiperOrigin-RevId: 160282472
    
    * Fix uninitialized values in TensorForest code.
    
    PiperOrigin-RevId: 160284420
    
    * [TF:XLA] Update Tensorflow LLVM release to upstream r306370.
    
    Fix broken XLA build.
    
    PiperOrigin-RevId: 160284588
    
    * tfdbg example: fix --tensor_size issue in debug_fibonacci
    
    PiperOrigin-RevId: 160290541
    
    * [SE] ThenConvolveWithAlgorithm vlogs algorithm configs.
    
    PiperOrigin-RevId: 160292762
    
    * Fix documentation of Estimator class (invalid quotes).
    
    PiperOrigin-RevId: 160292803
    
    * Shrink the test size to avoid OOM error on old GPUs.
    
    PiperOrigin-RevId: 160292834
    
    * [TF:XLA] Reject operators with resource outputs on CPU and GPU devices.
    
    We were checking for resource inputs but not resource outputs, which led to accidental fusion of some TensorArray ops on CPU and GPU.
    
    PiperOrigin-RevId: 160294302
    
    * Add a functionality of remote fused graph transformation to fuse graphs by op type
    
    PiperOrigin-RevId: 160300039
    
    * Cudnn compatible LSTMCell and LSTMBlockCell
    
    PiperOrigin-RevId: 160300668
    
    * [XLA] Remove "operand" argument from HandleReducePrecision.
    
    PiperOrigin-RevId: 160301461
    
    * Added more reduce window tests.
    
    PiperOrigin-RevId: 160301509
    
    * Updates more text classification examples in examples/learn.
    
    PiperOrigin-RevId: 160305131
    
    * Use C API to implement Operation._output_types
    
    This change first converts the _output_types member to a property and
    then implements it using C API if it is enabled.
    
    PiperOrigin-RevId: 160306227
    
    * Add more tests for BatchNormTraining.
    RELNOTES: n/a
    
    PiperOrigin-RevId: 160307959
    
    * Update path to print_selective_registration_header.py in comment
    
    PiperOrigin-RevId: 160308173
    
    * Migrate TensorForest v4 python to contrib.
    
    PiperOrigin-RevId: 160308805
    
    * Automated g4 rollback of changelist 159454657
    
    PiperOrigin-RevId: 160314706
    
    * TESTFIX:  distributions:trig_test wasn't passing in ASAN mode.
    
    PiperOrigin-RevId: 160315597
    
    * tfdbg doc: fixes and improvements
    
    PiperOrigin-RevId: 160318411
    
    * Add a time estimation to HloCostAnalysis and represent properties as a map so that adding more properties will be easier, e.g. in a sub-class.
    
    PiperOrigin-RevId: 160318494
    
    * tfdbg: revert dns:/// prefix in gRPC mode
    
    PiperOrigin-RevId: 160319348
    
    * Moves TensorCApi from c_api.cc to c_api_internal.h, where it can be used
    by other code that require access to the underlying TensorBuffers.
    
    PiperOrigin-RevId: 160323362
    
    * Readd the new tensors and variables documents, with tests passing.
    
    PiperOrigin-RevId: 160324191
    
    * Make ResourceHandle not be a proto
    
    I'm trying to make core/kernels independent of protos.  Currently the dtype ResourceHandle is itself a proto.  After this CL, ResourceHandle is a normal C++ type which gets converted to/from ResourceHandleProto at (de)serialization time.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 160329002
    
    * Minor cleanup: remove unused dependencies and inclusions
    
    PiperOrigin-RevId: 160334030
    
    * Add name_scopes to mnist_deep.py for a cleaner graph layout.
    
    PiperOrigin-RevId: 160338775
    
    * Add note about `tf.test.mock` to docs for `tf.test`
    
    PiperOrigin-RevId: 160338811
    
    * Internal change.
    
    PiperOrigin-RevId: 160339087
    
    * Fix bugs in ScatterNd and add ScatterNdNonAliasingAdd.
    
    tf.scatter_nd_non_aliasing_add acts similarly to tf.scatter_nd_add but
    works on non-ref objects (i.e., Tensors -- not Variables).  This means
    it has a gradient with respect to the primary input as well as the
    updates.  It does its best to avoid making extra copies of the input.
    
    PiperOrigin-RevId: 160339328
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160340888
    
    * Add checkpoint conversion for models that use the attention mechanism implemented in tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py.
    
    PiperOrigin-RevId: 160340994
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 160341769
    
    * Merge changes from github.
    
    PiperOrigin-RevId: 160344052
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160346151
    
    * Load py_test in tensorflow/contrib/boosted_trees/BUILD to fix pip test
    visibility failures.
    
    * Disable boosted_trees tests on mac while they are being debugged.

commit 2d44813882ea2307c029223e6ab50ea847e411a1
Author: Sergio Guadarrama <sguada@google.com>
Date:   Wed Jun 21 15:14:26 2017 -0700

    Use more efficient squared_difference
    
    PiperOrigin-RevId: 159751209

commit fa75f26351f42e4fd3fc89b553d7919a6f147e41
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jun 15 12:53:23 2017 -0700

    Introduce Predictor, an interface for efficient, repeated inference.
    
    PiperOrigin-RevId: 159141010

commit 1b5235fd897f7ea5cffc715300f67b4dc852fa27
Author: Jonathan Hseu <jhseu@google.com>
Date:   Fri Jun 9 10:37:18 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    ---
    Commit f0e185d1f authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Better handle nodes with a variable number of outputs
    
    PiperOrigin-RevId: 158435028
    
    ---
    Commit bc3e20807 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused BUILD dependencies
    
    PiperOrigin-RevId: 158431059
    
    ---
    Commit a0c80e4d5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete unnecessary (mistakenly duplicated) logging message.
    
    PiperOrigin-RevId: 158428506
    
    ---
    Commit b6ad1d747 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds DNN-only tests for DNNLinearCombinedClassifier.
    
    PiperOrigin-RevId: 158423119
    
    ---
    Commit ddbb58034 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unnecessary pylint disable
    
    PiperOrigin-RevId: 158416140
    
    ---
    Commit fcaa724e2 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans pack and unpack ops (#10336)
    
    * [OpenCL] Cleans pack op
    
    * [OpenCL] Cleans unpack op
    
    ---
    Commit 2f53cacb2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a test failure of quantization_utils_test on ASAN
    
    PiperOrigin-RevId: 158414538
    
    ---
    Commit 50b2f951c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158413455
    
    ---
    Commit 1e90b78e9 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add CacheDataset ops.
    
    Some input pipelines may pull down data from remote webservers or perform
    expensive processing. In order to avoid extraneous work, we now support
    caching the dataset (e.g. on disk).
    
    PiperOrigin-RevId: 158411901
    
    ---
    Commit e16cd2ede authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by gunan<gunan@google.com>:
    Fix typos (#10533)
    
    ---
    Commit 50d80ddf9 authored by Jonathan Hseu<jhseu@google.com>
    Committed by Jonathan Hseu<jhseu@google.com>:
    Fix fft_ops_test.py for CPU
    
    ---
    Commit d35cbbb44 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add weight-column support to the heads.
    
    PiperOrigin-RevId: 158409180
    
    ---
    Commit 7fb52cd54 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't crash when displaying XLA metrics if they happen to be negative.
    
    PiperOrigin-RevId: 158407664
    
    ---
    Commit 12a7a752a authored by Jianfei Wang<me@thinxer.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Add a tip for tf.train.LoggingTensorHook (#10237)
    
    `INFO` logs are not printed by default unless in IPython. Add a friendly tip for newcomers.
    ---
    Commit 216dcbf1e authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans reduction ops (#10340)
    
    * [OpenCL] Cleans reduction_ops_max.cc
    
    * [OpenCL] Cleans reduction_ops_mean.cc
    
    * [OpenCL] Cleans reduction_ops_min.cc
    
    * [OpenCL] Cleans reduction_ops_prod.cc
    
    * [OpenCL] Cleans reduction_ops_sum.cc
    
    ---
    Commit 2b351062a authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Improve docs for selective registration headers (#10351)
    
    * Improve docs for selective registration headers
    
    progressing #10299
    
    * Update print_selective_registration_header.py
    
    * Mention both flags
    
    -DSELECTIVE_REGISTRATION and -DSUPPORT_SELECTIVE_REGISTRATION
    
    ---
    Commit ee919510f authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Re-enable some python tests in Windows Bazel build (#10526)
    
    ---
    Commit b0e881457 authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Declare and assign separately (#10509)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2155
    ---
    Commit 284901b08 authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Remove unquoting quotes (#10506)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2027
    ---
    Commit 2a1f11556 authored by ksellesk<zhengdachuan200305@gmail.com>
    Committed by ksellesk<zhengdachuan200305@gmail.com>:
    Fix AttributeError in resnet.py
    
    There is no function tf.softmax() in Tensorflow 1.x.
    
    When running the old code, Python interpreter complains:
    
    File "resnet.py", line 152, in res_net_model
    prediction, loss = res_net(x, y)
    File "resnet.py", line 148, in res_net
    return tf.softmax(logits), loss
    AttributeError: 'module' object has no attribute 'softmax'
    
    ---
    Commit 1d68f729b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unneeded BUILD dependency
    
    PiperOrigin-RevId: 158391996
    
    ---
    Commit 08ed32dbb authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Windows: Make TensorFlow build without --cpu=x64_windows_msvc (#10466)
    
    * Windows: Make TensorFlow build without --cpu=x64_windows_msvc
    
    Since from Bazel 0.5.0, MSVC toolchain became the default toolchain on
    Windows. So --cpu=x64_windows_msvc is not required as long as we adjust
    the BUILD files in TensorFlow.
    
    --cpu=x64_windows_msvc is also supported for now, but is depracated.
    The configuration for cpu value x64_windows_msvc is a duplicate of
    x64_windows, which should be removed in the future.
    
    * Fix breakage on macOS
    
    ---
    Commit 02dbe153a authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Simplify Conditional (#10503)
    
    ---
    Commit c07bc581f authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Prefer read -a to split path (#10508)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2207
    ---
    Commit 0a389674d authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Prefer [ p ] && [ q ] over [ p -a q ] (#10507)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2166
    ---
    Commit 87a008ec3 authored by Jonathan Hseu<vomjom@vomjom.net>
    Committed by gunan<gunan@google.com>:
    Delete non-deterministic testEmpty() test (#10512)
    
    ---
    Commit 3a2971bd8 authored by Frank Chen<frankchn@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds the base for ClusterResolvers, a new way of communicating with and retrieving cluster information for running distributed TensorFlow.
    
    Implementations of this class would eventually allow users to simply point TensorFlow at a cluster management endpoint, and TensorFlow will automatically retrieve the host names/IPs and port numbers of TensorFlow workers from the cluster management service.
    
    PiperOrigin-RevId: 158358761
    
    ---
    Commit 28b4e7f04 authored by Jonathan Hseu<vomjom@vomjom.net>
    Committed by gunan<gunan@google.com>:
    Disable stage_op_test and map_stage_op_test (#10516)
    
    ---
    Commit 390e57a75 authored by Yan (Asta) Li<yanastali@users.noreply.github.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    Check EIGEN_MAX_ALIGN_BYTES to prevent mod-by-0 (#10380)
    
    * Check EIGEN_MAX_ALIGN_BYTES to prevent mod-by-0
    
    If EIGEN_MAX_ALIGN_BYTES is set to 0, alignment checks that mod by EIGEN_MAX_ALIGN_BYTES fail at runtime.
    
    * Returns true, as in tensorflow/core/framework/tensor.h
    * Update unit tests
    
    * Enable tests only if EIGEN_MAX_ALIGN_BYTES > 0
    
    ---
    Commit cd5ac40b3 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Update LLVM to upstream revision r304927.
    Add LLVM build rules for the LLVM AMDGPU backend, commented out by default. Fixes issue #10437.
    
    PiperOrigin-RevId: 158351480
    
    ---
    Commit 91cb809bd authored by David Norman<DavidNorman@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [XLA] Add ability to run the XLA unit tests against a different device (#9759)
    
    * Add ability to run the XLA unit tests against a different device
    
    * Allow for multiple extra backend devices
    
    * Correct merge error
    
    * Include options for additional tags
    
    ---
    Commit aff4d124b authored by Yuxin Wu<ppwwyyxxc@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Compare base_dtype instead of dtype in piecewise_constant (#10280)
    
    * Compare base_dtype instead of dtype in piecewise_constant
    
    Compare base_dtype instead of dtype in piecewise_constant. Fix #10086
    
    * add unit test
    
    * Small lint fix and comment
    
    ---
    Commit 845539f98 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add evaluation test for linear classifier (n==2 or n >2).
    
    PiperOrigin-RevId: 158340296
    
    ---
    Commit 7c46214ab authored by Jonathan Hseu<vomjom@vomjom.net>
    Committed by GitHub<noreply@github.com>:
    Fix numpy 1.13 incompatibilities (#10501)
    
    * Fix numpy 1.13 incompatibilities
    
    * Skip tests with numpy 1.13.0
    
    ---
    Commit 4572c41df authored by gunan<gunan@google.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    A few changes to kernel_tests. (#10502)
    
    * Disable reader_ops_test on windows.
    
    * Run buildifier on kernel_tests/BUILD
    
    * Mark map_stage_op_test as large.
    
    * Set the size of stage_op_test to large
    
    ---
    Commit 892293d98 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set a default for datasets end_of_sequence.
    
    While all datasets carefully set the end_of_sequence to true at the
    appropriate time, some datasets might forget to set it to false in the normal
    case. In order to avoid potential undefined behavior, we set the
    end_of_sequence variable to be false by default.
    
    PiperOrigin-RevId: 158337799
    
    ---
    Commit 187404eac authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Setup the env to since ops such as MatchFileOp rely on it.
    
    PiperOrigin-RevId: 158336344
    
    ---
    Commit 2741561c8 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix up vz_projector script structure
    
    We now make sure scripts and HTML imports are declared in the correct
    places. In the future, pedantically listing script tags should not be
    necessary.
    
    PiperOrigin-RevId: 158334306
    
    ---
    Commit beeaade46 authored by Kay Zhu<kayzhu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Resubmit a reverted change. Original description:
    
    [XLA] Enable HloEvaluator for constant folding, also merged a few operations
    from hlo_constant_folding to hlo_evaluator.
    
    Additionally:
    - In ShapeUtil::ForEachIndex:
        * fix a bug where visitor is called when the shape has zero elements (e.g., F32{1,0})
        * added test case for ForEachIndex.
    
    - In HloEvaluator:
        * Instead of copying and caching a Constant instruction, return the literal directly if the instruction is constant.
        * Fix an issue where TUPLE and OPAQUE primitives are not keyed in the templated typed_visitor.
        * Use (fixed) LiteralUtil::Populate to populate resulting literal, fixes the preexisting bug in the evaluator where R0 and shape with zero size dimensions are not handled.
        * Refactor ElementWiseUnaryOp and HandleCompare to be templatized on the operand's type.
        * Refactor IsFinite to be top level since it is only applicable to floats and the return type is always boolean.
        * Change from std::remainder to std::fmod for kRemainder to be compliant with existing XLA behavior.
        * Change from std::max and std::min to std::fmax and std::fmin to handle NaNs.
        * Minor comments fix.
    
    PiperOrigin-RevId: 158330052
    
    ---
    Commit b94540e6f authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tf.layers.conv2d use_bias=True to use nn.bias_add
    
    PiperOrigin-RevId: 158326493
    
    ---
    Commit 379aa9911 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 158325855
    
    ---
    Commit 4e529f0f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158325293
    
    ---
    Commit 0a9d2dac0 authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a util function in virtual placer to return canonicalized device string, which can be used to fix the node's device field before passing them to the maxcut algorithm.
    
    PiperOrigin-RevId: 158322753
    
    ---
    Commit 2d8da1d9b authored by Daniel Ylitalo<daniel@blodan.se>
    Committed by gunan<gunan@google.com>:
    Recognize CPU core count in FreeBSD (#10490)
    
    ---
    Commit c19e6cac0 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Initial implementation of TensorArray ops.
    
    The XLA implementation of TensorArrays is more restrictive than regular TensorArrays:
    * XLA TensorArrays must have dynamic_size=False.
    * all elements in an XLA TensorArray must have the same shape.
    * writes always add their values to any existing values; neither reads nor writes ever issue errors. Out-of-bounds writes currently wrap.
    
    Refactor Variable handling in the TF/XLA bridge. Use a XlaVariable* to refer to variables inside compilation rather than a numerical ID. Allow for variables that don't correspond to variables known to the user. Also use XlaVariable to handle TensorArrays.
    
    PiperOrigin-RevId: 158322041
    
    ---
    Commit b5e8d3086 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Refactor randomized tests to allow testing of larger inputs without running out of memory.
    
    PiperOrigin-RevId: 158321431
    
    ---
    Commit 5d90bbaac authored by Kay Zhu<kayzhu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Disable constant_folding in test base, so that intended test code paths
    would not be elided by constant_folding pass.
    
    PiperOrigin-RevId: 158317641
    
    ---
    Commit 036ce8ba6 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans dense_update_ops (#10335)
    
    * [OpenCL] Cleans dense_update_ops
    
    * Acts on feedback from: #10335#discussion_r120536460
    
    ---
    Commit 85f968125 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans cast operation (#10330)
    
    * [OpenCL] Removes not needed typedef for SYCLDevice
    
    * [OpenCL] Fixes formatting
    
    * [OpenCL] use SYCLDevice for int32 cast case
    
    ---
    Commit bff5e72da authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix typo.
    
    PiperOrigin-RevId: 158310742
    
    ---
    Commit 38249d6be authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Swap the order of NanTensorHook and custom hooks
    
    to ensure that when the training encounteres NaN's in the loss function, user-supplied hooks such as tf_debug.LocalCLIDebugHook can still be used to debug the root cause of the numeric issues.
    
    PiperOrigin-RevId: 158310249
    
    ---
    Commit 599727c65 authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Propagate debug option flags to hlo_test_base.
    
    Specific HLO tests have to replace the generic test_main target with a manual
    main() that invokes RUN_ALL_TESTS.
    
    To get access to a module with debug options set up, a new convenience method
    is created on HloTestBase.
    
    Initially algebraic_simplifier_test is modified as a canary; in a followup
    we'll convert all HLO tests to this approach.
    
    PiperOrigin-RevId: 158309488
    
    ---
    Commit 0770393e9 authored by Eric Liu<ioeric@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [Tensorboard] Add a trace viewer component to TensorBoard.
    
    We make the trace viewer a separate app; otherwise, there would be dependency
    conflicts (e.g. Polymer) between the trace viewer app and the tensorboard app.
    The trace viewer app would be served by a plugin, and Tensorboard dashboard will integrate trace viewer app using iframe in the
    future.
    
    This CL also added "mominify" support for link import HTML tags in the
    tensorboard home-grown java vulnizer; otherwise, the vulcanized trace viewer code
    would crash the java vulcanizer.
    
    For open-source build, we add a denpendency on the Catapult github repository
    (https://github.com/catapult-project/catapult/tree/master/tracing). We use a bazel genrule to vulcanize a trace viewer binary which is then used in the
    tf-trace-viewer component.
    
    PiperOrigin-RevId: 158309408
    
    ---
    Commit 85e832201 authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Support unknown emit shapes in tf.nn.raw_rnn.
    
    PiperOrigin-RevId: 158308002
    
    ---
    Commit edb5fed7f authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add label-vocab support to binary logistic head.
    Add assertion that binary classifier label is in range [0., 1.]
    Fixed Classifier Integration tests.
    
    PiperOrigin-RevId: 158307521
    
    ---
    Commit f8e1cf8fa authored by Justine Tunney<jart@google.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Open up visibility of tf_imports (#10500)
    
    This also fixes the definition of Clutz.
    ---
    Commit 9fd7cf054 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans relu ops (#10343)
    
    * [OpenCL] register relu ops to gpu types (no half)
    
    * [OpenCL] Removes #undef EIGEN_USE_SYCL
    
    ---
    Commit 09c1455e3 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans reverse_op.cc (#10346)
    
    ---
    Commit b7892a30f authored by orome<royl@aldaron.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Clarify tf.matmul documentation (#10381)
    
    * Update math_ops.py
    
    * Fix non-ascii character
    
    ---
    Commit 9786b7062 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Cleans StridedSlice Op (#10314)
    
    * [OpenCL] Cleans StridedSlice Op
    
    * [OpenCL] Removes half from registred types
    
    ---
    Commit f105df047 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, optimize backward filter convolution for images 2 or 4 times smaller than 16x16. Also initialize in_cols from blockDim, to fix the regression caused in CL 157906773.
    
    PiperOrigin-RevId: 158296136
    
    ---
    Commit 492afc2e3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 158295169
    
    ---
    Commit abe0877ef authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add bazel version check to .configure
    
    PiperOrigin-RevId: 158294569
    
    ---
    Commit b702e7e79 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158294289
    
    ---
    Commit 94085bee7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Replace std::function object with regular function.
    
    The function is called recursively, and the std::function object had only existed to allow recursion from within a lambda expression. A regular function should be cheaper than a polymorphic function wrapper.
    
    PiperOrigin-RevId: 158292415
    
    ---
    Commit ba656b261 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use template specialization instead of overloaded methods. This is a more appropriate tool here. NFC
    
    PiperOrigin-RevId: 158292035
    
    ---
    Commit 55f987692 authored by Yutaka Leon<yleon@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
      Make tf.contrib.lookup  python functions use the kernels v2 that uses the resource tensor as handler.
    
    PiperOrigin-RevId: 158291836
    
    ---
    Commit ebae3deba authored by Wei Ho<weiho@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch back to max_num_rows_to_load instead of reading slice by slice due to performance regression from network overhead.
    
    Add check when using initializing values to avoid seg fault
    
    PiperOrigin-RevId: 158291218
    
    ---
    Commit 7b4c01794 authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Support numpy-style padding and slicing of tf.spectral.rfft/irfft to match the desired FFT length.
    
    Fixes incorrect RFFT/IRFFT results when fft_length does not match the input dimension.
    
    PiperOrigin-RevId: 158289991
    
    ---
    Commit fdb8e2935 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update iOS examples to use CocoaPods, and moved to tensorflow/examples/ios
    
    PiperOrigin-RevId: 158289285
    
    ---
    Commit d86167b5f authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Merging rc2 back into master.
    
    ---
    Commit dffea202a authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Clean up some code after previous CL
    
    PiperOrigin-RevId: 158282834
    
    ---
    Commit 7b5302af0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds ability to set a "family" attribute in Tensorflow summaries, which
    controls the "tab name" of the summary that is displayed.
    
    This solution keeps using name_scope to keep names unique, but then prefixes the tag with the family name if provided.
    
    PiperOrigin-RevId: 158278922
    
    ---
    Commit 611c82b5b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds integration test for DNNLinearCombined((Classifier)|(Regressor)).
    
    PiperOrigin-RevId: 158278512
    
    ---
    Commit cc6c91a9a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove a further unused proto header inclusion
    
    PiperOrigin-RevId: 158278026
    
    ---
    Commit 9f17c26ca authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add HloLocation to dataflow analysis.
    Add an HloLocation abstraction to dataflow analysis which indicates where (in the output of what instruction and at which index) an HloValue may appear. Previously only uses were stored with an HLO value where a use is an edge in the HLO graph (instruction, operand number and ShapeIndex).
    
    Also, change the handling of tuple-shaped kSelect instructions when ssa_form is true. Previously a phi value would be created. With this change the the value set instead contains the union of it's inputs identical to the ssa_form=false case.
    
    PiperOrigin-RevId: 158276598
    
    ---
    Commit b9d5e1441 authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Start collecting flags for debug options in a single place.
    
    ClientLibraryTestBase will now parse command-line flags for debug options
    automatically, permitting subclasses to override certain options by using
    mutable_debug_options.
    
    main() still has to call AppendDebugOptionsFlags() explicitly before running
    the TF flag parser. In the mean-time, this CL leaves flag handling to the
    current "legacy" approach. However, this is part of a larger plan to move *all*
    debugging flags for XLA into the DebugOptions message and expose them as flags
    from a single place. The other flags (which are not controlling debugging
    options) will have to be propagated more explicitly.
    
    PiperOrigin-RevId: 158276294
    
    ---
    Commit 3b6fe94bb authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Properly handle shape nodes that have a preexisting control dependency
    
    PiperOrigin-RevId: 158274845
    
    ---
    Commit 1d67379d5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor cleanup
    
    PiperOrigin-RevId: 158268933
    
    ---
    Commit 41997756c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Sort header inclusions; define EIGEN_USE_THREADS where headers depend on it.
    
    PiperOrigin-RevId: 158267803
    
    ---
    Commit 85355f015 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add missing header inclusion
    
    PiperOrigin-RevId: 158265934
    
    ---
    Commit 3cf88d390 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    When GPU is configured, do not require --config=cuda.
    Also fix indentation in configure.
    
    PiperOrigin-RevId: 158232959
    
    ---
    Commit f48673b50 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Removes ReductionFunctor for SYCLDevice (#10326)
    
    We are using Eigen implementation
    ---
    Commit 1b6453bec authored by Joan Puigcerver<joapuipe@gmail.com>
    Committed by gunan<gunan@google.com>:
    Fixes issue #10258 (#10366)
    
    On CUDA versions previous to 8.0, only __shared__ variables could be declared as static in the device code.
    ---
    Commit cd56a638d authored by Beomsu Kim<123bskim@naver.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fixed wrong range in docstring (#10272)
    
    ---
    Commit d13ae380c authored by Micha? Jastrz?bski<michal.jastrzebski@intel.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix CMD in Dockerfile (#10444)
    
    Currently Notebook fails execution because default user for this container is root, and unless explicitly allowed, jupyter notebook will not start.
    ---
    Commit 8118ab4ec authored by Simon Perkins<simon.perkins@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Support partial gets in MapStagingArea (#10276)
    
    * Modify map staging area tests
    
    - size from `small` to `medium`
    - introduce 2 shards
    
    * Add partial get support in MapStagingArea
    
    A partial list of tensors in a (key, value) map entry can now be
    requested. Once all tensors associated with the entry are removed,
    it is removed from the map.
    
    * Correct output/indices mismatch errors
    
    * Rename IncompleteTuple to OptionalTuple
    
    * Add partial get test with indices
    
    * Add some more index checks
    
    * Improve stage test case graph creation
    
    Test sessions (and default graphs) are reused by default.
    Create explicit, finalized graphs in each test to prevent
    possible interactions between stateful Staging Areas and
    others ops created in separate tests.
    
    * Make staging area tests small and remove shards
    
    They were originally made 'medium' to ameliorate timeouts in the test
    case, but they usually run in ~1s so they should be small.
    
    * Improve imports
    
    Avoid importing base tensorflow package
    
    * Support both python 2 and python 3 range.
    
    * Set map_stage_op_test to size=large
    
    * Convert the tests to size=medium
    
    ---
    Commit 0df102b0a authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Update `configure` script sample (#10455)
    
    The `configure` script was changed regularly since the generation of the sample.
    This PR updates the sample to reflect those changes.
    ---
    Commit f6dc1ac61 authored by Earthson Lu<Earthson.Lu@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    MKL_INSTALL_PATH should not be ignore when given (#10180)
    
    * MKL_INSTALL_PATH should not be clear when given
    
    * fix overwrite by default
    
    ---
    Commit 8ad6a036e authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Java: Update Maven release to 1.2.0-rc2
    
    PiperOrigin-RevId: 158212897
    
    ---
    Commit 15eddf035 authored by Fritz Obermeyer<fritz.obermeyer@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Export C API symbols in _pywrap_tensorflow_internal.so (#10469)
    
    * Export C API symbols
    
    * Export C API symbols under config:default
    
    ---
    Commit 754e12668 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Removes half concat op registration (#10331)
    
    ---
    Commit cfdc22dee authored by Peng Yu<yupbank@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    fix the error (#10293)
    
    ---
    Commit 58747e357 authored by Joel Hestness<jthestness@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    PhiloxRandom: Fix race in GPU fill function (#10298)
    
    * PhiloxRandom: Fix race in GPU fill function
    
    The PhiloxRandom fill kernel for the GPU had race conditions that caused the
    outputs to be non-deterministic. In particular, the code previously executed
    with N GPU threads (# thread contexts per GPU), but it would only advance the
    fill addresses by N-1 stride in each step. This incorrect stride caused the
    0th and N-1st threads to write to the same memory locations, racing for which
    was last to write their common locations. Make the stride equal to the number
    of threads to eliminate the race.
    
    BONUS: By fixing this race, PhiloxRandom constant-sized GPU initializers now
    match CPU initializers.
    
    * Update random_ops_test.py to find race conditions
    
    Increasing the size of arrays in the random_ops_test.py test to manifest
    the race conditions to be resolved.
    
    ---
    Commit 2cbcda08f authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fixed formatting in Linux install guide (#10353)
    
    Formatting issues were introduced in PR #8825, commit f30918b3694afe844990cbddc82e27e023d88856
    ---
    Commit ab5f38560 authored by Lakshay Garg<lakshayg@outlook.in>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fixed typos in documentation & READMEs (#10365)
    
    ---
    Commit 94dc1dbfa authored by Christos Nikolaou<cNikolaou@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Enable figures in the tfprof README.md (#10372)
    
    ---
    Commit 3018d4678 authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix typos (#10386)
    
    ---
    Commit c5f3c6171 authored by Daniel Rasmussen<drasmuss@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix unbatch for Datasets with multiple elements (#10401)
    
    * Fix unbatch for datasets with multiple elements
    
    * fixup! pylint (indent two spaces instead of four)
    
    ---
    Commit 8b065bc10 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix unaligned args in api_docs/python/tf/contrib/learn/Evaluable (#10423)
    
    This commit fixes unaligned args in api_docs/python/tf/contrib/learn/Evaluable
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    ---
    Commit 8f89b654f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Profile memory usage in VirtualScheduler and report peak memory usage.
    To do so, NodeState now handles different output ports of a node (in case
    a node has multiple outputs).
    
    Also, VirtualScheduler code is cleaned up with more comments.
    
    PiperOrigin-RevId: 158209068
    
    ---
    Commit 0ea0bf5aa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a frontend for viewing the first ops that exhibit bad values (NaN, +/- Inf).
    
    This helps the user identify problematic ops. Also moved the debugger data logic within tf-graph-info into a new tf-graph-debugger-data-card component.
    
    PiperOrigin-RevId: 158208679
    
    ---
    Commit ed47ecf2d authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Cleans variable op (#10333)
    
    * [OpenCL] Cleans variable op
    
    * Fixes formatting and float / double -> GPU_NUMBER_TYPES_NO_HALF
    
    ---
    Commit 9b2c1af63 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Improves device reporting (#10462)
    
    Prints: id, type, name, vendor and profile of the device
    ---
    Commit 7f5384dcc authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Making load() work for resource variables.
    
    PiperOrigin-RevId: 158205361
    
    ---
    Commit 05412bd36 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Simplify Shape traversal visitors.
    Simplify shape traversal visitors in ShapeUtil and ShapeTree. Add a non-Status form because most uses of the traversal methods do not use it, and remove is_leaf parameter from ShapeTree.ForEach* as it is not frequently used.
    
    PiperOrigin-RevId: 158201574
    
    ---
    Commit 69c9365b4 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extracted linear estimator testing utils to be reused by dnn-linear-combined.
    Added tests for linear part of dnn-linear-combined estimator.
    
    PiperOrigin-RevId: 158200827
    
    ---
    Commit 65ce8c723 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add arrowheads to dataflow edges.
    Make reference edges orange.
    Remove animations from tooltips in the graph documentation.
    
    Previously, arrowheads were only added to reference edges (because we assumed users knew about the convention that arrowless edges flow upwards). That decision nicely reduces clutter. However, recently, some internal and external folks have expressed confusion, and so I want to try adding arrowheads to all data flow edges. And make the reference edges starkly different.
    
    See #10428
    
    PiperOrigin-RevId: 158195388
    
    ---
    Commit bf4c3dd6b authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Revert "Fix patching issue on Windows" (#10472)
    
    This reverts commit 47e6785646a1266f01a1a570bd799f8518ee2997.
    
    ---
    Commit b49515539 authored by David Soergel<soergel@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add only string constants to ASSET_FILEPATHS collection.
    
    PiperOrigin-RevId: 158192152
    
    ---
    Commit 51acad09c authored by Sergio Guadarrama<sguada@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add tests with different delta to huber_loss.
    
    PiperOrigin-RevId: 158191361
    
    ---
    Commit a4e7b7add authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes a bug in setting default optimizers for DNNLinearCombinedClassifier.
    
    PiperOrigin-RevId: 158190192
    
    ---
    Commit ddd67e333 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans reshape.cc (#10347)
    
    * [OpenCL] Cleans reshape.cc
    
    * Removes half and complex numbers.
    
     Half is extension and complex numbers needs implementation in Eigen first
    
    ---
    Commit 3ca653304 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158186454
    
    ---
    Commit 8cda8660e authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans sendrecv_ops.cc (#10345)
    
    ---
    Commit 6915bb919 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans Slice op (#10341)
    
    ---
    Commit 54998b45d authored by Michele Colombo<m-colombo@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    BasicRNNCell comment fix (#10467)
    
    ---
    Commit df5906fb7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Mark saver/restore ops that depend on filesystem as stateful to disable them
    from being folded into a constant by graph optimizer.
    
    PiperOrigin-RevId: 158182282
    
    ---
    Commit 96cb4d182 authored by Sergio Guadarrama<sguada@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add support of scale_l1 == 0. or scale_l2 == 0 to l1_l2_regularizer.
    Added tests.
    
    PiperOrigin-RevId: 158179790
    
    ---
    Commit b65eb3f9b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Speed up atrous_convolution_test by combining evaluations.
    
    To make this test run faster (and prevent it from timing out under
    certain circumstances), this change combines all evaluations for each
    test method into a single call to Session.run, to eliminate overhead.
    
    This reduces the test time from about 40 seconds to 10 seconds.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 158175227
    
    ---
    Commit b440abce7 authored by Gao, Xiang<qasdfgtyuiop@gmail.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    add Cuda{2D,3D}LaunchConfig that maximizes occupancy (#10032)
    
    * add Cuda{2D,3D}LaunchConfig that max occupancy
    
    * remove default val, check input<=0
    
    * add max size check
    
    * fix typo
    
    * tests, docs, and related changes
    
    * build the test
    
    * buildify
    
    * cudaOccupancy... call check success, and style fix
    
    ---
    Commit 81cf61fdb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Initialize tensor in graph_properties_test, to avoid msan complaint.
    
    PiperOrigin-RevId: 158169374
    
    ---
    Commit cabc5c35c authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add xla_disable_hlo_passes to DebugOptions
    
    Also add a SetDebugOptions method to ClientLibraryTestBas; this lets us set
    debug options in tests by calling it.
    
    As an example, this CL removes the current way of passing
    xla_disable_hlo_passes programmatically in tests - it used to employ a special
    constructor parameter which is no longer required.
    
    PiperOrigin-RevId: 158169006
    
    ---
    Commit 187d23337 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans Pad op (#10339)
    
    ---
    Commit e8bc38ef6 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Fix test failures on windows. (#10470)
    
    ---
    Commit 2b3535c64 authored by David Soergel<soergel@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor docstring fix for build_parsing_serving_input_receiver_fn
    
    PiperOrigin-RevId: 158163615
    
    ---
    Commit e55f2e036 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Propagates constants through switch nodes.
    
    PiperOrigin-RevId: 158163537
    
    ---
    Commit b01d4b905 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Remove outdated todo.
    
    PiperOrigin-RevId: 158161411
    
    ---
    Commit 7125733d7 authored by William Chargin<wchargin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Create a set of sample data for the audio plugin
    
    This implements a simple tone generator, with sine waves, square waves,
    and triangle waves, plus two simple combinations of sine waves. The step
    value is used to control the frequency.
    
    PiperOrigin-RevId: 158160889
    
    ---
    Commit dc81a2420 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Updates to the WALSMatrixFactorization estimator:
    - Add a completed_sweeps variable to keep track of sweeps that have been completed during training.
    - Add a StopAtSweepHook, which can request a stop after completing a specified number of sweeps.
    
    PiperOrigin-RevId: 158156347
    
    ---
    Commit 74220616c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set device cores and frequency in op_level_cost_estimator_test,
    to avoid asan error about assigning inf to int64 (this comes
    in from a divide-by-0).
    
    PiperOrigin-RevId: 158155488
    
    ---
    Commit 47e678564 authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Fix patching issue on Windows (#10452)
    
    ---
    Commit 6d54f09d9 authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Fix linking errors of lmdb on Windows (#10457)
    
    ---
    Commit 61c8a745b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor cleanup: Add braces around if statement arms; remove redundant "return" and "static".
    
    PiperOrigin-RevId: 158143418
    
    ---
    Commit e9a889c5e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Pass int parameter by value, not by const reference
    
    PiperOrigin-RevId: 158142102
    
    ---
    Commit 9184726ed authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid unnecessary copying of map data during visitation
    
    PiperOrigin-RevId: 158141962
    
    ---
    Commit 2e7e1d57b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Small fix for how std::move is used in constructors
    
    PiperOrigin-RevId: 158141564
    
    ---
    Commit 2a61c1652 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In cpu compiler's CompileAheadOfTime, pass ordering when compiling entry computation.
    
    PiperOrigin-RevId: 158140349
    
    ---
    Commit f3f53e8b3 authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Add support for dicts and remove lists from nested structures.
    
    This changes the behavior of constructors like
    `tf.contrib.data.Dataset.from_tensors()` when passed a list. Previously, the
    `nest` utility would recurse into each element of such a list and create a
    separate Dataset component. Now the list will be converted to a tensor, allowing code like:
    
    ```python
    dataset = tf.contrib.data.Dataset.from_tensor_slices(([1, 2, 3], [4, 5, 6]))
    ```
    
    ...to define a dataset with two components (each of shape `()`).
    
    This change also adds support for dictionaries as nested structures, which
    simplifies integration with dictionary-returning ops like `tf.parse_example()`.
    
    Fixes #10151.
    
    RELNOTES: Breaking change to `tf.contrib.data.Dataset` APIs that expect a
    nested structure. Lists are now converted to tf.Tensor implicitly. You may need
    to change uses of lists to tuples in existing code. In addition, dicts are now
    supported as a nested structure.
    PiperOrigin-RevId: 158139467
    
    ---
    Commit b6a8848c1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Enabling python configuration to use a remotely generated configuration that is located inside of the org_tensorflow repo (previously it *had* to be a remote repo declared in workspace file).
    
    PiperOrigin-RevId: 158138601
    
    ---
    Commit 0fe0bfcc3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused protobuf header inclusions
    
    PiperOrigin-RevId: 158120864
    
    ---
    Commit f0c4c6c3f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast NCHW backward filter convolution for images smaller than 16x16.
    
    PiperOrigin-RevId: 158111294
    
    ---
    Commit 8dcf37b47 authored by Jon Malmaud<malmaud@gmail.com>
    Committed by gunan<gunan@google.com>:
    Fix typo (#10379)
    
    ---
    Commit 3039d7da2 authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    Remove "bazel clean" (#10318)
    
    Reverting #8880 (see #10236)
    unnecessary since bazelbuild/bazel#2759 was merged
    ---
    Commit ae1c16ae8 authored by Yifei Feng<fengyifei2026@gmail.com>
    Committed by gunan<gunan@google.com>:
    Update docker to cudnn6. (#10307)
    
    * Update docker to cudnn6.
    
    * Update Dockerfile.gpu
    
    * Add --expunge to bazel clean to make cuda_configure run again and update TF_CUDNN_VERSION.
    
    * Remove expunge and set CUDA and CUDNN version default in configure.
    
    * Update configure
    
    * Only set --action_env once
    
    * Update prints for default version.
    
    ---
    Commit 232e9d86d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tf_workspace() claims that the tf_repo_name argument is unused.
    temp_workaround_http_archive still requires it.
    This change silences the spurious message.
    
    PiperOrigin-RevId: 158089834
    
    ---
    Commit cc1a02d37 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add fp16 support to convolutional layers that support it.
    
    PiperOrigin-RevId: 158086284
    
    ---
    Commit 7d3fbba48 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extracted dnn estimator testing utils to be reused by dnn-linear-combined.
    Added tests for dnn part of dnn-linear-combined estimator.
    
    PiperOrigin-RevId: 158084898
    
    ---
    Commit 9d12c629c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactor the document and some polishment
    
    PiperOrigin-RevId: 158083952
    
    ---
    Commit 134138299 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Corrected comment: import_scoped_metagraph does not return a Saver.
    
    PiperOrigin-RevId: 158082288
    
    ---
    Commit a58553e4d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add function in shape inference to try to infer output tensor content based on
    the input shapes of the op. In some cases (E.g: shape), knowing the shapes of
    the input is all that is necessary to infer the content of the output tensor.
    This improves shape inference.
    
    PiperOrigin-RevId: 158079306
    
    ---
    Commit 0cc851c08 authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Call maxcut algorithm in the model_based_cost_estimator.
    
    PiperOrigin-RevId: 158078511
    
    ---
    Commit 7d76a90be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add question marks next to items in the graph legend.
    
    PiperOrigin-RevId: 158076005
    
    ---
    Commit 68fdb7628 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add DNNLinearCombinedClassifier.
    
    PiperOrigin-RevId: 158075939
    
    ---
    Commit 3d52e4cb9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix create_meta_graph to respect an empty collection_list.
    
    PiperOrigin-RevId: 158073112
    
    ---
    Commit 54ccc3e5a authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add module-scoped HLO dataflow analysis.
    This is the first step to replacing TuplePointsToAnalysis with a global, module-scoped analysis. This dataflow analysis identifies all values and their defs and uses in the XLA graph. The analysis is currently unused. Follow up CLs will add buffer alias analysis using this dataflow analysis, and incrementally switch the transformation passes (for example, CopyInsertion) to use these new module-scoped analyses.
    
    PiperOrigin-RevId: 158067910
    
    ---
    Commit 93c57c6e4 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Handle control flow logic properly:
     * Don't fold enter/exit nodes since that can interact badly with frames
     * Create proper control dependencies on switch nodes
    
    PiperOrigin-RevId: 158066691
    
    ---
    Commit 9e6899720 authored by Jingyue Wu<jingyue@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [SE] Add cudnnTransformTensor to StreamExecutor.
    
    PiperOrigin-RevId: 158062553
    
    ---
    Commit 827874c30 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast NCHW backward input convolution for images smaller than 16x16.
    
    PiperOrigin-RevId: 158061669
    
    ---
    Commit bee26215c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Speed up multinomial_op on CPU by using a vectorized Eigen expression and avoiding unnecessary casts.
    
    Benchmark with AVX+FMA enabled:
    
    Run on <redacted> (12 X 3492 MHz CPUs); 2017-06-05T12:54:07.881672447-07:00
    CPU: Intel Haswell with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:15MB
    Benchmark                          Base (ns)  New (ns) Improvement
    ------------------------------------------------------------------
    BM_Multinomial_cpu_1_10000_4          250817    172953    +31.0%
    BM_Multinomial_cpu_1_10000_128        273834    187552    +31.5%
    BM_Multinomial_cpu_1_10000_10000     1174175   1130778     +3.7%
    BM_Multinomial_cpu_1_100000_4        2040741   1276761    +37.4%
    BM_Multinomial_cpu_32_10000_4       10221765   4498666    +56.0%
    BM_Multinomial_cpu_32_10000_128     10638159   4994754    +53.0%
    BM_Multinomial_cpu_32_100000_4      100790019  44193314    +56.2%
    BM_Multinomial_cpu_128_100000_1     431269640  182506078    +57.7%
    PiperOrigin-RevId: 158061480
    
    ---
    Commit 515b3ac67 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add Clutz to TensorBoard build
    
    This is so we can get JavaScript protobufs. This CL also improves the
    web_aspect and makes some peculiar Closure Compiler errors go away
    relating to externs.
    
    PiperOrigin-RevId: 158061198
    
    ---
    Commit 0df6760fe authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added a test to make sure that graph properties for variables are properly
    reported
    
    PiperOrigin-RevId: 158053084
    
    ---
    Commit 2ccfe8e76 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added a new method to extract the graph properties from a cost graph without
    having to run the model. This will simplify the process of creating regression
    tests
    
    PiperOrigin-RevId: 158050327
    
    ---
    Commit 27f1b80c2 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes memory leak in py_func when functions return unwrapped strings.
    
    PiperOrigin-RevId: 158046530
    
    ---
    Commit cf238e1f2 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix memory leak in python caused by @tf_should_use.
    
    The issue is that python's GC has trouble collecting objects with __del__ methods.
    
    The solution is two pronged:
    * Keep track of usage state outside of the class, via a dict mapping
      id(object) => state
    * Remove __del__ (this was the source: python's GC couldn't collect wrapped
      objects), and instead use weakref.finalize to emit warnings just as the object
      is being garbage collected.
    * Added tests for garbage collection [they were failing before i fixed the issue]
    
    PiperOrigin-RevId: 158042388
    
    ---
    Commit e6f581863 authored by Bo Wang<david.b.wang@gmail.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    New reader for LMDB databases (#9950)
    
    * Add LMDBReader op and test case
    
    * Add testcase to load LMDB from a folder
    
    * Add tensorflow/core/lib/lmdb/testdata/data.mdb
    
    * Add EOF test
    
    * Add license export
    
    * Blacklist the test data in pip_smoke_test.py
    
    * Address issues with respect to review
    
    * Add LICENSE to BUILD rules
    
    * Remove the prefx of LICENSE
    
    * Wrap key with compat.as_bytes()
    
    * Fixed a compilation flag
    
    * Improve BUILD rules
    
    * Support LMDB build in cmake
    
    * Fix BUILD file format with buildifier
    
    * Add fake unistd.h for lmdb to build on Windows
    
    * Avoid building lmdb tools which depends on unistd.h
    
    * Fix the string encoding issue in Python3
    
    * Update lmdb library name in CMakeList.txt
    
    ---
    Commit cc411f938 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    When converting the layout of Conv2DBackpropInput, we need to permute one of
    its inputs, which is a constant node. We permute a copy of this node, instead of the
    original node, because the original node may be used as input to other nodes.
    This kind of sharing of const node could arise if the graph is pre-optimized by common
    subexpression elimination, which is part of the L1 optimizations in
    TensorFlow.
    
    PiperOrigin-RevId: 158037552
    
    ---
    Commit 88bdb6fca authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove all remaining references to non-public TF modules from TensorBoard.
    
    I deleted the PluginAssetUtil tests because that code is deprecated.
    I'll later add manual testing for backcompat in the text plugin.
    
    PiperOrigin-RevId: 158037466
    
    ---
    Commit 6c531eb2f authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add file hash to Keras Boston Housing dataset to force cache update.
    
    PiperOrigin-RevId: 158036587
    
    ---
    Commit afdc38cd3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove deprecated resource handle functions in InferenceContext.
    
    PiperOrigin-RevId: 158034419
    
    ---
    Commit 9f932e6ce authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid parsing a rendezvous key for Send/Recv ops outside a loop.
    
    For such ops, the rendezvous key will be constant, because
    `ctx->frame_iter()` will always evaluate to `{0, 0}`. Benchmarking
    reveals that this can save between 1 and 2 microseconds per Send or
    Recv op execution. The optimization applies to all cross-process,
    inter-device, and intra-device (host-to/from-device memory) Send/Recv
    ops.
    
    PiperOrigin-RevId: 158032522
    
    ---
    Commit cc2dd4ac8 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tfdbg: dump debug data from different devices in separate directories
    
    Fixes: #7051
    wherein TFDBG failed to load the data dump from a Session.run() involving multiple GPUs.
    
    The root cause of the bug was that TFDBG previously assumed that node names are unique across all partition graphs. This is however not the case when multiple GPUs exist. The Send/Recv nodes in the partition graphs of the GPUs can have duplicate names. There will potentially be other cases like this in the future due to other reasons (e.g., distributed sessions and/or graph optimization).
    
    This CL relaxes this assumption, by dumping the GraphDef and tensor data from different devices into different sub-directories under the dump root directory.
    
    PiperOrigin-RevId: 158029814
    
    ---
    Commit a5909d643 authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixed triggering create device multiple times
    
    PiperOrigin-RevId: 158025196
    
    ---
    Commit 504a307b7 authored by Martin Wicke<wicke@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make sure that Adam colocates ops with a consistent variable across workers.
    
    PiperOrigin-RevId: 158022292
    
    ---
    Commit 69ba4d3d4 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix #10371
    
    cpuinfo.get_cpu_info() doesn't seem to include the l2_cache_size key on some
    architectures.
    
    PiperOrigin-RevId: 158021008
    
    ---
    Commit a51a9846c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Performance-related tweaks: Don't copy loop variables; remove ineffective std::move casts.
    
    PiperOrigin-RevId: 158017670
    
    ---
    Commit 009789f74 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Allow 0-sized slices in DynamicSlice and DynamicUpdateSlice; add tests.
    
    PiperOrigin-RevId: 158015870
    
    ---
    Commit 48a4853eb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Miscellaneous cleanups
    
    PiperOrigin-RevId: 158012131
    
    ---
    Commit 379ddde24 authored by Chris Song<sjhshy@gmail.com>
    Committed by Chris Song<sjhshy@gmail.com>:
    Fix misspells.
    
    ---
    Commit a0a76da97 authored by Lakshay Garg<lakshay.garg.1996@gmail.com>
    Committed by Lakshay Garg<lakshay.garg.1996@gmail.com>:
    Fixed typo in code
    
    ---
    Commit 7ffc35732 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add support for bools in matrix_diag, matrix_diag_part, matrix_set_diag, matrix_band_part.
    
    PiperOrigin-RevId: 157939272
    
    ---
    Commit edf3d5dbe authored by Darren Garvey<darren.garvey@gmail.com>
    Committed by Darren Garvey<darren.garvey@gmail.com>:
    configure: Fix default path when enabling MPI.
    
    Correct showing what the default path is when mpi is installed.
    
    ---
    Commit aad2e3daf authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast NCHW forward convolution for images smaller than 16x16.
    
    PiperOrigin-RevId: 157915637
    
    ---
    Commit 5cf08d9cb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Drop blockDim.y for the equivalent in_cols, and slightly improve naming (use 'pixels' instead of 'size' for height*width numbers).
    
    PiperOrigin-RevId: 157906773
    
    ---
    Commit 563f05ff6 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf contrib seq2seq] Expand tile_batch to handle nested structures.
    
    This allows it to properly tile the initial wrapper state when using
    BeamSearchDecoder with AttentionWrapper.  Unit tests updated to show this use.
    
    PiperOrigin-RevId: 157903115
    
    ---
    Commit 1234e2dda authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix Plottable definition
    
    On Mac OS the build directory in the Node package conflicts with BUILD.
    
    PiperOrigin-RevId: 157899970
    
    ---
    Commit bb7a8d8e7 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't use the _output_shape attribute in the op_level_cost_estimator since
    there is no guaranty that it will be present or accurate.
    
    PiperOrigin-RevId: 157898989
    
    ---
    Commit 6f4204c3d authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix TensorBoard SHA256 in cmake
    
    PiperOrigin-RevId: 157897958
    
    ---
    Commit c9d2f432b authored by Justine Tunney<jart@google.com>
    Committed by Justine Tunney<jart@google.com>:
    Fix TensorBoard SHA256 in cmake
    
    ---
    Commit 1c70fb686 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add training test for multi classes (n>2) linear classifier.
    
    PiperOrigin-RevId: 157896002
    
    ---
    Commit 675d36be0 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add fused batch norm to tf.layers.
    
    PiperOrigin-RevId: 157893874
    
    ---
    Commit f37d0ea47 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change -- first draft docs
    
    PiperOrigin-RevId: 157891937
    
    ---
    Commit 9b8f6113b authored by Zongheng Yang<zongheng@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tensor_bundle: fix that the read path forgets to cache file handles.
    
    In a case where a reader is geographically far from the file, this change
    achieves a speedup of end-to-end checkpoint restore by 5.8x.
    
    PiperOrigin-RevId: 157889659
    
    ---
    Commit 0c92dada6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use inplace Cholesky factorization and solves to speed up and reduce memory usage in matrix_solve_ls.
    Check succes before copying outputs in cholesky_op.
    
    PiperOrigin-RevId: 157887564
    
    ---
    Commit a4caeb2ea authored by William Chargin<wchargin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extract the graphs dashboard to a plugin
    
    This completes the great plugin migration!
    
    The graphs plugin is somewhat different from the plugins considered so
    far. First, it exposes two kinds of data: graph data and run metadata.
    We elect to put both sources of data under the domain of the graphs
    plugin for now, because it's not clear that the run metadata would be
    useful for anything else. Second, the graph data really has no use for
    "tags": a run either has an associated graph or it does not. Thus, we
    expose an endpoint /data/plugin/graphs/runs that is different in format
    from the /tags routes exposed by other plugins (it returns just a list
    instead of a run-to-tag mapping).
    
    This change removes a bunch of tests from application_test.py. The tests
    cover the compresion behavior of the graph endpoint, but the graph
    endpoint doesn't have any special logic in the way of compression. Thus,
    the tests are, apparently, testing that werkzeug (or whatever is
    relevant here) provides good compression defaults. This isn't
    necessarily a bad idea, but it shouldn't be coupled to the graph tests.
    
    To get test data that includes run metadata, you can run this script:
    
        https://raw.githubusercontent.com/tensorflow/tensorflow/326942394e69074d50d5889218a24c9371eff259/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py
    
    PiperOrigin-RevId: 157884714
    
    ---
    Commit 05a6a13f7 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by gunan<gunan@google.com>:
    Make sure all writer caches are closed before deleting directories in dnn_test.
    
    ---
    Commit d0e761f8d authored by Gunhan Gulsoy<gunan@google.com>
    Committed by gunan<gunan@google.com>:
    Disable another test that uses matrix_set_diag on windows.
    
    ---
    Commit 8939b8562 authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Re-implement IteratorGetNext as an AsyncOpKernel.
    
    This prevents the op from consuming an inter-op thread pool thread
    when blocked, and fixes a potential deadlock when many IteratorGetNext
    ops are blocked. Fixes #10369.
    
    PiperOrigin-RevId: 157878885
    
    ---
    Commit 9e25c68ad authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add loss_only_head to hold additional loss terms for multi_head setup
    
    PiperOrigin-RevId: 157875934
    
    ---
    Commit 7cdcd0cca authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Filter more op types that don't benefit from constant folding.
    
    PiperOrigin-RevId: 157875168
    
    ---
    Commit 366990d92 authored by Kay Zhu<kayzhu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix a subtle issue in copy_insertion due the interaction between copy
    overriding logic and RecordIndicesToColocatingBuffers:
    
    - When building instructions ShapeTree to be copy overriden, it is possible
    that we create a single kCopy for two identical instructions. An example can
    be:
    
        %tuple.19 = tuple(%constant.4, %constant.1793, %constant.1793)
    
    where it is used in a while.init operand, and constant.1793 is read-only within
    the loop and also used by another while loop. The copy overriding pass will then
    create the following (logical, not finalized) tuple:
    
        %tuple.19 = tuple(%constant.4, %copy.5, %copy.5)
    
    - In the subsequent pass RecordAmbiguousOrNonDistinctIndices, to add copies to
    ensure point_to set is distinct, the duplicate %copy.5 are ignored because they
    are not yet finalized, and these indices (1 and 2 in the example) are still
    marked as to-be copied.
    
    Therefore distinctiveness is lost.
    
    This fix applies to the override building stage, to explicitly avoid creating
    shared copies for non-distinct buffers.
    
    PiperOrigin-RevId: 157872231
    
    ---
    Commit f4b8d21b8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change function parameters to references to avoid copying, or otherwise move from function parameters when moving reduces the amount of copying.
    
    PiperOrigin-RevId: 157867333
    
    ---
    Commit 3eee61caa authored by Drew Hintz<pushespretn@gmail.com>
    Committed by GitHub<noreply@github.com>:
    fix quotes in example code from ? to "
    ---
    Commit 4905c0eae authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove TODO - the new tolerance is okay to keep.
    
    PiperOrigin-RevId: 157861020
    
    ---
    Commit 55f6b6ff1 authored by David Soergel<soergel@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add explicit SparseTensor support to SignatureDef.
    
    PiperOrigin-RevId: 157860466
    
    ---
    Commit 79099d677 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removes default thresholds from BinaryLogisticHead and adds predict and evaluate tests for DNNClassifier.
    
    PiperOrigin-RevId: 157856471
    
    ---
    Commit 54595f0f3 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds the training test for LinearClassifier with n_classes=2.
    
    PiperOrigin-RevId: 157855473
    
    ---
    Commit cd6c02985 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add 'streaming_curve_points' metric which returns curve [ROC, PR] approximation at specified number of points.
    
    PiperOrigin-RevId: 157851535
    
    ---
    Commit 0f2db7391 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Split union-find implementation in mark_for_compilation_pass.cc into a separate library, make it more generic.
    
    PiperOrigin-RevId: 157850985
    
    ---
    Commit d5421cf58 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add additional concat test.
    
    PiperOrigin-RevId: 157844113
    
    ---
    Commit f661128db authored by Geoffrey Irving<geoffreyi@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused overloads of SummarizeGraphDef and EqualGraphDef
    
    PiperOrigin-RevId: 157843404
    
    ---
    Commit a56d59a84 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set flow to a value during TensorArray creation,
    Re-enable tensor_array_ops_test in msan.
    
    PiperOrigin-RevId: 157841785
    
    ---
    Commit edcc5cc13 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add manual test runner for vz_sorting
    
    PiperOrigin-RevId: 157841098
    
    ---
    Commit 3f6404f20 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Assign a max height of 800px to images in the image dashboard.
    
    The user could always expand to actual dimensions if need be.
    
    PiperOrigin-RevId: 157838046
    
    ---
    Commit c6ea6972a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove debugging LOG(INFO) from previous change.
    
    PiperOrigin-RevId: 157837305
    
    ---
    Commit 07d39f28e authored by freedom" Koan-Sin Tan<koansin.tan@gmail.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    make gcc-5 on Ubuntu 16.04 happy (#10385)
    
    gcc-5 complains of ambiguity and refuses to go when doing something
    like 'bazel build -c opt tensorflow/...'
    ---
    Commit ac66be783 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor cleanup: Remove unused BUILD dependencies and unnecessary code.
    
    PiperOrigin-RevId: 157837211
    
    ---
    Commit 4161ccc8e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adjust tolerance on dirichlet_multinomial test.
    
    PiperOrigin-RevId: 157834660
    
    ---
    Commit 43c0f52f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix off-by-one error in BoolVector(begin, end) constructor.
    
    PiperOrigin-RevId: 157833086
    
    ---
    Commit 419d437ba authored by Lakshay Garg<lakshay.garg.1996@gmail.com>
    Committed by Lakshay Garg<lakshay.garg.1996@gmail.com>:
    Fixed typo in code comment
    
    ---
    Commit 07710014d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix device colocation for KMeans in case of multiple parameter servers.
    
    PiperOrigin-RevId: 157795360
    
    ---
    Commit b659bc39f authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplify TensorBoard build
    
    - Remove tensorboard_typescript_genrule
    - Remove tensorboard_typescript_bundle
    - Introduce ts_web_library Skylark rule which supports seamless
      TypeScript compilation.
    - Use Closure Compiler in semi-advanced mode to compile JavaScript.
      This is done in a way that preserves <script> tag placement, which
      causes pages to load faster and avoid FOUC, thereby making it a
      better solution than the existing vulcanize.
    
    PiperOrigin-RevId: 157794795
    
    ---
    Commit 0503ce09c authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Wipe out previous shape inference result when importing a grappler item
    Run graph optimizations last: since they can be expensive it's best to filter invalid items first.
    
    PiperOrigin-RevId: 157792834
    
    ---
    Commit 9ae941c4a authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Turn reductions along an empty set of dimensions into identity nodes.
    
    PiperOrigin-RevId: 157792209
    
    ---
    Commit 69075f354 authored by Yangzihao Wang<yangzihao@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add functional support for cudnnConvolutionBiasActivationForward().
    
    PiperOrigin-RevId: 157788425
    
    ---
    Commit 7d7a40309 authored by William Chargin<wchargin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extract the distributions dashboard to a plugin
    
    This continues the great plugin migration. The distributions plugin was
    similar to the histograms plugin, but it also purported to allow CSV
    download like the scalars plugin. However, the existing implementation
    of this was flawed, and would always yield a 500 on current prod [1]
    (unless there were actually no data). This indicates that no one is
    actually using it---probably because there isn't a relevant button on
    the frontend, anyway!---so I just removed it.
    
    This also changes most frontend occurrences of "compressedHistograms"
    to "distributions" while we're at it.
    
    [1]: Due to the reference `value.rank_in_bps` in the handler
    `_serve_compressed_histograms`; this field does not exist and throws an
    `AttributeError`.
    
    PiperOrigin-RevId: 157787156
    
    ---
    Commit 23cdf96b8 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable session_test.py
    
    A number of CL's have split up session_test.py to be a bit smaller. As a
    result, this CL will re-enable the session_test to see if it remains flaky.
    
    PiperOrigin-RevId: 157786407
    
    ---
    Commit d741d81c5 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expose tf.test.StubOutForTesting in the tf testing api
    
    Also redirect TensorBoard usage to use that endpoint.
    
    This is part of my ongoing effort to have TensorBoard only
    depend on TensorFlow via its public api, so that it can
    be split into a project with a fast external build.
    
    PiperOrigin-RevId: 157784552
    
    ---
    Commit 40411cd5c authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactor projector plugin to only use tf public methods.
    
    Remove all reference to the PluginAsset system, which is deprecated.
    
    Part of an ongoing effort to have TensorBoard only consume the public
    TensorFlow api.
    
    PiperOrigin-RevId: 157784016
    
    ---
    Commit a65a70ea5 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix pip tests under contrib/text
    
    PiperOrigin-RevId: 157783952
    
    ---
    Commit fb4bc806a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix flakiness in GpuMultiSessionMemoryTest.
    
    PiperOrigin-RevId: 157781368
    
    ---
    Commit f7de292df authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update placeholder nodes' shapes in the GraphDef to reflect manually specified values for incomplete placeholder shapes. Previously, these overrides were only specified in the feed nodes, which improves estimates when using dynamic shapes but not when using static shapes. With this change, static shapes also benefit.
    
    PiperOrigin-RevId: 157780800
    
    ---
    Commit eebd44123 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a frontend method for retrieving numeric alerts from the debugger plugin.
    
    This route responds with a list of alerts (occurrences of bad values) in ascending timestamp order.
    
    PiperOrigin-RevId: 157780270
    
    ---
    Commit 5bc685d7f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] If an op has a single "large" operand, we want to fuse this op into some of its consumers, even if we can't fuse into all of them.
    
    PiperOrigin-RevId: 157779106
    
    ---
    Commit 2ee09b873 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Various improvements to ShapeTree.
    Add support for holding non-copyable types, operator==, and a
    CopySubtreeFrom method for copying a subtree from one ShapeTree to
    another.
    
    PiperOrigin-RevId: 157777636
    
    ---
    Commit 4f3ae7699 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add beam_search kernels used by BeamSearchDecoder to tensorflow.contrib.
    
    PiperOrigin-RevId: 157775011
    
    ---
    Commit 6b16c33b3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make audio-related logic use the audio plugin.
    
    Previously, fetching audio and related data from TensorBoard used handlers within application.py. We now remove those handlers in favor of routes offered by the audio plugin. ML Dash is updated as well.
    
    PiperOrigin-RevId: 157774953
    
    ---
    Commit 8032e1f75 authored by Geoffrey Irving<geoffreyi@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make function instantiation use std::vector<NodeDef> instead of GraphDef
    
    It's about to turn into std::vector<NodeInfoPtr>; this change gets us partway there.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 157771141
    
    ---
    Commit 2e44be35d authored by Vinu Rajashekhar<vinuraja@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds a protected DeleteResourceMgr(...) method in Device.
    
    PiperOrigin-RevId: 157770378
    
    ---
    Commit cc346e690 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Strip the :x suffix when generating control inputs from input names
    
    PiperOrigin-RevId: 157770257
    
    ---
    Commit d6fe47af5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use tensorflow::StringPiece in literal_util.
    Use template for RepeatedField assignment.
    
    PiperOrigin-RevId: 157765477
    
    ---
    Commit 7866fa01b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    This change significantly reduces time and resources used to load large TensorFlow graphs.
    
    For a real-world large graph (13k nodes, 20k edges), this change:
    
    * reduces all heap allocations by 19%
    * reduces retained (final) heap allocations by 2.2%
    * reduces CPU time by 11.2%
    
    In most TF graphs, the set of unique values set to Node::assigned_device_name() is quite small.  This change adds an interning table to the Graph object, which contains all of the unique values used for Node::set_assigned_device_name(), as well as a look-up table.  This is the main source of the reduction in retained heap memory; nearly all nodes are assigned to just one or two unique devices.
    
    This change removes the "string assigned_device_name_" field from the Node class, and replaces it with "int assigned_device_name_index_".  However, because you need both the index and the name table to get the actual value, the Node::assigned_device_name() accessor needs access to the parent Graph.  This requires adding a "Graph* graph_" field to the Node class.
    
    In the future, if all users of this property are converted to use Graph::assigned_device_name(Node*), then the Node::graph_ field can be deleted, and the space reclaimed.  However, doing so is out of the scope of this CL, and even with this new pointer field, the Node class is smaller than it was before, so this is still a net win.
    
    The placement algorithm in simple_placer.cc is one of the main accessors of the Node::assigned_device_name property.  This CL contains significant changes to simple_placer.cc, which directly take advantage of the fact that the property is an index into a name table, rather than treating it simply as a string.  Many temporary allocations are also removed, which is the main source of the reduction in total heap allocations.
    
    This CL also contains a few changes that remove short-lived allocations in unrelated code, such as the changes in op.cc/h, costmodel.cc, etc.  It is extremely easy in C++ to accidentally allocate memory, especially when implicit conversions and copy constructors allocate memory.
    
    All of the changes in this CL were motivated by empirical measurement, using CPU profiling and heap profiling.
    
    PiperOrigin-RevId: 157762909
    
    ---
    Commit fdffafbc1 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add QueueDequeueUpTo to the list of dequeue ops
    
    PiperOrigin-RevId: 157760201
    
    ---
    Commit 7ad0d0698 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add type error to start_queue_runners if given session is not a `tf.Session`. Due to semver, we suppress the error if a MonitoredSession is provided.
    
    PiperOrigin-RevId: 157748375
    
    ---
    Commit 7106f9fac authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Implemented an initial version of virtual scheduler unit test.
    
    PiperOrigin-RevId: 157746305
    
    ---
    Commit b020db0c6 authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    revert public visibility
    
    ---
    Commit 5b05728c2 authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    visibility workaround 3
    
    ---
    Commit 15a740ebb authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update and Move DNNLinearCombinedRegressor to estimator/canned.
    
    PiperOrigin-RevId: 157744087
    
    ---
    Commit d29bbeca3 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix outdated code ref in TensorBoard README, add link to SO question.
    
    PiperOrigin-RevId: 157743374
    
    ---
    Commit 9fc164225 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix index_table_from_file to allow vocabulary_file be a Tensor
    
    PiperOrigin-RevId: 157740677
    
    ---
    Commit 0aa3e0194 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change
    
    PiperOrigin-RevId: 157740660
    
    ---
    Commit 02ac85399 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduce new class Literal to replace protobuf Literal.
    
    This renames the existing Literal message to LiteralProto and introduces a new
    C++ class named Literal to replace it.
    
    The LiteralProto is only used at RPC boundaries, or when protobuf-specific
    functionality is required.  The Literal class offers a 'ToProto' function to
    generate a new LiteralProto message when necessary.
    
    Currently, all the static functions in class LiteralUtil, just forward to their
    counterparts in class Literal.  This will change in a future CL.
    
    Class Literal implements all the buffers as std::vectors.  The only exception
    is preds(), which given the std::vector<bool> representation, makes it unusable
    for the semantics we require (it's not possible to get the address of the
    underlying vector, for instance).
    
    The CL adds a BoolVector class to work around that issue.
    
    In future CLs, the std::vector representation may be changed to something more
    efficient, if needed.
    
    PiperOrigin-RevId: 157739125
    
    ---
    Commit 207203253 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Python 3.6 support on windows. (#10356)
    
    * Python 3.6 support on windows.
    
    * Fix typo in README.md
    
    * Make environment configurable for windows gpu build.
    
    ---
    Commit 2b75a9a6e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157734029
    
    ---
    Commit f60b6bdcb authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a warning to documentation of MonitoredSession.
    
    PiperOrigin-RevId: 157728225
    
    ---
    Commit eb10a4c49 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Preallocate vector storage when the ultimate vector size is known in advance
    
    PiperOrigin-RevId: 157724431
    
    ---
    Commit ce32228c4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add release notes for Intel MKL integration.
    
    PiperOrigin-RevId: 157722003
    
    ---
    Commit a23255bc0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds missing group OP to benchmark
    
    PiperOrigin-RevId: 157716500
    
    ---
    Commit d3e840a6c authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Disable writing of compressed checkpoints.
    
    Snappy compression (and decompression) was enabled after the
    1.1 release (in commit 63b2f999d3f22cfe915b89103faa1b0a1b1b7617).
    This means that checkpoints produced by the 1.2.0 release candidates
    will cause TensorFlow 1.1 (and prior) binaries to crash as they
    CHECK fail when trying to load snappy-compressed tables.
    
    To ease transition, disable writing of compressed checkpoints in
    1.2.0 for now.
    
    Reconsider this in the next release.
    
    PiperOrigin-RevId: 157675189
    
    ---
    Commit 6db400bbc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactoring Python op code generation.
    
    PiperOrigin-RevId: 157675126
    
    ---
    Commit d9620cab8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add flag to determine whether to do L1 optimizations and inline functions. Default is to do them. In tf_optimizer don't inline or do l1 optimizations.
    
    PiperOrigin-RevId: 157673614
    
    ---
    Commit 25bb504cc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make a plugin that serves data for the audio dashboard.
    
    Subsequent changes will make TensorBoard use this audio plugin instead of the previous handlers for audio-related data.
    
    PiperOrigin-RevId: 157673132
    
    ---
    Commit 24623653b authored by James Qin<jamesqin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix graph text format serialization
    
    PiperOrigin-RevId: 157669530
    
    ---
    Commit 3aed1735c authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    visibility workaround 2
    
    ---
    Commit fea90f89d authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    visibility workaround
    
    ---
    Commit 732a6b1ae authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Upgrade TypeScript to v2.3.4
    
    PiperOrigin-RevId: 157667511
    
    ---
    Commit 95d90ab2e authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Fixes Split op (#10322)
    
    * [OpenCL] Fixes Split op
    
      Split should alway go through SYCL device
    
    * [OpenCL] Removes half from registred types
    
    ---
    Commit 963441400 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Extends softmax op to cover double (#10323)
    
    ---
    Commit a702863e8 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Extends tile ops to int16 and int32 (#10328)
    
    * [OpenCL] Extends tile ops to int16 and int32
    
    * [OpenCL] Extends tile_ops to cover bool, uint8, int16, int64
    
    ---
    Commit 75385814f authored by cxx<cxxgtxy@gmail.com>
    Committed by cxx<cxxgtxy@gmail.com>:
    Fix comments error in mnist_replica.py where only one ps is used with two works by default.
    
    ---
    Commit 23364e2c6 authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    buildifier fix
    
    ---
    Commit e5088cb82 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix discrepancy between measured and analytical cost graph. Use tf_cuda_library for utils.
    
    PiperOrigin-RevId: 157660745
    
    ---
    Commit 787381ca5 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Split up session_test.py -> session_clusterspec_prop_test.py
    
    session_test.py has gotten very large. Additionally, recently it has become
    flaky. In order to both (1) improve overall code health, and (2) to facilitate
    root-causing the test flakiness, this CL begins to split apart session_test
    into focused subsets.
    
    I've suffixed the scoping of the session_test in order to preserve filesystem
    sort-order grouping.
    
    PiperOrigin-RevId: 157658981
    
    ---
    Commit b09932d74 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added PlaceholderWithDefault to the list of known placeholder types
    Use PartialTensorShape instead of TensorShapes to better handle partially known
    shapes
    
    PiperOrigin-RevId: 157657664
    
    ---
    Commit 0462416f6 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add make_ndarray, tensor_proto, and MetaGraphDef to tf api.
    
    Since TensorProtos are part of the TensorFlow API, it makes sense
    to also include the methods that generate and parse them.
    
    Similarly, we write out MetaGraphDef protos in the summary writer,
    so we should provide the proto as well.
    
    This is part of an ongoing effort to have TensorBoard only consume
    TensorFlow methods through the public api.
    
    PiperOrigin-RevId: 157657564
    
    ---
    Commit 458f94c12 authored by Wei Ho<weiho@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Open-source skip-gram ops
    
    PiperOrigin-RevId: 157655970
    
    ---
    Commit faac0331c authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduce tensorboard_zip_file build rule
    
    This rule can depend on web_library or tensorboard_html_binary. In
    both cases it will create a .zip file containing all the transitive
    web server paths. This can be used to deploy static assets to web
    servers.
    
    A small change was also made to Vulcanize to support path overriding.
    
    PiperOrigin-RevId: 157655047
    
    ---
    Commit 7ed44f4c9 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Split up session_test.py -> session_partial_run_test.py
    
    session_test.py has gotten very large. Additionally, recently it has become
    flaky. In order to both (1) improve overall code health, and (2) to facilitate
    root-causing the test flakiness, this CL begins to split apart session_test
    into focused subsets.
    
    I've suffixed the scoping of the session_test in order to preserve filesystem
    sort-order grouping.
    
    PiperOrigin-RevId: 157651813
    
    ---
    Commit 3c7ac46ae authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Teach Executable to do its own profiling (patch 4/4).
    
    This CL removes the xla::Service stub for ExecuteOnStreamWrapper so the users call the xla::Executable version directly, and simplifies the function API to simply accept "arguments" as a parameter (with a templated type) rather than requiring the user to capture it into a lambda around the relevant Executable::ExecuteOnStream method.
    
    PiperOrigin-RevId: 157651740
    
    ---
    Commit 626f95ab9 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Don't enforce that all nodes in an encapsulated subgraph are on the same device.
    Use the assigned device rather than the user-requested device when converting a Graph to a FunctionDef.
    
    PiperOrigin-RevId: 157648977
    
    ---
    Commit 414470329 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Guard stream pool with mutex.
    
    A data race can occur while populating the map.
    
    PiperOrigin-RevId: 157647183
    
    ---
    Commit ccdb30763 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Additional colocation options and bugfixes for TensorArray
    
    * colocate_with is now set properly when a TensorArray is passed through a
      while_loop
    * added a new argument, "colocate_with_first_write" (default: True; this is
      the current behavior).  If False, the TensorArray is simply placed on the
      device from the context it's constructed in, and no colocation constraints
      are added.
    
    PiperOrigin-RevId: 157643133
    
    ---
    Commit 03fc7022b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157642677
    
    ---
    Commit 41b87d6ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a new attribute narrow_range to FakeQuant* operations.  It quantizes into range [1; 255] instead of [0; 255].
    
    PiperOrigin-RevId: 157641054
    
    ---
    Commit c048e2938 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds support to non-placeholder inputs in _graph_to_function_def.
    
    Specifically, supports input ops with more than one output tensor.
    
    PiperOrigin-RevId: 157640908
    
    ---
    Commit d310de4fa authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Split up session_test.py -> session_list_devices_test.py
    
    session_test.py has gotten very large. Additionally, recently it has become
    flaky. In order to both (1) improve overall code health, and (2) to facilitate
    root-causing the test flakiness, this CL begins to split apart session_test
    into focused subsets.
    
    I've suffixed the scoping of the session_test in order to preserve filesystem
    sort-order grouping.
    
    PiperOrigin-RevId: 157640788
    
    ---
    Commit 8e868cf6a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused arguments to call_cpp_shape_fn.
    
    PiperOrigin-RevId: 157640125
    
    ---
    Commit 9ddbf31fe authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use unnamed namespace to effect internal linkage, replace string constructors with array-deducing helper function
    
    PiperOrigin-RevId: 157636308
    
    ---
    Commit 88ffe6276 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Increase cholesky_op_test to medium, bump shard_count 1 more.
    
    PiperOrigin-RevId: 157635774
    
    ---
    Commit bef563dc8 authored by Benjamin Kramer<kramerb@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Don't add constraints for computations we're not currently looking at.
    
    TuplePointsToAnalysis is computed globally per module, so we add all
    unconstrained buffers in that module, even if it's outside of the computation
    we're currently running on. Then we proceed to propagate default layouts to all
    those buffers and then throw the constraints away because they don't affect any
    instruction in the current computation.
    
    PiperOrigin-RevId: 157635564
    
    ---
    Commit a980aead8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use test_adjusted_name when making the mangled_test_name in
    run_and_gather_logs_lib.py, to avoid duplicate file names when the same test is
    run on multiple GPUs.
    
    PiperOrigin-RevId: 157630193
    
    ---
    Commit 0a84cfd58 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157629497
    
    ---
    Commit 6882effb8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make single-parameter constructors explicit
    
    PiperOrigin-RevId: 157628970
    
    ---
    Commit 0b8070253 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Support negative axis for Split op
    
    PiperOrigin-RevId: 157628162
    
    ---
    Commit 289e7bf5b authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Fixes and improvements to cmake windows build. (#10354)
    
    * Disable linalg ops tests on windows.
    
    * Do not print the full source code path for logs on windows.
    
    ---
    Commit bc236cfc3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Passes classification head to LinearClassifier.
    
    PiperOrigin-RevId: 157624020
    
    ---
    Commit cebd7e246 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Shanqing Cai<cais@google.com>:
    [OpenCL] Cleans debug ops (#10334)
    
    * [OpenCL] Cleans debug ops
    
    * Acts on feedback from #10334#discussion_r119452513
    
    * Acts on #10334#discussion_r119459463
    
    ---
    Commit fd6c3c4f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes flaky test in dnn_linear_combined_test.
    
    PiperOrigin-RevId: 157622951
    
    ---
    Commit c9cc388dc authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid CHECKs in BundleReader, propagate errors instead.
    
    Motivation:
    We'd like to evolve the checkpoint format over time (e.g., enable
    different types of compression). Without this change, a TensorFlow
    version that encounters a format that it doesn't understand would CHECK fail
    with an unhelpful error message.
    
    With this, it propagates a clearer error message up, giving the user some
    hints about what could be wrong.
    
    I don't have a unittest for this - I thought about writing a bundle and
    then strategically corrupting the bytes on disk before reading it back,
    but that seems a bit much. The intention of this change is to enable
    graceful reporting of forward compatibility breakages. Ideas for an
    appropriate unittest are appreciated.
    
    PiperOrigin-RevId: 157620358
    
    ---
    Commit ee05b8b69 authored by Wei Ho<weiho@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix to remove TF op usage outside of the initializer fn (due to deferred execution of initializer fn, this prevent issues with graph mismatch).
    
    PiperOrigin-RevId: 157620177
    
    ---
    Commit e8d17ea8c authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Materialize shapes that are known at graph construction time into constants
    that can be folded
    
    PiperOrigin-RevId: 157619380
    
    ---
    Commit dc0427d48 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Directly depend on the used libraries
    
    Do not rely on transitive dependencies.
    
    PiperOrigin-RevId: 157618184
    
    ---
    Commit 964d1a509 authored by Yuan Yu<yuanbyu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a bug that an erroneous control edge can be introduced when loops are nested in control dependency context.
    
    PiperOrigin-RevId: 157616919
    
    ---
    Commit 2de94bbb8 authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add an option to set the "generate HLO graph" regex without a flag.
    
    Pipes the option through xla.proto ExecutionOptions, to HloModuleConfig, which
    can then be accessed throughout the compiler.
    
    PiperOrigin-RevId: 157615458
    
    ---
    Commit d3c0482e6 authored by My name is<raviqqe@gmail.com>
    Committed by gunan<gunan@google.com>:
    Fix a typo in export_output.py (#9975)
    
    ---
    Commit 0c75d9f52 authored by ddurham2<ddurham@davyandbeth.com>
    Committed by gunan<gunan@google.com>:
    Adding lost documentation to tf.abs from the old tf.complex_abs when it learned how to work on complex data. (#9954)
    
    ---
    Commit 84661fa73 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Propagate control dependencies during constant folding
    
    PiperOrigin-RevId: 157610040
    
    ---
    Commit a3520340e authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Improve windows bazel python test suite. (#10305)
    
    * Improve windows bazel python test suite.
    
    - Create new tags, no_windows and no_windows_gpu
    - Instead of a separate maintained list, use bazel tags to exclude tests.
    - Tag all the python tests that are known to have issues in windows.
    
    * Also blacklist neon_depthwise_conv_ops_test in windows.
    
    * Only build tests in CPU windows tests.
    
    * Only build tests in GPU windows tests.
    
    * Also disable session_test on windows.
    
    * Only run py tests on windows, and only build tests that are not
    disabled.
    
    ---
    Commit a6f284ca4 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds integration tests for LinearRegressor.
    
    PiperOrigin-RevId: 157604107
    
    ---
    Commit d21bf7d75 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Backport changes from Github master.
    
    PiperOrigin-RevId: 157603238
    
    ---
    Commit 43bfc138c authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix OSS compilation error in tfprof_main.cc
    
    PiperOrigin-RevId: 157602449
    
    ---
    Commit 904a3d075 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixing issue with cuda compilation related to missing include (exception is only thrown when running with sandboxing on)
    
    PiperOrigin-RevId: 157602401
    
    ---
    Commit f59203c98 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Shard cholesky_op_test.
    
    PiperOrigin-RevId: 157601172
    
    ---
    Commit 3fdbb5579 authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Merging rc1 back into master.
    
    ---
    Commit be5d98a8b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds integration tests for DNNClassifier.
    
    PiperOrigin-RevId: 157592010
    
    ---
    Commit a05de6cd2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change reporting feature importances in RandomForestEstimator to run at the end of training, instead of part of the inference graph.
    
    PiperOrigin-RevId: 157591575
    
    ---
    Commit e96f1142f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unnecessary casts
    
    PiperOrigin-RevId: 157591439
    
    ---
    Commit 5f8571a6b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix missing namespace comments
    
    PiperOrigin-RevId: 157591364
    
    ---
    Commit eeb0b4067 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157573997
    
    ---
    Commit 7f9674217 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157573723
    
    ---
    Commit 473a590c9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Allow complex valued input for Cholesky decomposition.
    
    PiperOrigin-RevId: 157572536
    
    ---
    Commit 2d1860859 authored by Blake Hechtman<blakehechtman@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix test name in array_elementwise_ops_test.
    
    PiperOrigin-RevId: 157552402
    
    ---
    Commit a7fff05e0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tfprof multi-step profiling.
    
    This allows users to fill in RunMetadata across different steps.
    1. It is useful for RL model which runs a subset of graph each step.
    2. It also gets averages of multi-step stats.
    
    PiperOrigin-RevId: 157552388
    
    ---
    Commit fe589d9e7 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Implementation improvements (#9117)
    
    * OpenCL Improvements
    
    * Registers Scatter and ScatterNd Ops for SYCL
    
    * Registers Stack op for SYCL
    
    * Fixes No sycl buffer found error for debug ops
    
    * Registers MatMul and Transpose Ops to SYCL device for double
    
    * Extends analyzer_cli_test.py test to cover SYCL
    
    * Fixes Transpose Op for double when on SYCL
    
    * Bumps Eigen version to fix double precision issue on SYCL
    
    * Extends SessionDebugTestBase to cover SYCL
    
    * Register SYCL implementations for random ops
    
    * Avoid functions that might not be defined on SYCL device (#51)
    
    * Avoid functions that might not be defined on SYCL device
    
    * Simplify by using Eigen math functions
    
    * OpenCL improvements
    
     - Bumps Eigen Version
     - Refactors Ops registration
     - Introduces workaround for Const Op related to the difference between
       CUDA which uses pointers and OpenCL that uses buffers/accessors
     - Extends memory types to cover DEVICE_SYCL as well
     - Introduces  GetSYCLDevice() method that returns list of supported devices
       with GPU device having the highest priority ( doesn't include blacklisted devices )
     - ::internal::Transpose -> tensorflow::internal::Transpose in order to
       avoid compilation reported error
     - re-introduces fix for bugged string replacement causing a lot of compilation
       warnings -c -> --include
     - Adds sycl_runtime to bazels ARRAY_DEPS
     - Replicates TF_CALL_GPU_PROXY_TYPES for SYCL
    
    * [OpenCL] Fixes an issue caused by switch to aligned allocator for sycl buffer (#53)
    
    * [Build] Use gcc/g++ as a host compiler to avoid #8394 (#54)
    
    * [OpenCL] Fixes Scatter Op
    
    * Fix testSimple and testConst in stack_op_test (#3)
    
    * Fix testSimple and testConst in stack_op_test
    
    * Create a specialisation of DoParallelConcatUpdate for SyclDevice and
    register it
    
    * Guard all code in TENSORFLOW_USE_SYCL
    
    * Do not use sycl device for int32
    
    * Registration of the Sycl version is now looking like the one for the GPU
    
    * Remove added empty line
    
    * Register batch normalization kernels for OpenCL (#61)
    
    * [OpenCL] RandomGamma has no GPU friendly implementation (#57)
    
    * [OpenCL] Compatibility fixes for TensorFlow 1.1.0-rc1
    
    * [OpenCL] Implements BatchMatmul Op for SYCL
    
    * Lowercase the device name when GPU or SYCL returned
    
    * [OpenCL] kernel_estimator_test.py assertEqual-> assertAlmostEqual due to floating point representation on the device
    
    * [Eigen] Version bump
    
    * GPU device name string manipulation is not needed anymore
    
    * [OpenCL] Adds SYCL to device backwards compatibility
    
    * [OpenCL] Extends core_rnn_test.py to run for SYCL device
    
    * [OpenCL] Minor optimizations for build script
    
    * [OpenCL] Enables skip folder list in build script
    
    * [OpenCL] Fixes ApplyAdamOp for Sycl device
    
    * [OpenCL] SYCL device improvements
    
    * [OpenCL] Fixes debug_ops's SEGFAULT for SYCL device
    
    * [Build] Adds hexagon to skipped folders list
    
    * [OpenCL] Removes EnterLameDuckMode from SYCL device and allocator
    
    * [OpenCL] Registers Unique Op for SYCL device
    
    * [OpenCL][Temporary] Disables tests for SYCL target due to features not being implemented yet
    
      Tests affected:
        - tensorflow/contrib/memory_stats/python/kernel_tests/memory_stats_ops_test.py
        - tensorflow/contrib/rnn/python/kernel_tests/core_rnn_test.py
        - tensorflow/python/kernel_tests/conv_ops_test.py
        - tensorflow/python/kernel_tests/depthwise_conv_op_test.py
        - tensorflow/python/kernel_tests/pooling_ops_3d_test.py
        - tensorflow/python/kernel_tests/pooling_ops_test.py
        - tensorflow/python/kernel_tests/scatter_nd_ops_test.py
        - tensorflow/python/training/adam_test.py
        - tensorflow/python/training/localhost_cluster_performance_test.py
        - tensorflow/python/training/training_ops_test.py
    
    * [OpenCL][Temporary] Disables failing tests for SYCL in order to establish regression baseline
    
      Tests affected:
        - tensorflow/python/debug/cli/analyzer_cli_test.py
        - tensorflow/python/debug/lib/session_debug_testlib.py
        - tensorflow/python/debug/lib/stepper_test.py
        - tensorflow/python/kernel_tests/unstack_op_test.py
        - tensorflow/python/ops/image_ops_test.py
    
    * [OpenCL] Take options.config.device_count() into consideration
    
    * [OpenCL] Fixes compilation warning
    
    * [OpenCL] device:SYCL:0 -> sycl:0
    
    * [OpenCL] Removes unwanted flags in building script
    
    Removes flags given to computecpp that enable SIMD instructions
    Removes duplicate flags
    
    * bool -> const bool
    
    * [OpenCL] sycl in test_util.gpu_device_name() -> is_sycl_enabled()
    
    * [OpenCL][Temporary] Disables failing tests for SYCL in order to establish regression baseline
    
      Test affected:
        - tensorflow/contrib/stateless/python/kernel_tests/stateless_random_ops_test.py
    
    * Imports test_util from tensorflow.python.framework
    
    * [OpenCL] Fixes formatting in Python code
    
    * [OpenCL] Extends session_test.py to cover SYCL device
    
    * [OpenCL] Cleans singleton class
    
    * [OpenCL] Keeping CUDA happy
    
    * [OpenCL][Temporary] Disables failing tests for SYCL in order to establish regression baseline
    
      Test affected:
       - tensorflow/contrib/rnn/python/kernel_tests/core_rnn_cell_test.py
       - tensorflow/contrib/seq2seq/python/kernel_tests/beam_search_ops_test.py
    
    * Added support for building with SYCL on ARM.
    
    * Acts on the review feedback from:
     - #9117#discussion_r113608975
     - #9117#discussion_r113609173
    
    * [OpenCL] Fixes scatter_nd_op_test
    
    * Fixes auto-merge mistake
    
    * [OpenCL] struct SyclDevice -> class SyclDevice
    
    * Revert "[OpenCL] struct SyclDevice -> class SyclDevice"
    
    This reverts commit addd43348c374a5379f67bb1e5ad084715722fc2.
    
    * [OpenCL] Reverting refactoring commit.
    
      As requested in the review #9117#issuecomment-298454466
      This change set will be re-introduced in smaller chunks.
    
    * Revert "[OpenCL] device:SYCL:0 -> sycl:0"
    
    This reverts commit cf16e60340b62d16c3764d71b716fe03d35f87a9.
    
    * Revert "[OpenCL] Adds SYCL to device backwards compatibility"
    
    This reverts commit b8401b5164199b7a169be1c1d8dea5001195c390.
    
    * Acts on the feedback from #9117#discussion_r115036905
    
    * control_flow_ops_py_test.py expects device name to be lower cased
    
    * Acts on the feedback from #9117#discussion_r115037222
    
    * Removes debug print
    
    * Removes not needed partial specialisation
    
    * [OpenCL] Registers ScatterNdFunctor for SYCL device
    
    * [OpenCL] Make it compile
    
    * [OpenCL] Follow gpu_device changes
    
    * [OpenCL] Adds cxx_builtin_include_directory for python lib
    
      Fixes bazels missing undeclared inclusions that appeared after
      merge with TensorFlow upstream
    
    * [OpenCL] Fixes Constant Op
    
    * [OpenCL] gXX-4.8 -> gXX
    
    * [OpenCL] Removes -D_GLIBCXX_USE_CXX11_ABI=0 as it breaks default compiler setup for Ubuntu 16.04
    
    * Revert "[OpenCL] kernel_estimator_test.py assertEqual-> assertAlmostEqual due to floating point representation on the device"
    
    This reverts commit 06c50c0a485f40c30a436f02c3fa7794e370c49d.
    
    * [OpenCL] CPU allocator is a singleton we should not delete it
    
    ---
    Commit 7aac2395c authored by Blake Hechtman<blakehechtman@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Merge a copies of copies.
    
    PiperOrigin-RevId: 157549434
    
    ---
    Commit 37d9d5f0e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add some routines for managing summaries to slim.
    
    PiperOrigin-RevId: 157541902
    
    ---
    Commit d58cd2962 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix weblas license mirror URL
    
    PiperOrigin-RevId: 157537115
    
    ---
    Commit 5c13ee13b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make images-related logic use the images plugin.
    
    Previously, fetching images and related data from TensorBoard used handlers within application.py. We now remove those handlers in favor of routes offered by the images plugin. ML Dash is updated as well.
    
    PiperOrigin-RevId: 157536471
    
    ---
    Commit 60394a3d1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce size of the no-winograd tests, but still large enough that
    ShouldIncludeWinogradNonfusedAlgo returns true.
    
    PiperOrigin-RevId: 157535386
    
    ---
    Commit 9501c4104 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Replace protobuf CopyFrom with assignment
    
    PiperOrigin-RevId: 157534272
    
    ---
    Commit 96698f7fd authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf contrib seq2seq] Improve BeamSearchDecoder's ability to handle unknown shapes.
    
    Updated unit tests to contain inputs of unknown shape (at graph build time).
    Found an issue in the gather helper that stops it from properly propagating
    the batch size of the output shape.  This caused problems with tf.while_loop.
    Fixed.
    
    PiperOrigin-RevId: 157533937
    
    ---
    Commit 5c73d0102 authored by Neal Wu<wun@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Batch norm docs fix applied to _fused_batch_norm as well
    
    PiperOrigin-RevId: 157530527
    
    ---
    Commit abd4aa49a authored by Jonathan Hseu<jhseu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix docs for tf.abs() and tf.pow().
    
    PiperOrigin-RevId: 157528475
    
    ---
    Commit dd5ad6917 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Declarations of operators to support batch norm in xla
    
    PiperOrigin-RevId: 157527596
    
    ---
    Commit bbeaa1307 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix the expand_dim for label and weight for classifier heads.
    
    PiperOrigin-RevId: 157524909
    
    ---
    Commit 346021ab4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cleanup: Use C++ casts, remove redundant casts, use CHECK_OK
    
    PiperOrigin-RevId: 157522142
    
    ---
    Commit e405b0f6b authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactoring of layer name autogeneration, to remove a graph serialization warning.
    
    PiperOrigin-RevId: 157520123
    
    ---
    Commit 5784e1e35 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add HasOutputProperties to check for pruned ops; Return
    device name instead of casting it to a short name (GPU:0/CPU:0); VLOG(2) when printing op device placement since it is a lot of output.
    
    PiperOrigin-RevId: 157519077
    
    ---
    Commit 2994444bf authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Issue a more user-friendly error message if a variable's initializer is from inside a control-flow scope, such as tf.cond() or tf.while_loop().
    
    Fixes #8604.
    
    PiperOrigin-RevId: 157516279
    
    ---
    Commit da2daf068 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused using declarations
    
    PiperOrigin-RevId: 157513772
    
    ---
    Commit 8b2e8b566 authored by Derek Murray<derek.murray@gmail.com>
    Committed by gunan<gunan@google.com>:
    Exclude Python test files from CMake PIP package. (#10302)
    
    * Exclude *_test.py files from the CMake-built PIP package.
    
    * Add stray _test.py file to the PIP package.
    
    * Nit. Convert tabs to spaces in tf_python.cmake
    
    ---
    Commit 2249a4ea8 authored by Dan Ringwalt<ringwalt@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix control reaching the end of ProjectiveGenerator.
    
    PiperOrigin-RevId: 157510013
    
    ---
    Commit 040e2e20f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unneeded check for has properties in grappler.
    
    PiperOrigin-RevId: 157507665
    
    ---
    Commit 684006955 authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Windows: Remove session_test from bazel_test_lib.sh (#10274)
    
    It was disabled in 49b17146d2e4f04192d16ed67574142de167f3a1
    ---
    Commit 890a0a407 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by Gunhan Gulsoy<gunan@google.com>:
    Upgrade TF ci build and docker files to use bazel 0.5.0
    
    ---
    Commit 46db634e5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Only run the no-winograd tests once each.
    Only run the no-winograd tests on GPU; this also fixes
    timeouts in asan and msan.
    
    PiperOrigin-RevId: 157505317
    
    ---
    Commit a6cd4e735 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove all TB build references that circumvent TF's public API.
    
    This doesn't actually remove all the code references, lots of code references continue to work despite the BUILD references being removed. I think this is because depending on the public api transitively makes all of TensorFlow's guts available too.
    
    PiperOrigin-RevId: 157502987
    
    ---
    Commit dcc3cdce8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove redundant get() calls and string conversions
    
    PiperOrigin-RevId: 157497932
    
    ---
    Commit af2b9d875 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix the trace inputs functionality of the graph explorer.
    
    After migrating to d3 v4, the graph can no longer directly index into d3.Selections to obtain elements. Instead, we must use the nodes method of d3.Selection to generate an array of selected elements.
    
    PiperOrigin-RevId: 157493509
    
    ---
    Commit 5cf484584 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Small test that performs A*B+A and A*B+B.
    
    PiperOrigin-RevId: 157492992
    
    ---
    Commit b2355913b authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    remove some invalid entries (#10294)
    
    I noticed that some entries don't exist (anymore).
    This seems to be some kind of a consistency issue.
    
    More specifically:
    `tensorflow/contrib/ios_examples/camera/data`
    `tensorflow/contrib/session_bundle/testdata/saved_model_half_plus_two`
    `tensorflow/contrib/session_bundle/testdata/saved_model_half_plus_two/variables`
    
    This is the continuation of PR #10264
    ---
    Commit 367ec84f8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add SampleEmbeddingHelper to do sampling at inference time
    
    PiperOrigin-RevId: 157487623
    
    ---
    Commit a3ba225d5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add BatchMatMul execution cost prediction
    
    PiperOrigin-RevId: 157487507
    
    ---
    Commit 34a29fc3b authored by Eric Liu<ioeric@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] preserve metadata when replacing HLO instructions.
    
    The motivation is to add metadata for HLO instructions that are created to replace existing HLO instructions during optimizations. The assumption is that the old instruction and the new instruction would perform the same function, and that they would be correlated to the same TF op. This might not always be correct since HLO optimizations can cross TF op boundaries. But still this seems to be better than nothing.
    
    Note that this still doesn't fully resolve missing OpMetadata after HLO optimizations; new instructions might be added without using ReplaceInstruction.
    
    PiperOrigin-RevId: 157484394
    
    ---
    Commit 092a7b6e6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Disable keras lstm test in tsan.
    
    PiperOrigin-RevId: 157484268
    
    ---
    Commit 7280dafca authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use "empty" member function to test for emptiness
    
    PiperOrigin-RevId: 157483181
    
    ---
    Commit 6c3b15915 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expands integration tests in dnn_test.
    
    PiperOrigin-RevId: 157476608
    
    ---
    Commit 727193b1f authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    add missing import for `signal` package (#10264)
    
    * add missing import for `signal` package
    
    * add missing dependency for `signal` package
    
    * Update tf_python.cmake
    
    ---
    Commit 21461213d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused BUILD dependencies
    
    PiperOrigin-RevId: 157473460
    
    ---
    Commit 4788ca2be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix handling of Infinity/NaN in line chart domain
    
    Test Plan:
      - Use the script listed below to generate data that has enough
        infinities for these values to not be treated as outliers.
      - Load the data into TensorBoard (`--logdir /tmp/infbug`) and look at
        the scalars plot; also look at the console.
      - Before this change, the chart is completely blank, and there is a
        console warning: "QuantitativeScales cannot take NaN or Infinity as
        a domain value. Ignoring."
      - After this change, there is no console output, and the chart appears
        as intended: a reasonable domain is shown, and the infinities just
        shoot off the chart.
    
    Generating script:
    ```py
    import tensorflow as tf
    
    LOGDIR = '/tmp/infbug'
    STEPS = 134
    
    def main():
      x = tf.Variable(3.1415)
      y = x.assign_add(x)
      tf.summary.scalar('y', y)
      summ = tf.summary.merge_all()
    
      sess = tf.Session()
      writer = tf.summary.FileWriter(LOGDIR)
      writer.add_graph(sess.graph)
      sess.run(tf.global_variables_initializer())
      for step in xrange(STEPS):
        writer.add_summary(sess.run(summ), step)
      writer.close()
    
    if __name__ == '__main__':
      main()
    ```
    
    PiperOrigin-RevId: 157472340
    
    ---
    Commit 49476a62c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused namespace aliases
    
    PiperOrigin-RevId: 157468609
    
    ---
    Commit d83074847 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use "nullptr" for null pointer values
    
    PiperOrigin-RevId: 157468186
    
    ---
    Commit b73fea6e2 authored by Tim Harley<tharley@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactor `tf.Operation.traceback` implementation in to methods of tf.Graph.
    
    Adds an `_extract_frame_info` method to allow derived classes to extend the
    information available in each op traceback, if desired. The default result of
    `tf.Operation.traceback` is unchanged.
    
    Also fixes a poorly scoped `pylint disable=line-too-long`, so adds the necessary
    enable/disable blocks to silence pylint for the offending docstrings.
    
    PiperOrigin-RevId: 157466174
    
    ---
    Commit f7ca8db7d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Improve shape inference error messages for DynamicSlice/DynamicUpdateSlice.
    
    PiperOrigin-RevId: 157461335
    
    ---
    Commit 8c2a079ec authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding a slot / accumulator warmstart initializer that overrides the provided partitioner at call time with one passed at construction time.  This is intended to be used for slot Variables (such as accumulators) associated with Optimizers, since these Variables are created in a fashion that relies on replicating the exact shape of the associated primary variables (see slot_creator).
    
    PiperOrigin-RevId: 157453498
    
    ---
    Commit 73d10599f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Default CUDNN_HOME to CUDA_TOOLKIT_TARGET_DIR. The cuDNN distro is most naturally installed in the same directory as the CUDA SDK, so try to find it there if the user doesn't specify any other directory.
    
    PiperOrigin-RevId: 157436253
    
    ---
    Commit eb7cf9331 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157429266
    
    ---
    Commit 346dcc0a4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157429078
    
    ---
    Commit 3d5ede131 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update documentation for sparse_matmul op to reflect gradient calculation.
    
    PiperOrigin-RevId: 157428135
    
    ---
    Commit 822d64f0c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix embedding_lookup() bug where normalization did not work with ids of rank != 1.
    
    PiperOrigin-RevId: 157422220
    
    ---
    Commit 8cad6b824 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Improve the error message for live set memory check.
    
    PiperOrigin-RevId: 157415647
    
    ---
    Commit 34dcd5b49 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf contrib seq2seq] Bugfixes to BeamSearchDecoder
    
    Implementation by Cinjon Resnick.  He can't push this since he's traveling.
    I just copied the fix and added some small syntax tweaks to make the unit
    tests pass.  More comprehensive unit tests will come in the near future.
    
    Fixes at least part of #9904.
    
    BeamSearchDecoder:
    1. Fix the bug where we don't pass the next cell state through.
    2. Gather the cell state (and attention if that's a part of the model
       as an AttentionWrapper on the cell) according to the next_beam_ids.
    PiperOrigin-RevId: 157415564
    
    ---
    Commit f7ae1461c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix oversampling in the GPU version of multinomial due to an error in generating
    gumbel noise.  -log(-log(U)) gives infinity if U draws a hard 0.  Adds a tiny
    offset to U (2e-30) to avoid log(U) = -inf.
    
    The CPU sampling algorithm depends on the order of the logits which is
    undesirable and can also oversample the first logit if it is smaller than the
    smallest random float larger than 0 (~1e-7).  Switching to double precision
    internally mitigates these problems, although it doesn't fix them.  Slowdown
    is ~35% in the worst case.
    
    Also adds various tests that we would like the sampling to pass.
    
    CPU Benchmark before:
    
    32 10000 1 0.060 0.069 0.87
    32 10000 4 0.229 0.074 3.10
    32 10000 32 2.180 0.059 37.09
    32 100000 1 0.430 0.480 0.90
    32 100000 4 2.322 0.449 5.17
    32 100000 32 31.508 0.471 66.96
    128 10000 1 0.168 0.235 0.71
    128 10000 4 0.965 0.246 3.93
    128 10000 32 7.989 0.225 35.51
    128 100000 1 1.681 1.539 1.09
    128 100000 4 9.012 1.57 35.73
    128 100000 32 126.222 1.626 77.60
    
    CPU Benchmark after:
    
    32 10000 1 0.054 0.112 0.48
    32 10000 4 0.206 0.093 2.21
    32 10000 32 1.826 0.091 20.12
    32 100000 1 0.292 0.636 0.46
    32 100000 4 2.086 0.606 3.44
    32 100000 32 28.496 0.633 45.03
    128 10000 1 0.125 0.266 0.47
    128 10000 4 0.759 0.258 2.94
    128 10000 32 7.362 0.254 29.03
    128 100000 1 1.550 2.18 10.71
    128 100000 4 8.712 2.22 23.92
    128 100000 32 122.585 2.213 55.39
    
    PiperOrigin-RevId: 157414849
    
    ---
    Commit 62cf561f1 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add numpy_input_fn integration for LinearRegressor and fix the expand_dim for label and weight.
    
    PiperOrigin-RevId: 157405237
    
    ---
    Commit 40c7e0dd7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157402364
    
    ---
    Commit 2726c00ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157402063
    
    ---
    Commit e9d2fba8f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix comment describing ignore_longer_outputs_than_inputs.
    
    PiperOrigin-RevId: 157400110
    
    ---
    Commit 5f097217f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    An initial step of eliminating all implicit broadcast at the HLO level.
    Guard the shape inference for binary ops behind a flag.
    
    PiperOrigin-RevId: 157373647
    
    ---
    Commit e78e5ec8a authored by Yangzihao Wang<yangzihao@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set winograd nofused flag to be true by default.
    
    Disable winograd nonfused conv for certain input params to avoid a known bug in cuDNNv5 and cuDNNv6.
    
    PiperOrigin-RevId: 157352847
    
    ---
    Commit 3f9b69a50 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast variant for forward convolution when the input images are smaller than 16x16.
    
    PiperOrigin-RevId: 157347823
    
    ---
    Commit 848123e61 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix incorrect condition to instantiate depthwise_ops introduced in commit 15d9f00fa. The change should have excluded depthwise_conv2d for doubles on windows debug builds, but it excluded it for all windows and all debug builds.
    
    PiperOrigin-RevId: 157345929
    
    ---
    Commit 060d67b34 authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by Taehoon Lee<taehoonlee@snu.ac.kr>:
    Fix typos
    
    ---
    Commit 409419bcc authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    add closing code quotes
    
    PiperOrigin-RevId: 157339360
    
    ---
    Commit d20d0a623 authored by Jonathan Hseu<jhseu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix the contrib estimator_test by updating the global step in all the appropriate spots.
    
    PiperOrigin-RevId: 157328239
    
    ---
    Commit d1144d3a9 authored by Juang, Yi-Lin<b02901026@ntu.edu.tw>
    Committed by Juang, Yi-Lin<b02901026@ntu.edu.tw>:
    Fix typos
    
    ---
    Commit fa8bb43b1 authored by lanhin<lanhin1@gmail.com>
    Committed by lanhin<lanhin1@gmail.com>:
    Fixed a comment typo in GraphView:InitializeNode(), executor.cc.
    
    ---
    Commit 9f13ae93f authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Java: Update Maven release to 1.2.0-rc1
    
    PiperOrigin-RevId: 157294719
    
    ---
    Commit c8256769c authored by Gunhan Gulsoy<gunan@google.com>
    Committed by Gunhan Gulsoy<gunan@google.com>:
    Address comments and sanity check failures.
    
    ---
    Commit 344225a60 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157292254
    
    ---
    Commit eb2f6d041 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    VLOG(2) instead of VLOG(1) for detailed op printouts.
    
    PiperOrigin-RevId: 157291238
    
    ---
    Commit b4466279a authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tfdbg: add runtime shape and dtype info to DebugNumericSummary
    
    PiperOrigin-RevId: 157291215
    
    ---
    Commit 4fb2425f8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add GraphOptimizer to Grappler item builder to do L1 optimizations and
    inlining.
    
    Op Counts Comparison (BNMT)
    Counts: Profile vs Grappler
    Op: Add, 968 vs 965
    Op: AddN, 2228 vs 2228
    Op: ApplyGradientDescent, 84 vs 84
    Op: BatchMatMul, 998 vs 998
    Op: Identity, 142 vs 105
    Op: MatMul, 63 vs 63
    Op: Mul, 10318 vs 10306
    Op: OneHot, 1 vs 1
    Op: Reshape, 8421 vs 8422
    Op: Select, 488 vs 488
    Op: Shape, 8132 vs 8131
    Op: Sigmoid, 942 vs 942
    Op: Softmax, 19 vs 19
    Op: StridedSlice, 58 vs 74
    Op: Sub, 1398 vs 1394
    Op: Tanh, 333 vs 333
    Op: Tile, 21 vs 21
    Op: Transpose, 39 vs 39
    PiperOrigin-RevId: 157288420
    
    ---
    Commit 8918fa9ef authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 157272843
    
    PiperOrigin-RevId: 158534336

commit 02ac85399d4fb35d5055ecf426632b9446a70041
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jun 1 11:30:36 2017 -0700

    Introduce new class Literal to replace protobuf Literal.
    
    This renames the existing Literal message to LiteralProto and introduces a new
    C++ class named Literal to replace it.
    
    The LiteralProto is only used at RPC boundaries, or when protobuf-specific
    functionality is required.  The Literal class offers a 'ToProto' function to
    generate a new LiteralProto message when necessary.
    
    Currently, all the static functions in class LiteralUtil, just forward to their
    counterparts in class Literal.  This will change in a future CL.
    
    Class Literal implements all the buffers as std::vectors.  The only exception
    is preds(), which given the std::vector<bool> representation, makes it unusable
    for the semantics we require (it's not possible to get the address of the
    underlying vector, for instance).
    
    The CL adds a BoolVector class to work around that issue.
    
    In future CLs, the std::vector representation may be changed to something more
    efficient, if needed.
    
    PiperOrigin-RevId: 157739125

commit 9c495f9499199ea46fff9028774374fa0c52e018
Author: Brennan Saeta <saeta@google.com>
Date:   Fri May 26 11:04:04 2017 -0700

    Add session.list_devices() API
    
    In order to debug a TensorFlow cluster or check whether devices are available
    in a local session (e.g. GPU drivers are loaded), this change adds a
    `sess.list_devices` API to list all devices within the cluster.
    
    This CL implements the list_devices() feature via extensions to the TensorFlow
    C API, and the corresponding additions to the session.h session class and
    corresponding subclasses for both direct sessions, grpc_sessions,
    tensorflow_serving, and others.
    
    Additionally, in order to accomidate ClusterSpec propagation clusters,
    Master::ListDevices now also includes a session_handle in order to identify
    the appropriate master_session on which it should list the available
    devices. (With ClusterSpec propagation, different sessions can have different
    servers with different device capabilities.)
    
    This CL adds a ListDevices() API to MasterSession. It is most
    efficient to implement this API call there, because the MasterSession
    already has a list of devices.
    
    Additionally, this change upgrades the implementation of
    Master::ListDevices() to delegate to the MasterSession if a session
    handle is specified, and to return an error if no corresponding session
    is found.
    PiperOrigin-RevId: 157239656

commit ac9fee249c52de7abb113372f093a6bb620dee9c
Author: Eugene Brevdo <ebrevdo@google.com>
Date:   Mon May 22 17:06:20 2017 -0700

    C++ implementation of SparseFillEmptyRows
    
    Should be much faster and more efficient than the python version.  Does not
    require sorted indices.  safe_embedding_lookup_sparse should now be faster.
    
    (will take full effect in 3 weeks, on June 10th)
    
    PiperOrigin-RevId: 156806888

commit 18727ef581297437e20d6df4a08b60e8b021f284
Author: Ian Langmore <langmore@google.com>
Date:   Mon May 15 09:43:42 2017 -0700

    .assert_positive_definite and .assert_non_singular default implementations
    added to LinearOperator base class.
    
    Previously I was avoiding these because they are inefficient...however, the
    desire to have a consistent API is overriding this.
    
    PiperOrigin-RevId: 156064641

commit 9e7bf403817a3acd4e8d865b041f37609564076e
Author: drpngx <drpngx@users.noreply.github.com>
Date:   Mon Apr 10 13:55:56 2017 -0700

    Branch 152703253 (#9112)
    
    * Improve py_func error handling.
    
    Automatically translate some python errors into corresponding TF errors at runtime.
    Change: 152156821
    
    * Update interaction with libpng so that we use the public API instead of
    knowledge of the internal libpng data structures.
    Change: 152167754
    
    * TensorBoard plugins now contain their own name/route prefix.
    Change: 152167807
    
    * Passes trainable flag to separable_conv2d biases.
    Change: 152170239
    
    * Saving resource variables with a caching device.
    Change: 152171539
    
    * Drop loss from estimator_spec.eval_metric_ops, as required by core Estimator.
    Change: 152179924
    
    * sample_stats.percentile DOCFIX.
    Change: 152182295
    
    * Added a memory optimizer to grappler.
    Change: 152184170
    
    * Change default behavior of the tf runs selector:
    
    - If there are fewer than 41 runs, enable them all by default
    - If there are 41 runs or more, disable them all by default
    
    This is in response to user complaints that having it enable only the first ten runs by default was confusing, because it was not obvious to users that some runs had been disabled.
    However, it still solves the initial user complaint that having very many runs simultaneously enabled would lag the UI.
    
    I also changed the "toggle all runs" button to try to turn everything off before turning everything on.
    Also, I improved the logic for detecting when the runs selection is back in the default state, so that we can avoid generating long URI strings wherever possible.
    Change: 152188948
    
    * Autogenerated Change: Change TensorBoard TAG to 52
    Change: 152189000
    
    * Remove warning that only happening with config cuda.
    Change: 152189205
    
    * Make resource variable shared name consistent with non-resource variables.
    
    Remove colocation constraint from resource variable cached value with the
    variable itself.
    Change: 152192203
    
    * Add a way to specify the optimization order; refactor and add constant folding to meta optimizer.
    Change: 152193646
    
    * Backport fixes and improvements from external Keras.
    Change: 152198296
    
    * Merge changes from github.
    Change: 152200430
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    Change: 152200754
    
    * Update ops-related pbtxt files.
    Change: 152203174
    
    * Make ImportGraphDef() work with functions.
    
    In addition to modify graph_constructor.cc, this patch adds some other
    functionality to enable importing fucntions:
    * Ability to add FunctionDefLibraries to Graphs and
      FunctionLibraryDefinitions (in addition to existing functions)
    * FunctionDefsEqual() utility function
    Change: 152205258
    
    * Expand contrib test to more than just test targets.
    Change: 152206822
    
    * Preserve graph version during optimization
    Change: 152213262
    
    * Exclude enter and exit nodes from shape refiner's constant folding.
    Change: 152213637
    
    * Allow reshape_mover and algebraic_simplifier to make multiple mutations, by avoiding the short-circuit
    std::any_of.
    Change: 152232810
    
    * Fix dynamic_rnn transpose bug (can input/output non-3d tensors).
    
    Also a few cleanups to RNN code.
    Change: 152267628
    
    * Fix flaky tests
    Change: 152272801
    
    * Add an auto parallelization grappler optimization pass.
    Change: 152276787
    
    * Change json.decode.JSONDecodeError to ValueError.  JSONDecodeError seems to be
    the exception used in the simplejson module, not the json module.
    Change: 152278012
    
    * Internal change.
    Change: 152281471
    
    * [XLA] Force buffer sharing of separate while instructions.
    Change: 152288540
    
    * replica_device_setter should work for resource variables
    Change: 152289915
    
    * Fix ./configure script
    1. Add %workspace% in .bazelrc file when using import statement
    2. Write action_env into bazelrc file for required environment variables for OpenCL support
    Change: 152290700
    
    * Pointing a number of Tensorboard graph visualization-related help links to the new locations for the correspondent API documentation.
    Change: 152293459
    
    * Restore most of pull request #8606
    
    Pull request #8606 added str(Label(...)) for most dependencies in
    tensorflow.bzl, allowing most functions to be used from repositories which
    include TensorFlow as a submodule.  Unfortunately, it broke when pulled into
    Google and was removed in cl/152200430.  This CL restores the change, except
    for two Android-only functions; these were the only problematic bits.
    Change: 152297413
    
    * Removed dead code in Estimator.
    Change: 152297597
    
    * Assert rank is at least equal to new_rank for `_sparse_inner_flatten`.
    Change: 152303319
    
    * Extend quantization ranges to include 0.0f.
    Change: 152304380
    
    * Remove Keras config file saving.
    Change: 152306552
    
    * API backwards compatibility tests.
    Change: 152310869
    
    * [TF:XLA] Add a test for an R3 -> R4 broadcast.
    Change: 152313967
    
    * Fix the problem that no enough placeholders for persistent tensor
    batch delete
    
    The deleter_key is always a device_name, hence there is only one
    of it. Hence, we cannot delete >1 handles at one time.
    
    In the fix, it creates delete placeholder on demand, the max
    number of placeholders is _DEAD_HANDLES_THRESHOLD.
    Change: 152322770
    
    * [XLA] Add several reduction tests.
    Change: 152323510
    
    * Added the memory optimizer to the meta optimizer.
    Change: 152323689
    
    * Started a set of utilities to categorize op types
    Change: 152329057
    
    * Add AudioSpectrogram op to TensorFlow for audio feature generation
    Change: 152332221
    
    * Update ops-related pbtxt files.
    Change: 152332812
    
    * Automated rollback of change 152332221
    Change: 152333917
    
    * Call Py_CLEAR on dead fields during TF_RESOURCE-to-ndarray conversion
    Change: 152338333
    
    * [TF contrib seq2seq] Initial, incomplete implementation of beam search decoder.
    
    **DOES NOT WORK, pushed for collaboration only**
    Change: 152343927
    
    * [XLA] Change HloPassPipeline to disallow Add* calls after Run.
    Change: 152345578
    
    * Automated rollback of change 152332812
    Change: 152349057
    
    * Remove all 64/32 bit compiler warnings from core/ops.
    Change: 152353506
    
    * libtensorflow.so: Don't export private symbols.
    
    With this change, libtensorflow.so will only export
    functions defined in c_api.h. This also results in
    a decreased binary size of libtensorflow.so.
    
    On Linux the decrease was from roughly 150MB to 67MB.
    On OS X it was from roughly 101MB to 82MB.
    
    Also fixes #8923
    Change: 152366053
    
    * Add Elu ops in XLA.
    Change: 152383201
    
    * Fixed test. ('broadcast_dims' has size 1)
    Change: 152383633
    
    * Add more detailed error message for rank assertion in _sparse_inner_flatten.
    Change: 152397909
    
    * tensor_bundle: propagrates errors related to directory creation.
    Change: 152401909
    
    * matrix_adjoint added to contrib/linalg/linear_operator_util
    Change: 152404828
    
    * Add an is_active method to plugins
    
    This method determines whether a plugin is active. A plugin may be inactive if say it lacks data. This new is_active method allows us to add a route to TensorBoard noting which plugins are active. The frontend could then avoid querying routes of inactive plugins.
    Change: 152406232
    
    * Replace a gather op for shapes by a stack op so dilated convolutions can be
    placed on GPU even with strict placing (before the gather went to CPU).
    Change: 152411159
    
    * [TF:XLA] Implement BatchToSpace, BatchToSpaceND, SpaceToBatch, SpaceToBatchND.
    Fix crashes in core implementations of the same operators for zero-sized blocks.
    Change: 152416903
    
    * Estimator saves relative paths in checkpoint.
    Change: 152420211
    
    * Fix layers_test exception regex matching.
    Change: 152422855
    
    * Unhide bijectors. Correct TransformedDistribution docstring.
    Change: 152424418
    
    * Choosing a saner default for min_eval_frequency in the constructor for Experiment for the GCS file system, because the default of 1 causes performance problems.
    Change: 152439984
    
    * Inherit use_resource from scope for partitioned variables.
    Change: 152442103
    
    * Support quantized reshape in hexagon runtime
    Change: 152445539
    
    * tfdbg CLI: add command list_source (ls) + UI fixes and improvements
    
    The new list_source (shorthand: ls) command lists Python source files responsible for constructing the nodes and tensors encountered in the run() call.
    
    It divides the source files into two categories and list them separately.
    1) files that are not part of the TensorFlow Python library, and
    2) files that are a part of it.
    
    The list contains information about how many nodes, tensors and dumps of tensors the files is responsible for. The file paths contain clickable links to the existing print_source/ps command.
    
    The list_source/ls command supports filtering by file-path and node-name regex patterns.
    
    UI fixes:
    * Fixed inconsistent black vs. transparent background color that made the layout look messy on some terminal types. Now using the transparent color for default font color consistently.
    * In the print_source command output, add clickable links to expand source lines and graph elements.
    Change: 152446002
    
    * tfcompile: Be a little more verbose about missing required flags.
    
    Fixes #9014
    Change: 152446338
    
    * Disable failing test cases in pooling_ops_test.
    Change: 152447322
    
    * Register more types for tf.image_crop_and_resize(). Resolves #9020.
    Change: 152448160
    
    * Automated rollback of change 152439984
    Change: 152450929
    
    * Add a route to TensorBoard for fetching plugin names
    
    Specifically, we add a /data/plugins_listing route to the TensorBoard application. This route responds with an object mapping the name of each initialized plugin to whether it is active.
    
    This route could help the frontend avoid issuing requests to inactive plugins.
    
    Ordered the listing of routes within application.py so there is a little more organization.
    
    Refactored the test for application to use a fake plugin.
    Change: 152451390
    
    * Added the ability to retrieve the amount of usable gpu memory
    Change: 152453470
    
    * Allow to set session ConfigProto in RunConfig and use it in Estimator.
    Change: 152454548
    
    * Colocate ResourceVariable reads with their handles.
    Change: 152455939
    
    * tfdbg: update doc for new command list_source/ls
    Change: 152456128
    
    * Make rnn directions slightly easier to follow.
    Change: 152456296
    
    * Internal change
    Change: 152458104
    
    * Adds batch renormalization.
    
    NOTE: if you use renormalization, you might want to use faster moving average updates, i.e. lower `decay` values.
    Change: 152458872
    
    * When using ImportGraphDef with a passed in ShapeRefiner, use the
    producer version of the GraphDef when importing; the ShapeRefiner
    may be initialized with a different graph_def_version, so we need
    to be able to override it.
    
    The test failed without the change to graph_constructor and passes with it.
    The test uses a legacy graph that is supported (reduction shape).
    Change: 152459169
    
    * Allow any iterable for `export_strategies` arg.
    Change: 152461826
    
    * Log steps/sec every 100 steps in MonitoredSession, as before.
    Change: 152465320
    
    * Fixes documentation to note that the in case of ties the identity of the return value of ArgMin and ArgMaxis not guaranteed .
    Change: 152465346
    
    * Automated rollback of change 152465346
    Change: 152465844
    
    * Fix shape inference fn on _ParallelConcatStart.
    Change: 152466076
    
    * Fix getting started guide
    
    Explain numerical differences in loss
    fix one example to print
    Change: 152466119
    
    * Remove superfluous mode argument.
    Change: 152467334
    
    * Add a tool that converts HLO computations to tensorflow GraphDef which can be visualized on Tensorboard.
    
    This CL defines basic tensorflow::OpDef for each HLO instruction/node. More attributes (e.g. shapes, colors) will be added in the future.
    Change: 152477918
    
    * [TF:XLA] Increase shard count of //third_party/tensorflow/compiler/tests:spacetobatch_test to reduce flakiness when built under ASAN.
    Change: 152496244
    
    * Make projector plugin backend read assets saved via the PluginAssets API.
    
    At the same time, keep backwards compatibility with the old way of looking up assets.
    Change: 152504793
    
    * Move MNIST pointers to mirror hosted by the CVDF on Google Cloud.
    Fixes: #9031
    Change: 152504901
    
    * Merge changes from github.
    Change: 152508170
    
    * Update API after changing default step couter frequency before.
    Change: 152517535
    
    * Move a few random op helper functions to header files
    
    1. shape_inference::RandomShape
    2. OpKernel::MakeShape(Tensor, TensorShape*)
    Change: 152522156
    
    * addresses the divide by zero bug
    Change: 152522488
    
    * Clarify doc on tf.assign.
    Change: 152523909
    
    * Sparse adam for resource variables.
    Change: 152525327
    
    * Automated rollback of change 152310869
    Change: 152528732
    
    * Add an env_var tf_sync_on_finish_bool that block until device has finished all queued operations in a step if true.
    Change: 152533676
    
    * Add more node attributes for HloInstruction on Tensorboard e.g. shape and layout etc.
    Change: 152534472
    
    * Add tf.complex64 GPU support to tf.gather.
    
    Also add ldg specializations for std::complex.
    Change: 152537848
    
    * Formatting changes
    Change: 152544842
    
    * Upgrade TensorBoard TypeScript to 2.2.1
    
    See also: #8326
    Change: 152545950
    
    * TEST:  Getting reasonable test sizes on linalg library, removing need for
    sharding.
    Change: 152546409
    
    * Disabling _testSourceUtilModuleReturnsTrue as its causing opensource issues.
    Change: 152548721
    
    * Fix race due to unsafe buffer forwarding in maxpooling second order gradients added in #6664.
    Re-enable previously flaky tests.
    Clean up a few minor things in maxpooling_op_gpu.cu.cc
    Change: 152550050
    
    * LinearOperator:  adjoint_arg kwarg added to all operators.  Now,
    operator.apply(x, adjoint_arg=True) means that the adjoint of 'x' is taken
    before application of operator.  Sometimes this is done more efficiently than
    simply taking adjoint.
    Change: 152560471
    
    * Adds weighted_average_loss metric key.
    Change: 152560999
    
    * Documentation: Fix bug in manual device placement example
    Change: 152563392
    
    * Change for internal compatibility.
    
    * Use std::vector for storage instead of map.
    Do the sorting inplace and return the same vector to avoid any copies.
    On larger streams it is about 50% faster.
    Change: 152576112
    
    * Add tf.add_n GPU support for complex64/complex128.
    
    Also adds a unit test for tf.add_n.
    Change: 152577190
    
    * - Adds support for nested types in tf.case and tf.cond.
    - Adds a "strict" mode which disables silent unpacking of singleton lists.
    - Adds shape inference to tf.case.
    - Adds a lot of unit tests.
    Change: 152581097
    
    * [XLA] Add support for folding transpose into convolution
    Change: 152581336
    
    * Add a smoke test to ensure that the doc generator runs.
    Change: 152592164
    
    * Add tensorboard to the _do_not_descend_map of the PublicAPIVisitor.
    Change: 152592268
    
    * Add auto parallelization to meta optimizer. Enable MetaOptimizer if any one of the optimizers is on.
    Change: 152598517
    
    * Update ops-related pbtxt files.
    Change: 152629248
    
    * Prevent the renorm_weight from being updated too early.
    Change: 152631776
    
    * Automated rollback of change 152528732
    Change: 152652473
    
    * Construct TensorBoard dashboards in a JS list
    
    Previously, adding a dashboard to TensorBoard involved changing logic in several places.
    
    As part of this effort, added constructors to dashboards. Tweaked logic in various dashboards to preserve original behavior. For instance, the graph dashboard can only perform fitting after the dashboard is attached to the DOM.
    Change: 152658532
    
    * Make CheckpointSaverListener visible next to CheckpointSaverHook.
    Change: 152662945
    
    * tfdbg CLI: minor bug fixes
    
    1: The calculation of the scroll command in the scroll bar didn't take into account that the y-coordinate of the scroll block is in the ScrollBar coordinate system, while the mouse click y-coordinate is in the screen coordinate system.
    
    2: The y position of the ScrollBar was off by one.
    
    3: The command box is not re-created after mouse-triggered commands, leading to strange-looking cursor position.
    Change: 152684294
    
    * Remove obsolete use of validate_indices from embedding_ops.py
    
    validate_indices is ignored, so it shouldn't appear in new code.
    Change: 152691948
    
    * Preparation of using GMock matchers in XLA tests.
    Change: 152691970
    
    * Replace RuntimeException by RuntimeError in coordinator documentation.
    Change: 152697758
    
    * Move the TensorBoard debugger plugin to be internal.
    
    This feature is currently not open-source anyway.
    Change: 152700267
    
    * Add a single-machine tf.learn Estimator implementation for the WALS solver.
    Change: 152700915
    
    * Add tf.contrib.training.python_input -- making it easy to feed data into
    TensorFlow from python coroutines.
    Change: 152701623
    
    * Show that QuantizeToFloat consistently introduces a small error. The
    error is equal to
      range_min - round(range_min / range_scale) * range_scale
    Change: 152702015
    
    * Internal Changes
    Change: 152703253
    
    * Remove tensorflow/tensorboard/plugins/debugger, as part of merge resolution.

commit 7ec0b6864d80f86d919bf025299225571a785852
Author: Ian Langmore <langmore@google.com>
Date:   Fri Apr 7 15:54:13 2017 -0800

    LinearOperator:  adjoint_arg kwarg added to all operators.  Now,
    operator.apply(x, adjoint_arg=True) means that the adjoint of 'x' is taken
    before application of operator.  Sometimes this is done more efficiently than
    simply taking adjoint.
    Change: 152560471

commit e05e5ed13e2e3270b61b89a1ba936f5bb1d7ecf2
Author: Jojy George Varghese <jojy.varghese@gmail.com>
Date:   Tue Mar 7 18:55:09 2017 -0800

    Use vector constructor to initialize Array3D. (#8144)
    
    * Use vector constructor to initialize Array3D.
    
    Current constructor of Array3D calls resize to initialize the inner vector of
    Array3D and follows up with a Fill call. This can be replaced with a simple
    call to vector constructor. Vector constructor might also be more efficient.
    
    * Change Array4D ctor implementation.
    
     Using vector ctor.

commit 778de47cdb257cecfac1888f88a653358e0fe021
Author: Jojy George Varghese <jojy.varghese@gmail.com>
Date:   Tue Mar 7 15:21:47 2017 -0800

    Use vector constructor to initialize Array2D. (#8115)
    
    Current constructor of Array2D calls resize to initialize the inner vector of
      Array2D and follows up with a Fill call. This can be replaced with a simple
      call to vector constructor. Vector constructor might also be more efficient.

commit 4891c01b1cadf085a915a3eac5dd1b8d8cdee203
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Feb 21 17:31:57 2017 -0800

    Allow (safe) in-place computation in TensorFlow C++ ops. When at least one input tensor has the same size and type as the output, and the underlying buffer is owned by the op, i.e. when its refcount is 1 at the time the op's Compute method executes, the computation can be performed in place and allocation of the output buffer avoided.
    
    I updated the following ops to perform in-place computation automatically when possible:
       * All standard coefficient-wise unary and binary operators (including with broadcasting) inheriting from base classes in kernels/cwise_ops_common.h.
       * unary and binary operators inheriting from base classes in framework/numeric_op.h. This is mostly old code for the Relu family and associated gradients.
       * All linear algebra ops inheriting from linalg_common.
       * Misc individual files/ops: softmax, select, bias, aggregate ops, batch_norm & fused_batch_norm, adjust_hue, constant, depthwise_conv_grad, fractional_avg_pool, misc. pooling ops, matrix_set_diag, xent & sparse_xent, unique_op.
    Change: 148166936

commit df5d3cd42335e31bccb6c796169d000d73c747d3
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Feb 15 15:03:07 2017 -0800

    Add ops for efficient WALS loss computation in factorization_ops.
    Add unit tests for loss computation.
    Improve performance of unit tests.
    Update trainer to add an option for loss computation (turned off by default).
    Change: 147649717

commit ff6c40e7fca121c869f6308b3a0a9fad7625d527
Author: Jeffrey A. Dean <jeff@google.com>
Date:   Thu Feb 2 08:54:46 2017 -0800

    Add GraphView internal helper class, which is initialized from the Graph
    but holds a more efficient and cache-friendly representation of the data
    structures needed during graph traversal.
    
    Also made faster path for main critical section for "normal" nodes not
    related to control flow.
    
    RELNOTES: Performance tuning of core graph execution module to be more
    cache friendly, and to have faster paths through critical sections.
    
    Co-author=sanjay
    Change: 146368628

commit 6ced72274b62be7f697d045eb2e7efa4f7f521a0
Author: Jeffrey A. Dean <jeff@google.com>
Date:   Thu Feb 2 08:54:46 2017 -0800

    Add GraphView internal helper class, which is initialized from the Graph
    but holds a more efficient and cache-friendly representation of the data
    structures needed during graph traversal.
    
    Also made faster path for main critical section for "normal" nodes not
    related to control flow.
    
    RELNOTES: Performance tuning of core graph execution module to be more
    cache friendly, and to have faster paths through critical sections.
    
    Co-author=sanjay
    Change: 146368628

commit 3699dfecc5942cab5f3c488442c07bccfd64261d
Author: Derek Murray <mrry@google.com>
Date:   Fri Jan 13 13:53:23 2017 -0800

    Provide multiple implementations of RPC responses on the fetch path.
    
    This CL includes wrapper classes for the protocol buffer messages
    `tensorflow::RunStepResponse` and `tensorflow::RunGraphResponse` (to
    complement the corresponding request message wrappers that were added recently).
    
    This change makes the backend code deal with abstract
    `tensorflow::MutableRunStepResponseWrapper` and
    `tensorflow::MutableRunGraphResponseWrapper` interfaces and adds three
    concrete implementations of each interface:
    
    * A mutable in-memory wrapper, which maintains the tensor data in
      `tensorflow::Tensor` objects, and provides the most efficient
      implementation when the client and master (or master and worker) or
      in the same address space.
    
    * A mutable, owned protobuf wrapper, which has a similar implementation
      to today's client code.
    
    * A mutable, non-owned protobuf wrapper, which has a similar
      implementation to today's server code (where the protobuf message is
      owned by the RPC subsystem).
    
    This is another improvement for issue #6256.
    Change: 144481118

commit bf00bcc5fc75d9bd1d61c67cc6c2fc55708a26ea
Author: Derek Murray <mrry@google.com>
Date:   Wed Jan 4 18:34:21 2017 -0800

    Provide multiple implementations of RPC requests on the feed path.
    
    This CL includes wrapper classes for the protocol buffer messages
    `tensorflow::RunStepRequest` and `tensorflow::RunGraphRequest`.
    
    Previously the service arguments were always protocol buffer messages,
    which can entail copying large tensor values into and out of the
    request message. This change makes the backend code deal with abstract
    `tensorflow::RunStepRequestWrapper` and
    `tensorflow::RunGraphRequestWrapper` interfaces and adds three
    concrete implementations of each interface:
    
    * An mutable in-memory wrapper, which maintains the tensor data in
      `tensorflow::Tensor` objects, and provides the most efficient
      implementation when the client and master are in the same address
      space.
    
    * A mutable protobuf wrapper, which has a similar implementation to
      today's client code.
    
    * A const wrapper around a const protobuf, which has a similar
      implementation to today's server code.
    
    This is another improvement for issue #6256.
    Change: 143620823

commit 70d4f7e40648e6f1aa942503bc746a4459ab4925
Author: Ian Langmore <langmore@google.com>
Date:   Wed Jan 4 12:31:23 2017 -0800

    LinearOperatorIdentity added to tensorflow/contrib/linalg/
    
    This operator is initialized with a num_rows and batch_shape parameter.  An alternative would be a single shape parameter.  The reasons for this are:
    
    1.  Compatibility with tf.eye and np.eye
    2.  If "shape" was used, and ndims was not known statically, then operator.apply(x) and operator.solve(x) need to force a broadcast by adding an array of zeros.  This is unnecessarily inefficient.  Having an explicit "batch_shape=None" option allows (in the event that batch_shape is None) operator.apply(x) and operator.solve(x) to simply return x.
    Change: 143582824

commit 8e83097d53c2095782736db55c0d174f1c1b51dd
Author: Derek Murray <mrry@google.com>
Date:   Thu Dec 22 17:34:54 2016 -0800

    Combine NamedTensorProto and NamedTensor into a single proto.
    
    Also use `Tensor::AsProtoTensorContent()` when populating the fetched
    values from a gRPC worker service, as this is more efficient for larger
    values. This should improve #6256 slightly.
    Change: 142813084

commit 694c52608f599992e80b3cd5a5161259c8f18831
Author: Ian Langmore <langmore@google.com>
Date:   Tue Nov 29 13:34:29 2016 -0800

    LinearOperator updates
    
    SquareLinearOperatorDerivedClassTest.  New base test class that reduces boilerplate in derived class tests for square operators.
    
    _tests_to_skip property.  Provides a way to skip tests.
    
    add_to_tensor() method added.  Some operators, like LinearOperatorDiag, can easily be added to a Tensor.
    
    Generic _to_dense() method now implemented in the base class.  This only relies on .apply.  This is somewhat efficient when .apply() is efficient.  This is useful for some cases, such as a Circulant operator where .apply() is fast, but forming the dense matrix would be cumbersome.
    Change: 140519839

commit f9c693b58d1e398783aaf44c8e6d0f1d6d763487
Author: Xingdong Zuo <zuoxingdong@users.noreply.github.com>
Date:   Sun Nov 27 02:04:28 2016 +0100

    [TF-Slim]The latest version has `write_version=saver_pb2.SaverDef.V2` as default set… (#5875)
    
    * The latest TF has `write_version=tf.train.SaverDef.V2` as default setting. And V2 is more efficient than V1.
    
    * Update evaluation.py
    
    * Update evaluation.py

commit b978323e37d1a3651294ba39c1273639e8dcffd6
Author: Benoit Steiner <benoit.steiner.goog@gmail.com>
Date:   Fri Nov 18 18:56:57 2016 -0800

    Added basic tests to cover doubles as well as coefficient wise operations with broadcasts

commit f803bd7c5338d522d262314bd1e0eb4021367c3d
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Nov 10 16:47:07 2016 -0800

    Add a new op split_v that can handle variable size splits.
    
    Aside from being useful on its own, this op also makes the implementation
    of the gradient of concat much more efficient.  Previously a new slice op was
    created in the graph for every input tensor to concat.  This op moves that
    logic inside of one op.  The overhead could be quite significant in cases
    with 100+ input Tensors to concat.
    Change: 138822942

commit a21ca0536674e40c762951004eade753f1e6fb88
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Nov 9 15:30:03 2016 -0800

    More efficient implementation of tf.einsum().
    
    The current implementation generates intermediate tensors whose size grows
    exponentially as a function of the sum of the ranks of the input tensors.  The
    new implementation reduces to batch matrix multiplication, which limits the
    size of intermediate tensors to the size of the intermediate products.  This
    also allows the function to benefit from GPU acceleration.
    
    Benchmarking:
    
    The following einsum() multiplies two 1000 x 1000 matrices:
    
      m = tf.random_normal((1000, 1000))
      x = tf.einsum('ij,jk->ik', m, m)
    
    Timing results on a Z440 workstation:
    
      Before: 7s, 4GB of ram
      After: 0.04s, 80MB of ram
    Change: 138693729

commit 80aec93166dadb2dc30250e1251ab3eb006c2d53
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Oct 27 08:10:54 2016 -0800

    Added new tensorflow::gtl::FlatMap and tensorflow::gtl::FlatSet classes.
    Mostly drop-in replacements for std::unordered_map and std::unordered_set,
    but much faster (does not do an allocation per entry, and represents
    entries in groups of 8 in a flat array, which is much more cache efficient).
    
    Benchmarks not included in this cl show about 3X to 5X performance
    improvements over the std::unordered_{set,map} for many kinds of
    common maps e.g. std::unordered_mapmap<int64, int64> or
    std::unordered_map<string, int64>.
    Change: 137401863

commit de7aaad2c29820ee8e4d9341834add5b32044f0a
Author: Yuan Yu <yuanbyu@google.com>
Date:   Tue Oct 25 20:55:26 2016 -0800

    Introduced per-loop PendingCount and Entry[]. This could significantly reduce the cost of iteration creation if the partition graph is large but the loop body is small, as explained in this old todo:
    
      // TODO(yuanbyu): We current use O(# of nodes in partition) space
      // even for nested iterations where only a small fraction of the
      // nodes are involved.  This is not efficient if the subgraph for
      // the frame is only a small subset of the partition. We should make
      // the vector size to be only the size of the frame subgraph.
    Change: 137238722

commit ffdd64b6aae6f2f70f126fcbfc82ce3bfa8ac79c
Author: Alexey Surkov <surkov@google.com>
Date:   Mon Oct 17 17:18:52 2016 -0800

    Implements DeleteRecursively for GcsFileSystem.
    
    GcsFileSystem uses a more efficient way to list all ojbects in a folder than the default FileSystem implementation.
    Change: 136423015

commit fdea17d8b449cbee9719ab4022a24e2d9918c25f
Author: Eugene Brevdo <ebrevdo@google.com>
Date:   Tue Oct 11 08:42:35 2016 -0800

    Store SparseTensors in a Map inside a container for Queue round-trip.
    
    This is much more efficient than serializing the underlying Tensors to strings
    and dserializing them on the other side.  Instead we pass through the keys
    to the SparseTensors inside the Map.
    
    Methods are kept private for use by queueing wrappers.
    
    Includes benchmarks that show wall-time is almost 50% of the wall-time of using the sparse serialization/deserialization wrappers:
    
    I1003 17:24:34.355306   18675 benchmark.py:77] Benchmark [BenchmarkSparseTensorsMapVsSerialization.benchmark_very_large_2d_float_st_tensor_maps] iters: 2000, wall_time: 0.00260997, cpu_time: -1,throughput: -1
    
    I1003 17:24:42.735983   18675 benchmark.py:77] Benchmark [BenchmarkSparseTensorsMapVsSerialization.benchmark_vey_large_2d_float_st_serialization] iters: 2000, wall_time: 0.00415492, cpu_time: -1,throughput: -1
    
    *** Update:
    
    After updates to sparse_tensor.h's concat code (pushed in a sister PR), there's a speedup in both benchmarks:
    
    I1004 09:39:30.630354   24400 benchmark.py:77] Benchmark [BenchmarkSparseTensorsMapVsSerialization.benchmark_very_large_2d_float_st_tensor_maps] iters: 2000, wall_time: 0.0022105
    
    I1004 09:39:38.125391   24400 benchmark.py:77] Benchmark [BenchmarkSparseTensorsMapVsSerialization.benchmark_very_large_2d_float_st_serialization] iters: 2000, wall_time: 0.00372696
    
    *** Update 2:
    
    After properly placed std::moves in the sparse_tensors_map code, that benchmark is now faster:
    
    Benchmark [BenchmarkSparseTensorsMapVsSerialization.benchmark_very_large_2d_float_st_tensor_maps] iters: 2000, wall_time: 0.00187492
    
    Total speedup is now: 0.00415492 / 0.00187492 = 2.2x
    Change: 135805924

commit 0907fbaf8eae931c4039beec407c4ec191323161
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Oct 10 17:14:21 2016 -0800

    Add initial version of MutableDenseHashTable that is implemented using
    tensors to store the key and value buckets.
    The implementation was inspired by the C++ dense_hash_map from
    https://github.com/sparsehash/sparsehash
    
    Compared to the existing MutableHashTable it can be more memory efficient
    when using small keys and values because it avoids the padding added by the
    memory allocator and does not need to store pointers in the buckets.
    For checkpointed tables it also avoids creating additional tensors during
    checkpoint and restore operations.
    
    Note that this is an initial implementation that is missing many features.
    They will be added shortly.
    
    Also update LookupInterface and existing implementations to pass down
    OpKernelContext, which is required for MutableDenseHashTable.
    Change: 135746705

commit ecdee38a534133ecd7ba18e58527cc4120277190
Author: Jianmin Chen <jmchen@google.com>
Date:   Fri Oct 7 12:53:06 2016 -0800

    Switch to the new accumulators in the sync_rep optimizer (currently called V2). Please note that the gradients from replicas are now averaged instead of summed (as in the old sync_replicas_optimizer) so you need to increase the learning rate according to the number of replicas. This change is introduced to be consistent with how gradients are aggregated (averaged) within a batch in a replica.
    
    As shown in the code change, the switch results in:
    1. much cleaner and simpler code.
    2. much more efficient and reliable staleness check. It is now 100% strict with
    no extra contention to PS servers.
    3. no need for clean_up op so we can get rid of the abort_op which can confuse users.
    4. number of replicas can be changed without complaints from checkpoint as the
    local_step is now just a local variable instead of a global vector variable.
    
    This has been tried with manual restarts of workers (chief or non chief) and
    ps and seems to be quite robust.
    Change: 135513399

commit 52bd6c4297fe684ffbafa93daa92a3802eceffb5
Author: Alexey Surkov <surkov@google.com>
Date:   Mon Sep 26 14:30:51 2016 -0800

    More efficient implementation of GetMatchingPaths for GCS.
    Change: 134335319

commit 8c784c51555db944fbe8c6cff702f7201a5a6463
Author: Alexey Surkov <surkov@google.com>
Date:   Mon Sep 26 14:30:51 2016 -0800

    More efficient implementation of GetMatchingPaths for GCS.
    Change: 134335319

commit b517f16a02965712d8902c5da699898c577a84f9
Author: Zongheng Yang <zongheng@google.com>
Date:   Thu Sep 22 17:48:42 2016 -0800

    Tensor bundle: a module to efficiently serialize/deserialize tensors.
    
    This module will serve as the backing store of TensorFlow's V2 checkpoint
    format.
    
    Highlights of the benefits:
    
    * Peak memory usage of both write and read paths are just 1x (plus a small
      constant-sized buffer).
    * Stores tensors in a non-proto format, circumventing the size limit on proto
      messages.
    * Flexibility: potentially allows by-row loading of a large tensor, or mmap.
    Change: 134028119

commit db15be82ce8c9e9e83168da80543e5a4ad1e0918
Author: Benoit Steiner <bsteiner@google.com>
Date:   Fri Aug 5 14:05:26 2016 -0800

    Encode the size of the input tensors in the placeholders. This helps generate
    a more efficient translation model
    Change: 129487167

commit 6e6d0dcde7c59f306c6f276ed153128fe8bdd8bf
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Jul 19 12:58:51 2016 -0800

    Rewrite to make SDCA optimizer distributed.
    
    Changes are:
    * Modifies the update equation to include the aspect of distribution, supports logistic loss, other loss functions in later CL.
    * Speeds up BM_SDCA_LARGE_SPARSE by 20x-34x.
    * Refactors the interface for the following:
       - Removes the need of the sparse-tensor wrappers
       - Makes the code efficient for dense features.
       - Removes the need of sparse_merge
       - Allows sparse features with weights, or without weights.
    Change: 127870447

commit 873889f856581167bc286cbb6e8ae7b94a506f08
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jul 11 10:02:48 2016 -0800

    Replace stratified_sample implementation to a strictly more efficient implementaiton. The new implementation discards fewer data, and scales better based on the number of classes. However, it requires knowing the class distribution of the data.
    Change: 127104811

commit 379df09118ddfdbad19375d6d853254312ccf1ae
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jun 30 14:00:39 2016 -0800

    Fix initialization issues with Variables whose shape contains a zero.
    
    Fixes #2099.
    
    Tries to give Variables the same behavior as non-Variable tensors in
    this respect. Useful for not having to special case e.g. coefficients
    of a feature vector which may sometimes not have any features.
    Change: 126347791

commit 8bf25a491b60d223bba11233de9e62f4b0db17e8
Author: Alexey Surkov <surkov@google.com>
Date:   Thu Jun 23 09:29:53 2016 -0800

    Add a read-ahead cache to the GCS implementation of RandomAccessFile.
    
    In some cases TensorFlow reads the data via RandomAccessFile in really small
    chunks, which doesn't work very efficiently with HTTP requests. Adding a
    read-ahead cache significantly boosts the performance.
    Change: 125691397

commit 13b2a36828269725ea18a86488de4e803c2d0d97
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Wed May 4 11:35:38 2016 -0800

    Make tf.pack use Const op when input is a constant list (or ndarray).
    This facilitates shape induction when shape is produced via tf.pack() and is
    generally more efficient.
    Change: 121508615

commit a4b475cb320a69fd787803095aec1c514375a136
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Mon May 2 20:51:19 2016 -0800

    Fix dynamic_rnn documentation for time_major.
    
    From reading the code, it looks like time_major = True is more efficient.
    Change: 121342997

commit 098f930de4ef044021f3ef1d3cdd6848c23eddb0
Author: Yuan Yu <yuanbyu@google.com>
Date:   Sun Apr 10 08:46:36 2016 -0800

    This is another step to make TensorFlow more interactive and flexible to users. It allows a tensor produced by a run call to stay "in-place" so that a future run call can use it in-place. To achieve this, a run call can now return a handle of a tensor to the client, which can then be fed to a subsequent run call. This feature is complimentary to partial run, though there are some overlaps.
    
    Here are a few properties of the current implementation:
    
    1. Tensors are stored in the state of a session. The tensors are garbage collected if the client doesn't have a reference to the tensor or the session is closed.
    
    2. There is no change to the current session API. We introduced two ops to manage the conversions between tensors and its handles. (There is a third op to garbage collect a tensor.) See the example below.
    
    3. It fits quite well into the current feed-fetch design/implementation. It tries to reuse the graph (and caches) as much as possible so to make things efficient.
    
    Below is a simple example. More examples can be found in sessopn_ops_test.py.
    
    # Return a handle.
    a = tf.constant(10)
    b = tf.constant(5)
    c = tf.mul(a, b)
    h = tf.get_session_handle(c).eval()
    
    # Feed a tensor handle.
    f, x = tf.get_session_tensor(dtypes.int32)
    y = tf.mul(x, 10)
    result = sess.run(y, feed_dict={f: h.handle})
    # result == 500
    Change: 119481352

commit 264bac93b1c8cc367d7519b13a6e1d11177c0227
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Fri Apr 8 16:03:23 2016 -0800

    Use new adjoint attribute for solvers to make gradients more efficient.
    Consolidate linalg shape inference functions.
    Change: 119423897

commit 2d691fe77da04492146b65f6d700bdf843902e4a
Author: Eugene Brevdo <ebrevdo@gmail.com>
Date:   Fri Apr 8 12:34:56 2016 -0800

    Re-enable write-once, read-many semantics for TensorArray.
    
    This implementation is a bit more efficient than the previous one because
    the first write just performs a shallow copy.  Only on an aggregation is
    any new memory allocated.
    
    For read-many semantics, the operations read, pack, and concat must be called
    with parameter  clear_after_read=False.  By default, the flag is set True; this
    means a read will remove the reference to the underlying Tensor in
    the TensorArray to reclaim memory in the runtime.
    Change: 119404140

commit 769aa524c4bdc99c61df468257c95c2f7daeb16e
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Wed Mar 16 13:18:49 2016 -0800

    Because TensorFlow knows the entire graph of your computations, it
    can automatically use the [backpropagation
    algorithm](http://colah.github.io/posts/2015-08-Backprop/)
    to efficiently determine how your variables affect the cost you ask it to
    minimize.
    Change: 117382393

commit 9a8c5ad18c61cb0695d31e2ce969008c82999c7c
Author: Derek Murray <mrry@google.com>
Date:   Tue Mar 15 11:02:22 2016 -0800

    Prevent the feeding of tensors whose values are used to calculate shapes.
    
    This change prevents feeding a tensor if its constant value has been
    accessed. For example, the constant value is often used in shape
    functions (e.g. in `tf.reshape(data, indices)`, `indices` is a tensor,
    but it is often constant) in order to infer more precise shapes. It is
    also used in the `tf.image.*` to generate simpler, more efficient
    graphs. However, doing so is potentially unsafe, because the tensor
    can be fed with a different value, which invalidates the previously
    obtained constant value, and can lead to subtle bugs.
    
    IF THIS BREAKS YOU
    ------------------
    
    Replace the tensor that you are feeding with a `tf.placeholder()` of
    the appropriate dtype and shape.
    Change: 117263031

commit febfec7256026a38bda30c78c2768b32e64c9a2c
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Tue Mar 8 11:08:47 2016 -0800

    Partially revert a change to zeros_like which broke the Mandelbrot example
    
    An earlier change made zeros_like inefficient if an output dtype different than
    the input was desired: it first made zeros of the input dtype and then cast.
    In addition to not being efficient, this broke the Mandelbrot example, which
    used zeros_like on a complex tensor with float output.  Cast is not allowed from
    complex to float, so this failed.
    
    The new code used tf.zeros and tf.shape if the dtypes differ.
    
    Fixes #1427.
    Change: 116675900

commit 5f7683ea100c06bba66536fd97b5c141f576e0d7
Author: Jianmin Chen <goog.jmchen@gmail.com>
Date:   Fri Mar 4 11:38:02 2016 -0800

    Add native depthwise_convolution op (backward pass) with GPU kernels. Now the
    depthwise convolution op is completed for GPU runs. There are still space for
    more optimization which will be done in the future CLs.
    
    Note that the current CPU kernels with this CL are just reference kernels and
    not optimized at all.
    
    The old depthwise_conv is very inefficient by calling slice() on each
    input channel on input and filters, followed by a conv() on each input channel,
    after which is a concat().
    Change: 116383911

commit 0c69be4e12fe5355cfdba931780a83d666e7abea
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Mon Feb 29 17:31:08 2016 -0800

    Lazily initialize the static coeffcients table once, on first use,
    rather than doing it every time ResizeBicubicOp<...>::Compute is
    invoked.
    
    Also refactored the way this is handled so that there is at most
    one coefficients table in the process, rather than one per TensorFlow
    numeric type.
    
    Saves about 60K bytes / binary.
    Change: 115927183

commit b51ef0cd06e1bfb529b272e55010790ff3ead31f
Author: Jianmin Chen <goog.jmchen@gmail.com>
Date:   Thu Feb 25 16:27:58 2016 -0800

    Rollback of: Add native depthwise_convolution op (forward pass).
    
    The current depthwise_conv is very inefficient by calling slice() on each
    input channel on input and filters, followed by a conv() on each input channel,
    after which is a concat().
    Change: 115617901

commit 90cf3e2eeaddd480cec8a587b8b20b3b562427ef
Author: Vijay Vasudevan <vrv@google.com>
Date:   Thu Feb 25 14:04:25 2016 -0800

    Rollback of: Add native depthwise_convolution op (forward pass).
    
    The current depthwise_conv is very inefficient by calling slice() on each
    input channel on input and filters, followed by a conv() on each input channel,
    after which is a concat().
    Change: 115601904

commit d1245c3c87160760c0fb66f19ddbd7fa48989e81
Merge: d16868d4bd4 590b8c6c398
Author: Illia Polosukhin <ilblackdragon@gmail.com>
Date:   Thu Feb 25 13:14:21 2016 -0800

    Merge pull request #115 from elqursh/optimize-predict
    
    Make estimator.predict memory efficient for large n_classes

commit 590b8c6c3986f0e494657d85848e5ae0d59d550b
Author: Ali Elqursh <elqursh@google.com>
Date:   Thu Feb 25 15:22:20 2016 -0500

    Make estimator.predict more memory efficient
    
    For multi-class classification estimator.predict currently
    appends all the predictions and then argmax the resulting
    tensor. For a large number of classes this tensor is huge
    and may not fit in memory.
    
    This CL changes the behavior to argmax before appending
    the results for the batch.

commit 7b47c8b4a362556bdbd604c81f804d76893737e4
Author: Jianmin Chen <goog.jmchen@gmail.com>
Date:   Thu Feb 25 11:19:05 2016 -0800

    Add native depthwise_convolution op (forward pass).
    
    The current depthwise_conv is very inefficient by calling slice() on each
    input channel on input and filters, followed by a conv() on each input channel,
    after which is a concat().
    Change: 115583330

commit 18cbcdfaabf58588675cf9c29e2b9ec84602422e
Author: Lukasz Kaiser <lukaszkaiser@gmail.com>
Date:   Wed Feb 10 15:39:46 2016 -0800

    Add an optional argument to model_with_buckets to get per-example loss and
    correct the use of conditionals in seq2seq functions to make them efficient.
    Change: 114377454

commit fea55e1e05ffbdaa4ae4369d1c35e689a7dc48a2
Author: Eugene Brevdo <ebrevdo@gmail.com>
Date:   Wed Jan 27 14:54:54 2016 -0800

    Breaking change in TF RNN python api: Return the final state instead of the
    list of states when calling tf.nn.rnn() and tf.nn.state_saving_rnn()
    
    This is necessary for further cleanup of RNN state propagation code
    (currently dynamic RNN calculations when passing sequence_length do not return
    the proper final state, this is a necessary fix to make that fix efficient).
    Change: 113203893

commit 72bf16f937c827050ee71ea4cfa7a25e44303246
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Fri Jan 8 07:26:00 2016 -0800

    Added support for unsorted top-k output, which makes it much more efficient.
    
    This is especially true if k=1 or k is large.
    Change: 111680805

commit 827163e960e8cb86d3dc3f70434c22713ac9f41c
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Thu Jan 7 18:38:32 2016 -0800

    Change to Relu gradient computation, to allow it to use the output of the Relu instead of its input. The reason is memory consumption: usually the Relu is followed by a Conv layer, which will keep its inputs until the backward pass. The Relu, which produces these inputs, can use them for its own backprop, and doing so will be more memory efficient than having Relu keep its inputs around.
    Change: 111649040
commit cf6a88aa42a9490892be6c5e040b7b8cdf3e3ba8
Author: Michael Gester <mgester@google.com>
Date:   Wed Oct 6 10:51:44 2021 -0700

    Rewrite side effect analysis for TF dialect
    
    Some advantages of the new code:
    - support op-based side effects efficiently which saves control dependencies and
      results in better performance; previously they were treated like unknown side
      effects (see new tests which failed before)
    - support value-based side effects for non-resource operands/results
      efficiently; those are not supported by resource alias analysis and are now
      treated like op-based side effects; previously they were treated like unknown
      side effects (see new tests which failed before)
    - simplified/removed many special cases, unified behavior for value-based and
      op-based side effects
    - improved code efficiency and readability
    - added function for querying all resource IDs that an op potentially accesses
    
    PiperOrigin-RevId: 401286244
    Change-Id: I33e782dfd83a1ab7f7876e2e96b90b2b738cd819

commit d36e9732e6ee5a73b8621e2a393b6e54228cc1f6
Author: Edward Loper <edloper@google.com>
Date:   Tue Sep 14 08:31:36 2021 -0700

    Improve efficiency of dispatch v2: update InstanceChecker to support checking multiple base classes.  This helps with cases like `tf.types.experimental.TensorLike`, which is a union containing 11 different types.
    
    PiperOrigin-RevId: 396601669
    Change-Id: I361c65e5ce5076cee840010f51004b8eb2f9794c

commit 0f755ec44ec56855d77e025bac8e02a7b5099181
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Sep 13 10:28:14 2021 -0700

    Improve efficiency in some code in c_api where we are calling `vector::push_back` in a loop without calling `vector::reserve` before the loop. Added those `reserve` calls.
    
    PiperOrigin-RevId: 396387348
    Change-Id: Idc10c8758969cdacbd6c4dcf365576434a326c1a

commit eca90a0f89f8a8fe3835a84942b03899deb358b9
Author: Mehdi Amini <aminim@google.com>
Date:   Thu Sep 9 10:57:41 2021 -0700

    Disable MLIR multi-threading in MlirXlaOpKernel
    
    Since this kernel is implementing lowering for a single TF operation, we
    disable MLIR threading for efficiency purpose (avoid starting a large number
    of threads eagerly).
    
    This also caches the MLIRContext in the kernel so that repeated invocation won't lead to creating/destroying an MLIRContext.
    
    PiperOrigin-RevId: 395740833
    Change-Id: I4d98591ccb7640808d1aaae2101031796168b67c

commit bf16d44a6cb089d3d8aa86746130f54c9308dcc2
Author: CJ Carey <cjcarey@google.com>
Date:   Wed Aug 25 15:34:44 2021 -0700

    Improve the efficiency of AppendFeatureValues when passing a container that supports a `size()` method.
    
    Instead of reusing the iterator-based overload when a container is passed, we now attempt to explicitly Reserve() the necessary space before copying/moving elements.
    
    This will save on allocations and total RAM usage, as the new feature's repeated field capacity is no longer grown dynamically.
    
    PiperOrigin-RevId: 392994752
    Change-Id: Icf3918716e2989d9980bdda5b233780bb2f97900

commit 1a67d56238ff7791a1534b749fb2b0c136b0627d
Author: Edward Loper <edloper@google.com>
Date:   Mon Aug 23 14:19:40 2021 -0700

    Add Python variable to keep track of what dispatcher signatures have been registered, for documentation & error-checking purposes.  (This variable is not used by the actual dispatch system, which is coded in c++ for efficiency.)
    
    PiperOrigin-RevId: 392517389
    Change-Id: Iea43273de1ac494eae1bc220cc305c0781d6006d

commit 054b867b895fc441e816ede4e7245b60b7742f43
Author: Tatiana Shpeisman <shpeisman@google.com>
Date:   Fri May 7 09:27:27 2021 -0700

    Improve efficiency of op name comparison in ClusterOpsByPolicy pass.
    
    For union-find policy, represents a set of op names as a set of identifiers instead of a set of strings. For use-def policy, hoists out string to identifier conversion to be done once per function instead of on every op name comparison. Unlike strings, identifier comparison takes constant time.
    
    PiperOrigin-RevId: 372570592
    Change-Id: Iebcb8f4b3e81c23d8bc89fd5a0a8daa6cf132795

commit 311c53372c29ab23f6ca0a3bc63f40154278caf4
Author: Haoliang Zhang <haoliang@google.com>
Date:   Thu Apr 29 14:03:24 2021 -0700

    Improve the efficiency of registering FunctionDef in the flex delegate:
    Previously we add a FunctionDef for each subgraph in the tflite model, this isn't efficient since there are subgraphs that are not intended to be invoked as functions. After the change, we will collect subgraphs used by a list of ops (MapDataset, ReduceDataset) and only register functions for those subgraphs.
    
    PiperOrigin-RevId: 371199293
    Change-Id: I3a8ca3841d018b9a57e339fd8becf0d03863b974

commit 706350f02372cbed8ee9dae04aabbc4a5da84760
Author: Andrew Audibert <aaudibert@google.com>
Date:   Wed Jan 13 11:15:20 2021 -0800

    [tf.data service] Implement round-robin reads.
    
    This enables a new mode of reading from the tf.data service, where consumers read from tasks in a coordinated fashion, instead of the normal first-come first-served.
    
    The main use case for this is coordinated bucketization for synchronous training, where we want to ensure that at each step consumers get batches with elements of similar sizes. This mitigates the inefficiency of some consumers slowly training on large examples while others quickly train on small examples, then block waiting for the slower examples to be processed.
    
    When `consumer_index` and `num_consumers` are specified to `distribute`, each task will enforce a strict round-robin order, where its first element goes to consumer 0, second element to consumer 1, and so on. This requires that all consumers consume the same number of elements.
    
    PiperOrigin-RevId: 351625063
    Change-Id: I9b400f55ad61406cb125af8225096e7ff5dc4b0c

commit 894eaa01b5028432b3e7cf24ad778bfb1b53eea0
Author: Jing Pu <jingpu@google.com>
Date:   Wed Dec 2 17:42:44 2020 -0800

    Optimize `Mul::fold` efficiency with specialized implementations for f32 and bf16.
    
    Other changes includes:
    
    - Remove `ConstFoldBinaryOpScalarScalar` function since it is unused because all TFL ops operates on tensor types so there shouldn't be any scalar Attribute to be handled by the folder.
    
    - Remove `is_commutative` parameters in some functions that are not used eventually.
    
    PiperOrigin-RevId: 345349413
    Change-Id: I94c4095caddb41316aea0db4cd939b9f867be2e9

commit befea92a3d74a010791eb845267f03c54315d660
Author: Jing Pu <jingpu@google.com>
Date:   Fri Nov 13 18:19:46 2020 -0800

    Call "Reserve" method in `ConvertXXXElementsAttr` functions which slightly improve the efficiency.
    
    PiperOrigin-RevId: 342374519
    Change-Id: I7b146e15145efbb43ff1d9ba4a0aed01c18b75cb

commit 9bf801ba1f26e4a7091695a7f5b512b0ed19e99b
Author: qqq.jq <895521320@qq.com>
Date:   Tue Nov 3 10:37:29 2020 +0800

    Remove the race check due to poor branching efficiency

commit 153947b5c51bc2b936eebda609bff77c19599211
Author: Prakalp Srivastava <prakalps@google.com>
Date:   Wed Jul 1 10:49:32 2020 -0700

    Only insert TPUCopyWithLayout when resource generator is on CPU.
    
    The placement of iterator is not determined by the device attribute of tf.IteratorGetNext but by the device attribute of the alias resource generator op. The generator ops are either function arguments or tf.VarHandle ops. So, we modify the TPU dynamic layout pass to check device attribute of generator ops.
    
    This CL modifies the Resource Alias Analysis to return the set of aliases of a given value. For efficiency, it now keeps a map of both resource value --> unique resource ID and vice-versa.
    
    This improves the performance of few models running with MLIR TF/XLA bridge. For example, Resnet50 step time is reduced from 180 ms to 125 ms (on par with the old bridge).
    
    PiperOrigin-RevId: 319255334
    Change-Id: I4df9f26f480b580b8277caae981f06c3189e7bf4

commit fc2d7fdacb35001e9b98ff8b844679985bbf61a4
Author: Derek Murray <mrry@google.com>
Date:   Fri Apr 3 16:57:16 2020 -0700

    [Executor] Reorganize code in `ExecutorState::NodeDone()` for efficiency.
    
    Executor microbenchmarks show a 3.22% to 4.16% improvement with this change, which avoids re-checking the status multiple times in the non-error case.
    
    PiperOrigin-RevId: 304719934
    Change-Id: I6a9e3d1db8b13f32eb558a57fcb272c07ba1079a

commit f120f7d514d50428bc34b4435ea8253f5cece990
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Feb 20 14:59:42 2020 -0800

    Suppress 'conversion to a dense matrix' warning from LinearOperatorFullMatrix.solve().
    
    The current warning is inappropriate: since a LinearOperatorFullMatrix is inherently dense, no efficiency is lost when we treat it as dense.
    
    PiperOrigin-RevId: 296305093
    Change-Id: Id3b7e2a00f05d1e516374c4241cd84529844a056

commit 942f618880c3616caf19882cbeb3445b2ea80f6a
Author: Shanqing Cai <cais@google.com>
Date:   Tue Dec 24 20:45:55 2019 -0800

    [tfdbg] Log device info for eager executions in DebugEvent file set
    
    - For space efficiency, devices are stored as IDs, instead of string names.
    - The DebuggedGraph proto and data object enables looking up device names from the said IDs.
    
    PiperOrigin-RevId: 287067889
    Change-Id: I027dff0367244ce427438377afd90df43bdf8e7a

commit 9c52e7ce02532c22a79ae7139f37c663add4c90f
Author: Adrian Kuegel <akuegel@google.com>
Date:   Tue Oct 29 03:53:32 2019 -0700

    Make it clear that optional common attributes are not ignored in HloParser.
    
    Also fix the case when an attribute appears both as a non-proto attribute and
    as a proto attribute. Here we prefer parsing the proto attribute.
    Also use flat_hash_set and flat_hash_map for efficiency, and replace one usage
    of map with vector.
    
    PiperOrigin-RevId: 277249631
    Change-Id: I41396e5a98dca13be6a5a7681bcfd03f775fb576

commit d969c96e5c77f99fd2c94aed277d729056c093e3
Author: Edward Loper <edloper@google.com>
Date:   Thu Oct 3 05:24:37 2019 -0700

    Extend tf.io.parse_sequence_example and tf.io.parse_single_sequence_example to handle ragged tensor features.
    
    tf.io.parse_single_sequence_example also now uses the fast-parsing code path that was written for parse_sequence_example, which should improve efficiency for large inputs.
    
    PiperOrigin-RevId: 272639850

commit b73b36714d316b3dc79db6b6b6dae206d8dcf05f
Author: Sanjoy Das <sanjoy@google.com>
Date:   Tue Apr 16 13:50:07 2019 -0700

    Refactor to make MarkForCompilationPass more hackable:
    
    1. Put more information in the Cluster class.  E.g. things like
       effective_cluster_size and has_functional_control_flow logically belong to
       Cluster instances.
    
    2. Use pointers to Cluster instead of Cluster values in the UnionFind data
       structure.  Besides being a minor efficiency fix, this fixes a gotcha that we
       used to have:
    
         UnionFind<Cluster>* cluster_a = ...;
         UnionFind<Cluster>* cluster_b = ...;
         Cluster* cluster_instance_a = &cluster_a->Get();
         // ...
         cluster_a->Merge(cluster_b);
    
         // We now have to remember to do this if we want to continue using
         // cluster_instance_a.
         cluster_instance_a = &cluster_a->Get();
    
       In general UnionFind<T> is easier to use if we can use T as a value type.
    
    3. Remove isolated_nodes_.  Putting nodes in isolated_nodes_ is equivalent to
    not putting them in compilation_candidates_.
    
    4. Map nodes that are not candidates to nullptr Cluster* instances to make bugs
    in this area more obvious.
    
    I did not investigate the change to the test case in depth because the new
    clustering produced after this CL is also correct (so the change is probably
    caused by a difference in iteration order or something like that).
    
    PiperOrigin-RevId: 243872193

commit d1cdcae41be613830f5b681a4e041648cf2f02c6
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Wed Jan 30 10:43:27 2019 -0800

    3000x speed improvement on compose-affine-maps by dropping NestedMatcher for
    a trivial inst walker :-) (reduces pass time from several minutes non-terminating to 120ms) - (fixes b/123541184)
    
    - use a simple 7-line inst walker to collect affine_apply op's instead of the nested
      matcher; -compose-affine-maps pass runs in 120ms now instead of 5 minutes + (non-
      terminating / out of memory) - on a realistic test case that is 20,000 lines 12-d
      loop nest
    
    - this CL is also pushing for simple existing/standard patterns unless there
      is a real efficiency issue (OTOH, fixing nested matcher to address this issue requires
      cl/231400521)
    
    - the improvement is from swapping out the nested walker as opposed to from a bug
      or anything else that this CL changes
    
    - update stale comment
    
    PiperOrigin-RevId: 231623619

commit c87da114fbdfd59a1b965b53f2044020a6621154
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Sat Dec 29 15:51:30 2018 -0800

    Fix b/122139732; update FlatAffineConstraints::isEmpty() to eliminate IDs in a
    better order.
    
    - update isEmpty() to eliminate IDs in a better order. Speed improvement for
      complex cases (for eg. high-d reshape's involving mod's/div's).
    - minor efficiency update to projectOut (was earlier making an extra albeit
      benign call to gaussianEliminateIds) (NFC).
    - move getBestIdToEliminate further up in the file (NFC).
    - add the failing test case.
    - add debug info to checkMemRefAccessDependence.
    
    PiperOrigin-RevId: 227244634

commit 2dcb0a07c88ce34196d8fe55ab8f415e537e1484
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Feb 6 10:56:19 2019 -0800

    New Timestamped BFCAllocator and GPUKernelTracker.
    
    The first part of this change extends BFCAllocator with an optional
    timing counter for recording the time at which each Chunk is freed.
    This has no effect for conventional memory management (as
    applied to CPU RAM), but can achieve a new behavior when applied
    to GPU RAM management.  The default TensorFlow memory allocation
    convention for GPU RAM is to Unref the tensors Ref'd by a GPU Op as
    soon as the Op has queued its kernel (and before that kernel is known
    to have completed execution).  This is safe if the memory is
    subsequently allocated to another GPU Op (the usual case) because that
    second Op will be sequential on the single GPU compute stream and
    hence won't touch the memory until the prior kernel has completed.
    But this practice is unsafe if the memory is used for I/O or for an Op
    queued on a different compute stream unless some further
    synchronization is inserted.
    
    Currently, I/O between a GPU and another device is made safe by
    inserting stream dependencies.  Multi-compute-stream computation is
    made safe by delaying the Unref of Ref'd tensors until the kernel is
    known to have completed, via callback through the GPU-specific
    EventMgr.  RDMA networking using GPUDirect is another difficult case
    where stream synchronization is not possible and it is necessary to
    wait until kernels are known to have completed before allowing
    reallocation of the used memory.
    
    Simply delaying the deallocation of memory until kernels are known to
    have completed is unsatisfactory because it substantially raises the
    high-water memory requirements of a program, drastically affecting the
    model architectures that are feasible on a particular GPU model.  The
    new freed-at count on BFCAllocator::Chunk is part of a strategy
    for maintaining the high-water size efficiency of our current
    single-compute-stream GPU memory allocation strategy while reducing
    synchronization stalls in I/O uses of GPU RAM.  In the future it
    may also be applied to multi-compute-stream execution.
    
    The key idea is that when a request to allocate GPU memory is made we
    can also pass along a 'freed-by' count and the allocator is free
    to return any Chunk whose freed_count is <= that threshold.
    This way we can continue to early-allocate GPU RAM without
    restrictions to GPU kernels to be executed on a single compute stream,
    while simultaneously satisfying the correctness constraints
    needed for off-stream use.
    
    GPUKernelTracker is the other component needed to make this new
    strategy work.  It keeps track of the stream queuing and real
    completion times of GPU kernels thus making it possible to pick the
    largest safe freed-by count when making a request for GPU memory
    that must be unemcumbered by other uses immediately.  A secondary
    capability of the GPUKernelTracker is that it enables capping the
    number of GPU kernels queued on a stream.  Without this cap some TF
    models can experience moments when hundreds of kernels are queued on
    the single compute stream.  Those queued but-not-executing kernels can
    tie up memory that could be used for other purposes before its really
    needed, and can delay I/O operations which are queued later and need
    to wait for the compute stream to clear, for safety.
    
    The new timestamped memory allocation strategy and pending-kernel
    capping are considered experimental features and default off for
    now, until more experience is gained.
    
    PiperOrigin-RevId: 232705088

commit 0f39e8a552018eba3bd2916c0a72467617bebf88
Author: Haoyu Zhang <haoyuzhang@google.com>
Date:   Thu Jan 17 10:41:18 2019 -0800

    Reuse existing dataset iterators in Keras for better memory efficiency.
    
    * In Keras model iteration, create only one iterator for training dataset and
      one iterator for validation datasets.
    * If training requires dataset to be reset at each epoch, reinitialize the
      training iterator;
    * If we run multiple validation passes between training epochs, reinitialize the validation
      iterator.
    
    Compared to recreating iterators, this approach reduces host memory usage and
    prevents memory leak.
    
    PiperOrigin-RevId: 229776545

commit f348ee8a0931c5048a3ed4f8d16b2f47a7466d39
Author: Eddie Zhou <eddz@google.com>
Date:   Fri Oct 26 13:42:24 2018 -0700

    Group the warm-starting of no-vocab variables into one init_from_checkpoint call for efficiency.
    
    PiperOrigin-RevId: 218906890

commit 9b44e8bd7b116503f9f1fe605d8ff43ef6ee132e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Aug 13 03:50:52 2018 -0700

    Fix 2 bugs in the logic of the ODE, impacting efficiency:
    1) if either of the side is always zero, you never want to do the multiplication
    2) because of the zero at the end, the if clause was never hit, not saving those flops.
    
    PiperOrigin-RevId: 208457125

commit 23f826271a5956982df17980bca3ac7513ec4ee4
Author: Cao Zongyan <zongyan.cao@alibaba-inc.com>
Date:   Thu Jul 26 11:27:40 2018 +0800

    A faster BatchSelectFunctor for tf.where on CPU.
    
    Op 'tf.where(c, t, e)' supports that 't' and 'e' are N-D tensors
    while 'c' is a 1D tensor, which would call BatchSelectFunctor to
    get the result. But its basic implementation broadcasts 'c' to the
    same dimension with 't' and 'e', which would get bad efficiency on
    CPU for large tensors. Here a loop-based implementation would be
    adopted to make this operation faster on CPU.

commit 0b522fd22b986704d1056254961cc7988ae182eb
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri May 25 12:54:49 2018 -0700

    Add ScopedAllocatorOptimizer in support of CollectiveReduce.
    
    The efficiency of CollectiveReduce is greatly improved by merging
    multiple parallel reductions over smaller tensors into a single
    reduction over a larger tensor that is the concatentation of the
    smaller tensors.  Because CollectiveReduce is essentially an
    element-wise array operation which operates on a 1-D reshape of
    the input tensor it is eligible for a ScopedAllocation optimization.
    
    The optimization works by looking for serially independent instances
    of CollectiveReduce that lie within the same name-scope tier and
    have the same control-flow (e.g. loop) embedding structure.  Where
    two or more such nodes are found the upstream nodes that generate
    their inputs are modified to write their outputs into consecutive
    regions of a single tensor buffer maintained by a ScopedAllocator.
    The multiple CollectiveReduce nodes are then replaced by a single
    CollectiveReduce that operates in-place on the backing buffer.
    
    The effectiveness of the optimization depends on there being candidate
    CollectiveReduce nodes with these characteristics that become eligible
    for execution at close to the same time.  If the name scope is too
    large, and includes nodes that become execution eligible at very different
    times, this graph rewrite could result in a slowdown.
    
    Note that this optimization is experimental: it is not guaranteed to
    work, especially for ops other than CollectiveReduce.
    
    PiperOrigin-RevId: 198089642

commit d9df4313a98fdc62187a94c5ab6d8955b699e9f2
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Feb 6 12:02:18 2018 -0800

    Improve side_effect_guards to (1) avoid aliasing non-tensors and (2) combine aliasing with re-indenting. Move the renaming visitor into a generic utility API.
    This loses potential efficiency by risking sequencing ops where there is no risk of a race. On the other hand it's still not entirely robust, and we need to raise an error where we can't guarantee that.
    
    PiperOrigin-RevId: 184717456

commit 4e1a7a74b61aa02bc9c3104706afb2153faefddf
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Dec 12 11:18:28 2017 -0800

    Add CompositeNodeManager for Grappler VirtualScheduler.
    
    CompositeNodeManager has per-device LIFO manager, FirstReadyManagers for _Send
    and _Recv ops, and chooses FirstReady among the ops from per-device LIFOManager
    and _Send and _Recv FirstReadyManagers.
    
    This one can maximizes producer-consumer locality within a device (with LIFO),
    but does not introduce previously reported scheduling inefficiency w.r.t.
    multi-device execution with separately managing _Send and _Recv ops and global
    FirstReady policy across devices.
    
    It's implemented, but not enabled; VirtualScheduler still uses
    FirstReadyManager.
    
    PiperOrigin-RevId: 178787352

commit 0ba2a1f6db399cbb5be3e71acdad1123af29348a
Author: Jeffrey A. Dean <jeff@google.com>
Date:   Fri Aug 4 14:55:48 2017 -0700

    Various compiler speedups.  Improves compilation of an image model from
    35.6 seconds to 33.3 seconds (average of three runs) (+6.5% improvement).
    
    (1) Avoid extra hash table lookups in HeapSimulator by holding onto the pointer
    to the hash table value, rather than looking it up from the same key multiple
    times.
    
    (2) In HeapSimulator, reuse operand_buffers_to_free and dead_buffers_to_free
    across all instructions, rather than allocating new vectors on every
    instructions.
    
    (3) Avoid use of Printf and improve efficiency of string generation for
    HloInstruction::ToString and ShapeUtil::HumanStringWithLayout.
    PiperOrigin-RevId: 164314222

commit 9fb91045a4186bdae15fc84272da1af11b3eea3c
Author: nolan liu <nolan.liou@gmail.com>
Date:   Tue Jul 25 06:53:50 2017 +0800

    Add mark_flag_as_required functions to make the APIs compatible with … (#11568)
    
    * Add mark_flag_as_required functions to make the APIs compatible with python-gflags.(#11195)
    
    * Add review advises for efficiency
    
    * Cleaning up some lint, renaming one of the private method names.
    
    * Import as underscore.

commit 624f0d402383ba4476e6131cbe1d421e3710c1bd
Author: Shanqing Cai <cais@google.com>
Date:   Thu Apr 13 12:47:18 2017 -0800

    Improve efficiency of get_session_handle
    
    Change get_session_handle() back to use v1 of GetSessionHandleOp, instead of v2. The v1 op returns a string, instead of an encoded ResourceHandle, which gets rid of the need to call ParseFromString() in Python.
    Change: 153101229

commit de604cbaaa093765f5dbccaf2a1097e83ca7fe32
Author: Shanqing Cai <cais@google.com>
Date:   Fri Mar 10 10:12:32 2017 -0800

    tfdbg: Let NodeStepper use TensorHandles as direct feeds
    
    CL/149672538 has made TensorHandles directly feedable for Session.run() calls. This eliminates the need to call TensorHandles.eval() to get the value of a Tensor and feed it back in during tfdbg NodeStepper's cont() (i.e., continue-to) calls.
    
    This change improves the memory efficiency and performance of NodeStepper.cont() by eliminating unnecessary Tensor-numpy and numpy-Tensor copying.
    Change: 149769853

commit cdecf416365c85f8274393e097ecab163cbea7c3
Author: Shanqing Cai <cais@google.com>
Date:   Thu Mar 9 11:13:46 2017 -0800

    Enable the direct use of TensorHandles as feed values through ResourceHandles
    
    This is motivated by, among other goals, the need to enhance memory efficiency during TFDBG's stepper operations. The stepper caches TensorHandles to already-continued-to tensors and use them as feeds if later continue-to actions depend on the tensors as transitive inputs. However, previously the TensorHandles had to be converted to Numpy arrays by calling eval() and the Numpy arrays were then fed back to next Session.run() calls. This mode of operation involved at least two unnecessary tensor-numpy and numpy-tensor copying.
    
    This CL makes it possible to use the ResourceHandle representations TensorHandles directly as feed values, eliminating the need for the aforementioned copying.
    
    To this end, the following changes are made
    1) the underlying representations of TensorHandles are changed from string to ResourceHandle. A custom numpy struct type is created to allow ResourceHandle of the TensorHandle subtype to be fed during Session.run() calls.
    2) added GetSessionHandleOpV2, which deprecates GetSessionHandleOp. The V2 op outputs a DT_RESOURCE Tensor, instead of a string Tensor in the deprecated version.
    Change: 149672538

commit 6dc7f989f10ceb4cc6b19e627ab742e02a0787b7
Author: Yaroslav Bulatov <yaroslavvb@gmail.com>
Date:   Mon Dec 12 22:34:22 2016 -0800

    replace AsProtoField with AsProtoTensorContent for efficiency (#6257)

commit d26c33bd3720fe492c023e368c68f56b763fa1d3
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Oct 6 17:09:00 2016 -0800

    Adding an optimized implementation of concat on GPUs.  Large efficiency gains
    over current code when there are many tensors that are being combined.
    
    One piece of fixing b/30377985.  The next step is to implement a split that
    can output variable sizes, then the gradient of concat will be one (fast) op
    instead of many slower ones.
    Change: 135429927

commit 426e36d6f351dd556ccb1c8defa1ddd88015942d
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Aug 26 07:33:33 2016 -0800

    Reduce subclass boilerplate by embracing duck-typing and adopting a "public-calls-private" design pattern. This pattern reduces lines of Distribution sub-class code by ~33%.
    
    Specifically, this change:
    
    1. Makes BaseDistribution purely virtual.
    2. The new idiom is that all public methods are implemented in the base class, and all possible argument checking is done there. Subclasses implement _methods called by the base class; if they fail to implement it will fire a NotImplementedError during tf graph construction.
    3. Fix style inconsistencies, eg, function order, remove unnecessary indirection, use tf.ones instead of tf.constant, etc.
    4. Fix efficiency when I noticed a problem. Example Dirichlet._variance.
    Change: 131404360

commit 8e37ef50c73d6b3f3ec530a3393fe2cba5ad3a30
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Tue May 10 10:55:24 2016 -0800

    tensorflow: finer-grained Shard parallelization
    
    Provide finer-grained Shard parallelization for the new non-blocking thread pool.
    This significantly resembles the parallel for algorithm in eigen executors:
    we choose a good block size based on amount of work and parallel efficiency,
    and then use recursive division in halves.
    
    Benchmark               Time(ns): old       new     diff  CPU(ns): old        new     diff
    ==========================================================================================
    cpu_RandomUniform/1M           647541    301220  -53.48%       9576553   10553619  +10.20%
    cpu_RandomUniform/2M          1116118    495724  -55.58%      18285896   19635580   +7.38%
    cpu_RandomUniform/8M          2691384   1671594  -37.89%      67830397   72105713   +6.30%
    cpu_RandomNormal/1M           2126780   1269039  -40.33%      46887528   53197040  +13.46%
    cpu_RandomNormal/2M           3529118   2350399  -33.40%      94337705  104481933  +10.75%
    cpu_RandomNormal/8M          12429704   8984079  -27.72%     383278086  410900286   +7.21%
    cpu_TruncatedNormal/1M        2513508   1504161  -40.16%      59181937   66096798  +11.68%
    cpu_TruncatedNormal/2M        4012258   2890855  -27.95%     122164300  129760843   +6.22%
    cpu_TruncatedNormal/8M       17628696  11159204  -36.70%     465946492  513345503  +10.17%
    
    TESTED:
      - passed opensource_build
        http://ci.tensorflow.org/view/Internal/job/tensorflow-cl-presubmit-multijob/281/
    Change: 121971279

commit b09764d0c95ec3c8f56bc930ab2cc25157630cfb
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Mon Apr 25 08:07:56 2016 -0800

    Rewrite Tensor::SummarizeValue to avoid a segfault when passed an
    uninitialized Tensor, and also for efficiency.
    Change: 120712310

commit 7cc6ba76176b84c828dd6b40ec5d2bc0d481f46a
Author: Xiaoqiang Zheng <zhengxq@google.com>
Date:   Thu Mar 10 13:23:33 2016 -0800

    Improve the BiasGrad for NCHW using less shared memory and better memory
    efficiency.
    
    With GoogleNet V1, time spent in BiasGrad in ms:
    
                  Before    After     Improvement
    GoogleNet V1  19.70     13.14     49.93%
    Change: 116901889

commit 7eae838548b2cc940b68c89d27e06fff46c78eb2
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Mon Feb 8 12:19:48 2016 -0800

    Changed the representation for pending and dead counts.  Previously,
    each of these was a std::vector<int>*, sized to the number of nodes in
    the graph.  This meant touching two cache lines every time we wanted
    to manipulate these values, and also required 8 bytes per node in
    total.  Instead, we now use a PendingCounts helper class added in this
    change that uses just a single byte to represent both these counts in
    the common case of fewer than 7 outgoing edges.  This helps with cache
    efficiency considerably because these values are heavily modified
    throughout the graph execution process by different threads running on
    different cores, and also because getting this to fit in, say, L1
    cache instead of L2 cache, also helps efficiency on just a single
    core.  As part of this, added a real interface that describes the
    various operations we want to do to these counts ("decrement_pending",
    "mark_live", "increment_dead_count", etc.), which is more
    understandable than having direct manipulation of counter values
    scattered throughout the ExecutorState code.
    Change: 114137346

commit bd3af957185f2835c638a045c80d6c11b7f71df1
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Fri Jan 15 16:55:13 2016 -0800

    Slight efficiency improvements for setting up binary op kernels.
    Change: 112296712
commit f6548bffe577202381fa5893ad7aa452ae4e4931
Author: Xuechen Li <lxuechen@google.com>
Date:   Mon Jul 23 12:46:01 2018 -0700

    Add main script training sampler on 2D energy landscapes.
    
    PiperOrigin-RevId: 205707483

commit 1eeca01d5c8702764f7597b5e9745573adefc88e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Sep 28 10:06:29 2017 -0700

    Add `tf.contrib.bayesflow.metropolis_hastings`.
    The Metropolis-Hastings accept/reject framework is useful for constructing various MCMC algorithms. Many of the MCMC algorithms are Metropolis-like, i.e., a proposal is generated and then the accept/reject procedure is performed. Current implementation accepts a user-defined target energy and proposal generating function (e.g., normal or HMC proposals) to produce a Markov Chain.
    
    PiperOrigin-RevId: 170358662
